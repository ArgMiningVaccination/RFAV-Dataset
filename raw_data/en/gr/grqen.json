{"title": "PDF", "author": "PDF", "url": "papyrus.bib.umontreal.ca/xmlui/bitstream/handle/1866/25934/Champagne_Clara_2021_memoire.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "of Scientific Evidence Fails to Persuade Antivaxxers A Transdisciplinary Review Par Clara Champagne D\u00e9partement de intitul\u00e9 Why Dissemination of Scientific Evidence Fails to Persuade Antivaxxers A Transdisciplinary Review Pr\u00e9sent\u00e9 par Clara Champagne A La des exemptions de vaccination pour leurs enfants sur la base de la religion ou qui visent \u00e0 promouvoir la vaccination reposent sur simple diffusion connaissances fiables; la communication scientifique est per\u00e7ue comme sens unique de diffusion des connaissances scientifiques. La th\u00e9orie est la suivante : pour lesquelles diffusion de preuves \u00e9chouent. La Selon la th\u00e9orie de la cognition culturelle, la culture les perceptions risque des biais cognitifs. Ces trois ii Abstract Most Americans are not concerned about vaccines. However, a small but vocal minority is, and a growing number of parents are receiving vaccine mandate exemptions for their children on the basis of religion or \"personal belief.\" Vaccine refusal can have disastrous consequences: in some communities, childhood vaccination coverage has dived well below the threshold required for \"herd immunity,\" allowing diseases like measles to stage a forceful comeback. Vaccine hesitancy and refusal are often attributed to a lack of knowledge or lack of understanding of scientific \"facts\" on the part of antivaxxers. Most public health interventions that aim to promote vaccination rely on disseminating trustworthy scientific knowledge and see science communication as a one-way process of diffusion of scientific evidence. If antivaxxers knew how safe, effective, and necessary vaccines are, the theory goes, they would vaccinate more. Unfortunately, literature across disciplines suggests that such passive, community-wide education interventions are mostly ineffective at persuading antivaxxers to adopt pro-vaccination attitudes and behaviours. Why? Inspired by Edgar Morin's principles of transdisciplinarity, Thomas Kuhn's theory of scientific revolutions, and Trisha Greenhalgh's meta-narrative review methodology, I examine the publications of different seminal authors across disciplines that directly or indirectly provide an answer to this question. I distinguish three main approaches, which differ as to their general explanation of why interventions based on simple dissemination of scientific evidence fail. The first explanation is that antivaxxers lack the scientific literacy that is necessary to understand the scientific evidence that is presented to them. The second is that antivaxxers' resistance to scientific evidence can be explained by the numerous cognitive biases and \"rules of thumb\" that lead individuals to make systematic errors in judgment and thus deviate from the rational choice theory decision-making ideal. The third narrative stresses sociocultural influences. According to cultural cognition theory, culture influences risk perceptions through the mechanisms of cognitive biases and heuristics. These three narratives about vaccine hesitancy and refusal are thoroughly examined in order to provide a cross-disciplinary synthesis of factors that may explain the failure of education-based public health interventions to persuade antivaxxers. Keywords: knowledge translation, science of science communication, antivaxxers, scientific literacy, cognitive biases, cultural theory of risk, cultural cognition Table of Contents List of Figures ________________________________________________________________ 1 List of Abbreviations ___________________________________________________________ 2 Introduction _________________________________________________________________ 4 Chapter 1 - Context ____________________________________________________________ 8 1.1. A short history of vaccination and of the anti-vaccination movement ___________________ 8 1.2. The state of vaccination today in the United States __________________________________ 16 1.3. Drivers of vaccine hesitancy and refusal __________________________________________ 21 1.3.1. Vaccines as Unnatural ____________________________________________________________ 24 1.3.2. Conspiracy Thinking and Lack of Trust ______________________________________________ 29 1.3.3. Science, Bad Science and Pseudoscience _____________________________________________ 30 Chapter 2 - Conceptual Model and Research Question ______________________________ 42 2.1. Literature on the Effectiveness of Dissemination of Scientific Evidence to Change Behaviours ________________________________________________________________________________ 42 2.2. Conceptual Model _____________________________________________________________ 47 2.3. Research Question ____________________________________________________________ 49 Chapter 3 - Method ___________________________________________________________ 53 Chapter 4 - Results ___________________________________________________________ 60 4.1. The Knowledge Deficit Model and Scientific Literacy _______________________________ 60 4.2. The Psychological Approach ____________________________________________________ 75 4.3. The Cultural Theory of Risk and Cultural Cognition _______________________________ 92 Chapter 5 - Discussion _______________________________________________________ 109 Index _____________________________________________________________________ 116 Bibliography _______________________________________________________________ 119 1 List of Figures Figure 1. - Non-medical State Exemptions from School Immunization Requirements, 2020 __________________ 16 Figure 2. - The KAP or knowledge deficit model of diffusion of scientific evidence _________________________ 49 Figure 3. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on scientific literacy __________________________________________________________ 61 Figure 4. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on the relationship between knowledge and attitudes ________________________________ 69 Figure 5. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on cognitive biases and heuristics _______________________________________________ 86 Figure 6. - Douglas and Wildavsky's group-grid scheme _____________________________________________ 94 Figure 7. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on the cultural theory of risk ___________________________________________________ 95 Figure 8. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on cultural cognition _________________________________________________________ 95 Figure 9. - Cultural cognition map ______________________________________________________________ 97 Figure 10. - Relationships between cultural predisposition, information exposure and risk-benefit perception __ 100 Figure 11. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on cultural cognition ________________________________________________________ 101 Figure 12. - A more complex KAP model ________________________________________________________ 111 Figure 13. - Other questions about the KAP model _________________________________________________ 112 2 List of Abbreviations AAP: American Academy of Pediatrics CDC: Centers for Disease Control and Prevention CIHR: Canadian Institute for Health Research FDA: Food and Drug Administration IPC: identity-protective cognition KAP: KTA: knowledge-to-action NIAM: National Immunization Awareness Month PTS: positive test strategy VICP: Vaccine Injury Compensation Program WHO: World Health Organization 3 The Brain, within its Groove Runs evenly - and true - But let a Splinter swerve - 'Twere easier for You - To put a Current back - When Floods have slit the Hills - And scooped a Turnpike for Themselves - And trodden out the Mills - Emily Dickinson The antivaxx movement has a lot of things that I love: Star power, science denial, hipster appeal. Because penny-farthings and handlebar moustaches are cool, but nothing is more vintage than dying of rubella. Stephen Colbert 4 Introduction This research is concerned with the role that the diffusion of scientific results plays in the fight against anti-vaccination in the United States. I first became interested in this subject around 2015, when outbreaks of measles among unvaccinated American communities led to spikes in the number of children infected with this preventable disease, which was declared eliminated in the United States in 2000. Vaccination has often been described as one of the biggest scientific achievements since the Enlightenment. Lewis Thomas, a renowned physician, writer and educator and former Dean of Yale Medical School and NYU School of Medicine, described vaccines as the best example of a \"true technology\", a \"genuinely decisive technology of modern medicine\" that is so effective that it is taken for granted.1 And while Thomas' words were written in 1974, they could not be truer today. Vaccines have withstood - even aced - the test of time, and yet they are indeed taken for granted. In the United States, a growing number of children are receiving exemptions from vaccine obligations based on religion and personal belief. This is alarming, not only because diseases like measles can have lasting effects on infected children while being preventable, but also because many epidemiologists anticipate that in coming years, there will be an increase in infectious diseases around the globe. Vaccines have never been more important, and vaccine refusal has never been more prevalent. In parallel to this concern about the state of vaccination today, I also worried about how we are discussing these issues, about which elements are making their way into the conversation. On vaccination as well as on other health-related topics, there seems to be a crying lack of rational dialogue. Pseudoscientific claims, woo-woo cures, false news and conspiracy theories abound. In the era of post-truth, trustworthy science seems unable to sway opinion. This should alarm researchers. Many have noted this before me.2 In fact, the fields of knowledge translation (or knowledge transfer) and \"the science of science communication\" have evolved into impressive corpora of research on the best ways to ensure utilization of scientific knowledge. But the starting point of my study is the realization that in comparison to research focused on utilization of scientific knowledge by practitioners, clinicians, policy- and decision-makers, there has been very little research on knowledge translation aimed at a general public, such as the concerned, well-intended parents who make up the anti-vaccination movement. And while studies on actors such as practitioners and policymakers have consistently shown the inefficacy of knowledge translation strategies consisting of simple diffusion of scientific knowledge, 5 interventions aimed at antivaxxers almost always rely on such strategies.3 When we decry that antivaxxers do not change their opinion in light of overwhelming scientific evidence, we assume that diffusion suffices. In this study, I look more closely at what really happens when we disseminate scientific evidence to antivaxxers. I make use of different research traditions to offer the seeds of a complex intervention model that is more realistic than the simple knowledge-attitudes-practices (KAP) model on which many interventions aimed at antivaxxers seem based. The United States is a particularly interesting case in the study of anti-vaccination. Evidently, it has proven to be a fertile ground for diseases like measles to spread. But the chief reason for choosing the United States over another country is that, in the U.S., conversations about different risks -vaccines, but also gun control, universal health care, GMOs, abortion, or climate change, to name just a few - have a way of becoming extremely divisive. The country is in the midst of what some have called a \"culture war.\" The United States, with its extreme political polarization, extreme inequality, and extreme diversity, is a potent case for studying how individuals make decisions about collective well-being and health. I start with three brief overviews: first, of the history of vaccination and anti-vaccination; second, of the state of vaccination in the United States today; and finally, of the main reasons for vaccine refusal evoked by antivaxxers today. There has been a large amount of studies published on all of these questions, and many books have already provided more comprehensive overviews than what is offered here.4 But these questions are important to provide context for the rest of the study, and grappling with them early on allows me to move on to the more specific and innovative question that interests me for my study, which is not why antivaxxers refuse vaccines, but rather why the diffusion of scientific evidence does not change their opinion and behaviour. In other words, my study is less concerned with the formation of opinion than with change of opinion. The specific question that guides the rest of my research is the following: Why do interventions relying on the dissemination of sound scientific evidence fail to change the behaviour of antivaxxers? I will delve into three research traditions that have studied this question: literature on scientific literacy, research on cognitive biases and heuristics, and cultural theory. The goal will be to provide a chronological, historical summary of the seminal literature in each of these approaches, and to suggest, along the way, how each approach relates to the KAP intervention model. I mobilize two types of literature. The first, which is mainly useful for the Context section, is literature that is specific to the case of anti-vaccination, and particularly in the United States. This includes books and articles by anthropologists, sociologists, and historians, as well as by journalists covering the rise of anti-vaccination attitudes in the U.S. Often, this literature focuses on childhood immunization, which is unsurprising given that vaccine mandates in the U.S. concern children entering school. 6 The second type of literature is not specific to anti-vaccination. The corpus synthesized in the Results section comes from a variety of research traditions across academic disciplines that have looked, directly or indirectly, at issues relating to risk perception. Some of the writings I summarize study the case of anti-vaccination specifically; most do not. In sum, the case I chose to study is anti-vaccination in the United States, but the research I mobilize goes beyond anti-vaccination and, as such, the findings apply to a variety of other risk issues. 7 R\u00c9F\u00c9RENCES: INTRODUCTION1 Lewis Thomas, The Lives of a Cell: Notes of a Biology Watcher (Toronto: Bantam Books, 1974), 39. 2 To name just a few popular science books that have made this argument: Carl Sagan, The Demon-Haunted World (New York: Penguin Random House, 1995); Steven Pinker, Enlightenment Now: The Case for Reason, Science, Humanism and Progress (New York: Penguin Random House/Viking, 2018); Hans Rosling, Factfulness (New Books, 2018); Shawn Otto, The War on Science: Who is Waging It, Why It Matters, What We Can Do About It (Minneapolis: Milkweed Editions, 2016); G\u00e9rald Bronner, L'empire des croyances (Paris: Presses Universitaires de France, 2003), Harry G. Frankfurt, On Bullshit (Princeton: Princeton University Press, 2005); Sebastian Dieguez, Total Bullshit! Au Coeur de Presses Universitaires de France, 2018); Michiko Kakutani, The Death of Truth (New York : Penguin Random House, 2018); Tom Nichols, The Death of Expertise (Oxford: Oxford University Press, 2017); Normand Baillargeon, Liliane est au lyc\u00e9e (Montr\u00e9al: Flammarion, 2011). 3 This is discussed in Chapter 38-42. 4 ; Concern in History (New York: Routledge, 2012); Jennifer A. Reich, Calling the Shots: Why Parents Reject Vaccines (New York: NYU Press, 2016); Heidi Larson, Stuck: How Vaccines Rumors Start - and Why They Don't Go Away (Oxford: Oxford University Press, 2020). 8 Chapter 1 - Context 1.1. A short history of vaccination and of the anti-vaccination movement It is impossible to talk about the anti-vaccination movement without talking about smallpox. In the 18th century, smallpox ravaged populations. Smallpox was responsible for 10% of deaths in the Enlightenment era, a roadblock in a century otherwise marked by progress and hope. Its mortality rate hovered around 20% to 25%, which is high, especially considering that many survivors were left disfigured by atrocious scars, eternal mementos of the infectious blisters that covered their bodies. As described by the historian James Colgrove: Its symptoms began with chills, aches, and fever, then progressed ominously to nausea, vomiting, and difficulty breathing. About a week after infection, bright red pustules developed on the victim's face and hands, and then spread to cover the entire body. Eventually the pustules dried and itched intensely, scabbed over, and fell off. About one out of four victims died; those who survived were usually scarred for life and often blinded. Children, who were generally more vulnerable to infectious diseases, died from the condition more often than did adults, but it struck young and old alike, and without regard to social class.1 The first practice resembling vaccination was variolation, also called inoculation. Variolation consisted in voluntarily transmitting the disease by extracting pus from a sick person's blisters, which was then scraped or inserted onto an incision made on the arm of a healthy subject.2 It was thought that this \"indirect\" skin transmission attenuated the strain of the disease while also providing immunity against \"natural\" smallpox. In fact, while this practice had existed in Asia and Africa for centuries, and while it grew very popular in Europe - especially among the nobility -, the effectiveness of variolation varied greatly, and cases of post-variolation infection and even death were pretty common.3 The first opponents to variolation dutifully kept track of these cases. The invention of the vaccine, in 1796, by the English doctor Edward Jenner was game-changing, and it gradually replaced variolation, which was prohibited in 1840.4 Jenner worked in the country, where the farming population seemed somewhat spared from smallpox. Milkmaids, who spent their days touching cows blistered by cowpox, developed blisters on their hands which seemed to make them immune against human smallpox.5 Their faces were left unscarred, and they did not become ill even if they nursed smallpox victims.6 Jenner took note of this and embarked on the experiment that would forever changed medicine. Eula Biss, in her book On Immunity: An Inoculation, tells the story this way: Jenner \"extracted pus from a blister on the hand of a milkmaid and scraped it into the arm of an eight-year-old boy. The boy got a fever but did not become ill. Jenner then exposed the boy to smallpox, which did not infect him. Emboldened, 9 Jenner continued his experiment on dozens of other people, including his own infant son. Before long, the procedure would be known by Jenner's term for cowpox, variolae vacinae, from the Latin vacca for cow, the beast that would forever leave its mark on vaccination.\"7 Mass immunization campaigns were soon underway.8 Antivaxxers, in one of many conspiracy theories, accused Jenner of raking in huge profits at the perils of the poor people upon whom vaccination was forced.9 In the 19th century, a radical transformation of living and working conditions - including compulsory school attendance, which brought children close together - led to an increase in diseases. 10 Antivaxxers blamed vaccines.11 Some argued that vaccines weakened the human species, an idea still present in the modern anti-vaccination movement.12 Mandatory vaccination laws came hand in hand with mandatory school attendance laws.13 This increase in compulsory laws provoked a worry among marginalized groups that vaccines were being imposed as another way to dominate them. Nadja Durbach, professor of history at the University of Utah and author of Bodily Matters: The Anti-Vaccination Movement in England, 1853-1907, explains that \"while anti-vaxers today are largely upper middle class, the crowd opposing vaccination in the 19th century was largely composed of lower- and working-class British citizens. They felt that they were the particular targets, as a class group, for vaccination and for prosecution under the compulsory laws. This was part of a larger expression of their sense of themselves as second-class citizens who thus lacked control over their bodies in the way that the middle and upper classes did not.\"14 In the United States, few states had compulsory vaccination laws in the 19th century, but immigrants had to present proof of vaccination upon their arrival.15 In Canada, the francophone population widely opposed vaccination, which they thought of as a blind devotion to the Crown of the anglophone population to England.16 In the antivax rhetoric, vaccines already took the shape of a weapon in a battle for power. This anxiety is still found today in developing countries which, for understandable reasons, are wary of Westerners blazing in holding syringes. Contamination accidents did nothing to soothe these fears. For a long time, adherents to vaccination could not explain these away. A smallpox pandemic in the 1870s seemed to further prove the inefficacy of vaccines.17 Today, we know that contamination can occur through dirty syringes. We know that a certain percentage of the population must be immunized in order to prevent outbreaks, and that the threshold varies depending on the contagiousness of the disease. We also know that some diseases mutate and that some vaccines need boosters in order to provide long-term immunity. But at the time, the science of vaccines was in a much more primitive state. Germ theory was first articulated in the 1860s, and a more modern specific germ theory was developed in the 1880s.18 Gradually, germs were identified; new vaccines were developed; and the science around vaccination became clearer.19 10 It still did not achieve unanimity, though. Many antivaxxers were resolute partisans of panspermia hypotheses and believed that microbes were only dangerous in unsanitary environments.20 There was a clear moralist essence to the argument that a healthy lifestyle could protect you against disease, because it implied that the sick, for lack of a healthy lifestyle, deserved the disease they battled. This hygienist/moralist stance is still found in the modern rhetoric of antivaxxers, many of whom believe that if they maintain a healthy lifestyle their bodies will be able to naturally fight off any and all diseases. Moreover, the antivax discourse pivoted and a new argument emerged: vaccination is an offense to human rights.21 Antivaxxers were able to reframe the vaccine debate as a political, democratic issue: \"compulsory vaccination collided with fundamental medical and religious beliefs held by millions; it overran the rights of parents and, most painfully, contradicted strongly held, and particularly American, notions of personal liberty.\"22 In the United States, many states that had compulsory vaccination laws abolished them following the 1870s pandemic. The Anti-Vaccination Society of America was founded in 1879, followed by the American Medical Liberty League and more local associations such as the Pittsburgh Health Club.23 Anti-vaccination was one of the first and most vehement opinion movements to practice social disobedience.24 The United States became the nervous centre of the antivax battle,25 with Cleveland and then Pittsburgh as its capitals.26 A similar reckoning happened in England, the first country to adopt a widespread compulsory vaccination law in 1853.27 This law \"triggered decades of widespread noncompliance and openly hostile antivaccinism,\"28 fueled by a broader libertarian sentiment at the time.29 In 1898, the English government responded to antivaxxers by adding to its law a \"conscientious objector\" clause allowing parents to apply for an exemption from vaccination.30 Immunization coverage rates dropped.31 However, in the mid-1890s, a measles epidemic around the state of Kentucky created a trail of panic across the South. Specter explains that southern communities, \"finding themselves defenseless against the virus,\" had to turn almost against their will to the United States Marine Hospital Service, the precursor to the U.S. Public Health Service. The doctors sent were granted \"broad police-like powers\": \"they established the first foothold of federal authority in the South since the end of the Civil War and Reconstruction. [...] at the dawn of the Progressive era, dozens of laws and regulations were established to empower police officers, public-health officials, and even the armed forces to vaccinate at will, and, if necessary, at gunpoint.\"32 These coercive laws dramatically reduced the number of smallpox cases in the United States, but they also initiated a dramatic battle over civil liberties.33 As Heidi Larson, an anthropologist who researches vaccine confidence, notes, \"[v]accination, from its start, has always walked a tense line between personal choice and public health, between autonomy and cooperation.\"34 In the United States, at the turn of the twentieth century, antivaxxers filed a series of lawsuits against municipal and local authorities that had 11 compulsory vaccination laws. They argued that an individual has the right to do what he chooses with his own body.35 In a 1905 landmark ruling that is still cited to this day, Jacobson v Massachusetts, the Supreme Court of the United States upheld compulsory vaccination laws, declaring that individual rights could not be legitimately invoked in the case of a threat to the collective well-being.36 The decision states that: The liberty secured by the Constitution of the United States does not import an absolute right in each person to be at all times, and in all circumstances, wholly freed from restraint, nor is it an element in such liberty that one person, or a minority of persons residing in any community and enjoying the benefits of its local government, should have power to dominate the majority when supported in their action by the authority of the State. It is within the police power of a State to enact a compulsory vaccination law, and it is for the legislature, and not for the courts, to determine in the first instance whether vaccination is or is not the best mode for the prevention of smallpox and the protection of public health.37 Moreover: Society based on the rule that each one is a law unto himself would soon be confronted with disorder and anarchy. Real liberty for all could not exist under the operation of a principle which recognizes the right of each individual person to use his own, whether in respect of his person or his property, regardless of the injury that may be done to others.38 In 1922, the same court confirmed the legality of school certificates.39 The word \"immunity\" comes from the Latin \"munis,\" meaning \"service,\" \"duty.\"40 At the end of the first World War, vaccination became a matter of patriotism - of service and duty to the country.41 Both world wars had a demobilizing effect on the antivax battle.42 Vaccine refusal, which was considered an act of political courage among certain educated strata of the population, was perceived very differently in the working class, where objectors were seen as cowards who refused to protect their country.43 Thus, while variolation was the affair of rich bourgeois in 18th-century England, in the 20th century, it is vaccine refusal that was seen as bourgeois behaviour.44 After World War II, a new impetus for international cooperation led to global health policies. While politics in the Cold War era was a divisive topic, medical and sanitary cooperation achieved wider consensus.45 The 1950s and 1960s were decades of \"enthusiasm and faith in progress.\"46 The World Health Organization, which was founded in 1948, implemented disease treatment programs on a global scale which relied on the use of vaccines.47 New vaccines were developed to treat a greater number of diseases. Life expectancy all over the world increased.48 In developing countries, where vaccines proved life-changing, there was little resistance.49 As noted by both the writer Eula Biss and the researchers Salvadori and Vignaud, the antivax movement only prospered in countries offering the freedoms of democratic debate50: \"Wealthier countries have the luxury of entertaining fears that the rest of the world cannot afford.\"51 Moreover, in the United States, the polio epidemic of the 1940s-1950s generated unprecedented mobilization in favor of vaccines.52 In 1952 alone, 60 000 Americans were infected with polio, and 20 000 became paralyzed because of it.53 \"For earlier generations of Americans, faith in mass vaccines derived in large part from the campaign to eradicate polio, in the 1950s - a time when the country's victory in World 12 War II and the subsequent postwar boom had boosted the public's belief in its leaders.\"54 The first inactived vaccine was developed by Jonas Salk.55 It was tested on 2 million children and proved to be a resounding success.56 However, the vaccine was produced in a hurry, and a contamination incident occurred at one of the laboratories, Cutter, which led to cases of post-vaccination paralyses and deaths.57 The public's trust was undermined; lawsuits were filed, and sensationalist media stories abounded.58 This incident, which came to be known as the Cutter Incident, led to the development of an attenuated oral polio vaccine (\"OPV\", or the Sabin vaccine), as well as more rigorous controls to ensure the safety of vaccines.59 Indeed, in the mid-20th century, protocols were implemented to ensure the efficacy and safety of vaccines, and the first rules of medical ethics were established.60 Allopathic medicine had \"long dispensed itself from basic precautionary principles that are common sense today\":61 \"in 1900 the F.D.A. didn't exist, and neither did any federal rules about how to make, test, or deliver vaccines.\"62 In the 19th century, experiments were often conducted on non-consenting sick people or marginalized groups such as prostitutes.63 There were incidents and contaminations.64 The rules and protocols established after the wars addressed these concerns. Vaccines became safer. In the 1960s, \"the Johnson administration made mass inoculation one component of the ambitious assault on poverty, ignorance, and disease known as the Great Society. In 1964 - a year in which 77 precent of Americans told pollsters they trusted government to do the right thing most or all of the time - the surgeon general established a committee to determine how states should administer vaccines. There was little public resistance. By 1968, half the states required children to be vaccinated to attend school, and the rest soon followed.\"65 In this decade, vaccines were developed to fight measles (1963), mumps (1967) and rubella (1969), all widespread childhood diseases.66 40 years ago, the WHO declared the eradication of smallpox, a scourge for humanity for millennia which killed 300 million people in the 20th century alone.67 Today, smallpox only exists in two vials kept in high-security facilities in Siberia and in Atlanta, at the CDC. As scientific consensus around vaccines grew, antivaxxers were forced to abandon their pseudoscientific arguments of the 19th century to return to their mystico-naturalist roots.68 Once again, a hygienist, moralist, almost religious stance was adopted, according to which a healthy body, obtained through healthy living, could fight off disease - no need for vaccines.69 As Peter Beinart writes, \"today's skepticism of vaccines has its roots in the alternative-medicine and self-help movements of the 1970s, which encouraged people to question established medical authority. This questioning coincided with a post-Watergate, post-Vietnam disillusionment with government that Ronald Reagan exploited when he declared in his 1981 inaugural address that 'government is not the solution to our problem; government is the problem.'\"70 Anti-vaccination, in trying to survive the generalization of the practice of vaccination, found allies - and an opportunity to regenerate itself - in other emerging social and political movements like anti- 13 capitalism, environmentalism and struggles for civils rights, such as the right to abortion which, not unlike anti-vaccination, denounces State intrusion in bodily intimacy.71 As noted by Beinart72 as well as Salvadori and Vignaud73, this era is marked by post-Nixon distrust in government, individualism, and fear of intrusion in the familial nucleus. By 1981, all American states had passed compulsory vaccination laws, but unlike smallpox-era laws, many laws of the 1960s and 1970s contained exemption clauses based on religious belief.74 After different tribunals found the obligation for claimants to prove the legitimacy of their religious belief unconstitutional, multiple states added exemptions based on \"personal belief\"75 - a much lower threshold. As explained by Conis, \"most personal belief exemptions were adopted in the same period, the late 1950s through the early 1980s, that the majority of modern school vaccine mandates were passed. [...] Such exemptions were often included or added to garner support in the process of passing or strengthening [vaccination] mandates.\" Moreover, \"the language in these exemptions reflected the influence of legal battles and rights movements of the 1970s that blurred the line between religious and moral beliefs, popularized health care rights, and promoted the idea of informed consent.\"76 For certain antivaxxers, vaccine refusal is part of a larger resistance to capitalism.77 Anti-vaccination is related to anti-capitalism in that many antivaxxers fear \"Big Pharma\" - a term coined by antivaxxers in response to privatisations in the pharmaceutical industry, where profit motives intertwine with vaccine-promotion campaigns.78 The paradox of this argument seems lost on antivaxxers: \"[A] privileged 1 percent are sheltered from risk while they draw resources from the other 99 percent.\"79 The development of Big Pharma can be explained by multiple factors. First, the fabrication of combined vaccines was complicated, and smaller companies often did not have the resources to produce them.80 Second, there was international pressure for standardisation of vaccines, and big pharmaceutical companies were best placed to ensure such standardisation.81 Third, the development of intellectual property laws led to the patenting of vaccine formulas by companies.82 Finally, in embarking upon a decades-long, relentless judicial harassment of government authorities and vaccine-producing laboratories, antivaxxers themselves contributed to the development of Big Pharma - although this paradox, too, seems lost on them.83 From the mid-1970s to the mid-1980s, the number of lawsuits per year increased exponentially. Between 1978 and 1984, the average claim ballooned from $10 million to $47 million.84 Only large international companies could survive these judicial battles.85 The science journalist James Hamblin writes that: Developing a novel vaccine that could prevent hundreds of thousands of cases of a deadly disease - but cause a much smaller number of side effects that could lead to multimillion-dollar lawsuits - made a useful product an unappealing business proposition. During the 1970s and '80s, some manufacturers began to withdraw from vaccine production. In the midst of this, public-health officials grew concerned about the stability of the country's continued supply of existing vaccines - and the dwindling business incentive for companies to invest in developing new ones.86 14 In 1986, President Reagan responded with the National Childhood Vaccination Injury Act, or \"Vaccine Act\", which set up a compensation fund for accidents determined to be attributable to a vaccine, in return for government and industry immunity unless there is a serious breach of prudence and security.87 The Vaccine Act introduced other special measures:88 petitioners' legal fees are covered by the Vaccine Injury Compensation Program (VICP); in 2017 alone, the program paid $25 million in fees.89 Moreover, the Vaccine Act enacted the Vaccine Adverse Event Reporting System, which requires health care professionals to report adverse events happening after a vaccine. As stated by Hamblin, \"[t]his level of attention to side effects is unprecedented among pharmaceutical products.\"90 In the past 30 years, the program has handed out more than $4 billion to claimants alleging that they were harmed by a vaccine.91 The Vaccine Act, an effort to respond to vaccine fears and to ensure the continued production of vaccines, has turned out to be a double-edged sword. The law does not have the same standard of proof as science.92 And in the case of this law, the burden of proof is reversed: \"The key legal stipulation is that if the petitioner has experienced one of the injuries or illnesses in the table in a period after receiving a vaccination, she receives a presumption of causation. Unlike a criminal case, where a defendant is presumed innocent, the vaccine cases are supposed to presume that vaccination was the cause - unless that can be disproved. So, as the VICP's site states, 'being awarded compensation for a petition does not necessarily mean the vaccine caused the alleged injury.'\"93 Moreover, \"[a]ccording to the CDC, some 300 million doses of vaccines are distributed in the United States in an average year. The program reports an average of about 500 petitions, of which it compensates about two-thirds. That's about one compensation for every 1 million vaccine doses. Working from the estimate that 70 percent of the awards are not clearly attributable to vaccines, the payments estimate a rate of injury or illness caused by vaccination at about one in 4.5 million.\"94 Besides, as noted by Eula Biss, many antivaxxers seem to forget that complications associated with vaccines are also caused by the diseases that these vaccines seek to prevent - for example, encephalitis, which can be caused both by measles and, in rare cases, by the measles vaccine.95 However, to the public eye, 4 billion dollars in damages suggests otherwise. These compensations create an appearance of causation; they perpetuate the idea that vaccines are to blame for the real harms suffered by these claimants, even if science suggests that they aren't.96 Fears about vaccines do not seem to be quelled by science. In her book Calling the Shots: Why Parents Reject Vaccines, the sociologist Jennifer Reich summarizes what can be learned from studying the history of anti-vaccination: The first point that is important to make is that vaccines are both a technology for individual benefit and a tool to protect community health. This dual use complicates how we understand informed consent, because something that might be primarily for the community good carries some risk to the individual. Unlike other medical interventions, infectious disease creates risk for others. Law has not been successful in resolving these tensions, which become magnified when distrust in science and scientific expertise grows. 15 Second, vaccine uptake is reasonably high when Americans see vaccines as lifesaving and lower when vaccines seem unnecessary. [...] Third, our vaccine history reveals a core tension between vaccines' significance as a public resource and the reality that it is a product produced by for-profit corporations. [...] Fourth, the shielding of vaccine makers from tort liability for a potentially dangerous product also underscores these conflicting understandings of vaccines. Threats to cease manufacturing have resulted in legal protection [...] These historical trends inarguably shape perceptions of vaccines today.97 Key Messages : A short history of vaccination and of the anti-vaccination movement Anti-vaccination attitudes are nothing new. Such attitudes have existed since the first practices resembling vaccination. Anti-vaccination attitudes have always been characterized by conspiracy thinking, pseudoscientific naturalist arguments and debate over what is perceived to be undue government control over individuals. Incidents, contaminations and experiments on nonconsenting sick people and marginalized groups did nothing to soothe these fears. What is perhaps new today is the speed at which arguments, theories and rumors about vaccines can spread, including on social media networks. 16 1.2. The state of vaccination today in the United States Today, in the United States, vaccination is sometimes described as a \"semi-obligation.\" There is no federal law making it compulsory, but all states demand proof of immunization for children entering school. Each state decides what the required vaccines are for enrollment and attendance at a childcare facility or school in that state.98 However, all states also recognize grounds for exemption [Figure 1]. In all 50 states, children may be granted exemptions for medical reasons. 45 states and Washington D.C. (all but West Virginia, Mississippi, California, New York and Maine) also grant exemptions for religious beliefs. Furthermore, 15 states grant personal belief exemptions - although this number has been decreasing following multiple measles outbreaks all over the country.99 As previously noted, the development of the personal belief exemption happened in waves, following the development of new vaccines or the enactment of new vaccine laws: \"In each stage, the exemptions reflected political compromise in the lawmaking process and broader struggles over liberties and rights.\"100 But, as Eula and Mavis Biss note, granting exemptions from vaccines based on \"personal belief\" is problematic: Philosophy is not a matter of declaring rigidly held beliefs, but of working out what can be held true in conversation with others. In the Western tradition, going all the way back to Plato, philosophy is based on dialogue. But philosophical exemptions to vaccination laws excuse people from explaining themselves. And the philosophy behind many exemptions remains as remote and ill-defined today as the conscience was in the Figure 1. - Non-medical State Exemptions from School Immunization Requirements, 2020 Source: National Conference of State Legislatures 17 late 1800s. These exemptions allow parents to offer their fears as justification for not vaccinating their children. [...] Americans seem to have inherited a folk theory of conscience that confuses firm belief with knowledge. But you can't know something that isn't true, though you can certainly believe something that isn't true.101 Today, a growing number of parents are receiving vaccine exemptions for their children on the basis on religion and personal belief. Some parents are delaying their children's vaccinations or cherry-picking the vaccines their children receive.102 Others are not vaccinating at all. Larson writes in The Lancet, \"there are growing anti-vaccination networks and vaccine refusals and increasing numbers of non-medical vaccine exemptions.\"103 In her 2020 book Stuck, she compares today's vaccine skepticism to wildfires: \"The emotions are burning hotter, traveling faster, and their paths and populations are less predictable.\"104 In a 2006 study published in the renowned Journal of the American Medical Association, researchers found that more non-medical exemptions are granted where personal belief exemptions are permitted, and that a larger number of personal belief exemptions are positively correlated with a higher incidence of pertussis (whooping cough) cases.105 According to a more recent study, states with higher overall non-medical exemption rates also have lower MMR vaccine coverage.106 In the United States, unvaccinated children tend to be white, to have a college-educated, married mother, and to live in a household with an income superior to $75 000.107 In 2018, the number of non-medical exemptions increased in many states: Arizona, Arkansas, Idaho, Maine, Minnesota, Missouri, North Dakota, Ohio, Oklahoma, Oregon, Texas et Utah.108 In some counties, the exemption rate reached 30%.109 The counties with the highest exemption rates tend to be densely-populated urban regions with international airports, two characteristics that increase the risk of an outbreak.110 More and more children are receiving medical exemptions, and some doctors are being identified as \"sellers\" of medical exemption certificates.111 Since the turn of the century, the proportion of American children under 2 who are unvaccinated has quadrupled.112 It is important here to pause to note the difference between vaccine hesitancy and vaccine refusal. As philosopher Maya Goldenberg explains: Vaccine hesitancy refers to an attitude of ambivalence regarding vaccines. It is distinct from vaccine refusal, which is a behavior. Vaccine hesitancy runs along a spectrum from mild to severe uncertainty about whether vaccines are safe, effective, and necessary. While attitudes and behaviors are linked, vaccine hesitancy does not fully determine vaccine acceptance or refusal.113 Public health research has historically focused on vaccine refusal, by looking at hard numbers on rates of vaccination like the ones I just presented. The interest in vaccine hesitancy is newer.114 Goldenberg writes that vaccine hesitancy is \"a more informative analytic concept\": \"In the industrialized North, where vaccines are widely available due to relatively stable health systems infrastructures, the great variation between vaccine hesitancy and refusal is important.\"115 18 It is clear that there is more vaccine hesitancy than vaccine refusal: \"rates of refusal of childhood vaccines [...] sit steady at 2 to 3 percent\" in the United States and Canada. In the 2018-2019 school year, the total percentage of American kindergarteners who received exemptions was 2,5% - higher than in 2017-2018 (2,3%) and 2016-2017 (2,1%). Only 0,3% of these were medical exemptions; the majority (2,2%) were religious or personal belief exemptions.116 This study also confirms the important variability between regions. At the state level, the range of kindergarteners who received exemptions ranged from 0,1% (in Mississippi) to 7,7% (in Idaho).117 Washington state, the center of a measles outbreak the same year, had one of the highest exemption rates in the country, with nearly 5% of all kindergarteners opting out of immunisations. In Clark County, the epicenter of the outbreak, that percentage was 7,9% in 2017-2018.118 These numbers are alarming given that for a disease as contagious as measles, the total rate of immunization has to reach 95% in order for herd immunity to protect the community from an outbreak.119 States like Idaho and Washington fall well below this threshold. And when herd immunity is not achieved, children who are too young to be vaccinated, as well as people who cannot be vaccinated for medical reasons, are at risk of becoming infected. By comparison, a national survey published in the renowned journal Pediatrics in July 2020 found that \"[a]lmost 1 in 15 US parents are hesitant about routine childhood vaccines, whereas >1 in 4 are hesitant about influenza vaccine. Furthermore, 1 in 8 parents are concerned about vaccine safety for both routine childhood and influenza vaccines, and only 1 in 4 believe influenza vaccine is effective.\"120 The attitude of vaccine hesitancy thus seems more prevalent than the behavior of vaccine refusal. However, as Yale law and psychology professor Dan Kahan points out, \"most Americans are not concerned about vaccine risks.\"121 Underscoring this matters: The dominant message is that there is a \"growing crisis of public confidence\" (Pettett 2012) in vaccines among \"a large and growing number\" of \"otherwise mainstream parents\" (Largent 2012) - not among weird, fringe outliers (e.g., members of the Taliban) but people just like you (e.g., California soccer moms; Krans 2013). Those responsible for propagating this trope - including individual public-health professionals who advance it through popular writings and media appearances - no doubt believe that fostering it will rally support for addressing the dangers posed by the small segment of the general population that is hostile to universal immunization. However, their assertion of \"growing distrust of vaccinations,\" in addition to being false, is replete with characteristics known to trigger self-reinforcing waves of public anxiety (Kasperson et al. 1998).122 [...] This is the message, in fact, of \"Assessing the State of Vaccine Confidence in the United States,\" issued by the Department of Health and Human Services' National Advisory Committee on Vaccines in the summer of 2015 [...] The report noted, for example, the consistent survey findings indicating that \"a majority of parents have favorable beliefs or perceptions regarding recommended childhood vaccines.\" It also observed that positive attitudes such as these are a science communication asset that must be protected. \"Parents,\" the report remarked, \"are more likely to be confident in immunization recommendations if they perceive that others in their social group have high levels of vaccine acceptance\" (NVAC 2015, 576, 580). By the same token, the report noted the serious risk that the misleading statements in the \"news media stories\" can undermine the role that norms plays [sic] in promoting vaccination behavior by creating the exaggerated impression that many parents are \"delaying or declining recommended vaccinations,\" thereby \"lower[ing] parental confidence in vaccines (NVAC 2015, 580). Even more critically, the report issued a call to the public health establishment to systematize its own role in generating, collecting, and acting on the empirical evidence relating to science communication and public opinion formation.\"123 19 Misleading alarmist messages that imply that many parents are resisting vaccination for their children may create such resistance: \"people tend to contribute voluntarily to public goods - such as herd immunity - when they believe that others are doing so but refrain when they perceive widespread free-riding.\"124 Giving credence to the false notion that there is ubiquitous controversy around vaccination is dangerous. As noted by the science journalist Michael Specter in The New Yorker, \"what makes it easy to be a vaccine dissenter these days is the fact that most people aren't. Because of routine vaccination, measles - which kills at least a hundred and fifty thousand people in the developing world each year - long ago ceased to be a significant threat in thee United States.\"125 Vaccination is a victim of its own success: the more invisible the diseases it prevents become, the more unnecessary vaccine mandates seem. Specter warns that \"the dangers of complacency are real.\"126 And indeed, they are. The menacing resurgence of measles has forced a reckoning. The number of cases of the disease - which was declared eliminated in the United States in 2000127 - tripled between 2018 and 2019 alone.128 According to the CDC, there were 63 measles cases in the United States in 2010, 220 in 2011, 55 in 2012, 187 in 2013, a staggering 667 in 2014, 188 in 2015, 86 in 2016, 120 in 2017, 375 in 2018, and a heartbreaking 1282 in 2019.129 These numbers are low compared to how many people used to contract the disease before a vaccine was developed - and, as mentioned above, the vast majority of American parents believe in vaccination -, but they are still too high given the existence of an effective vaccine. The fluctuation of this number year to year can be explained by outbreaks centered on certain communities. In 2014, there was a large outbreak among the unvaccinated Amish community in Ohio.130 In 2015, the number was inflated by a large outbreak which started at a Disneyland resort in California.131 In 2017, 75 people were infected in a largely unvaccinated Somali-American community. And in 2018, outbreaks in New York and New Jersey were largely concentrated among the unvaccinated Jewish orthodox community.132 2019 concluded with the highest number of reported cases of measles in the United States since 1992.133 The fact that in the past 10 years, so many children suffered from a disease that medicine can fully prevent is nothing short of heartbreaking. These epidemics suggest things. First, regions with the lower vaccination rates are incubators for diseases like measles; the number of cases in an area is directly related to the local vaccination rate. The problem is that a high overall rate of vaccination country-wide does not protect pockets of the population with vaccination rates lower than the threshold required for herd immunity. Kathleen Hall Jamieson, the director of the Annenberg Public Policy Center at the University of Pennsylvania, observes that perhaps this, like the alarmist messages denounced by Kahan, is another science communication error: When the CDC conventionalized the term \"herd immunity\" and set a threshold of 90% to 95% as the immunization goal needed to attain community protection from measles, for example, it analogized humans 20 to cattle, seemed to assume that mindless conformity was a social good, and mistakenly implied that achieved 90% to 95% overall immunization was protective. Instead, since individuals are not equally likely to interact with one another, 95% immunization can leave enclaves with much lower rates, including specific community schools and pediatric offices. By contrast, the more apt notion of \"community immunity\" both invests audiences with identity and agency and invites them to scrutinize the immunization levels of the communities with which their families engage. Unlike \"herd immunity,\" \"community immunity\" invites concern about unvaccinated enclaves of individuals.134 Second, as noted by Beinart, \"[a]nti-vaccination activists have enjoyed particular success in communities whose cultural isolation makes them easy prey for misinformation.\"135 Beinart reports that in 2010 and 2011, Andrew Wakefield - the disgraced British doctor who authored the falsified, now-widely debunked article suggesting a link between the MMR vaccine and autism - visited the Somali-American community in Minnesota three times. The local vaccination rate, which was 92% in 2004, plunged to 42% in 2014. In 2017, children of the Somali-American community accounted for the majority of the country's measles cases.136 Many states responded to the measles resurgence with bills to modify their exemption clauses. With Senate Bill 277 in 2015, California acted swiftly to remove personal belief as a ground from exemption from vaccine requirements. Maine and New York soon followed. Conis writes that \"[i]n 2019, in response to record-breaking measles outbreaks, lawmakers in at least 10 states attempted to eliminate or restrict the exemption,\"137 provoking an \"outbreak of demonstrations\" across the country.138 Key Messages : The state of vaccination today in the United States The vast majority of American children are vaccinated. Speaking about the state of vaccination in the U.S. today as if large numbers of individuals are vaccine-hesitant is misleading and constitutes a science communication mistake. There have always been exemptions from vaccine obligations. However, today, a greater proportion of exemptions are based on \"personal belief.\" While the overall immunization rate remains high, there have been alarming outbreaks of diseases like measles in communities where an insufficient number of people are vaccinated in order to achieve \"herd\" immunity. 21 1.3. Drivers of vaccine hesitancy and refusal A lot has been written on the drivers of vaccine hesitancy and refusal. A new stream of research focusing on the concept of \"vaccine confidence\" explores the myriad factors favoring or impeding trust in vaccines, providing \"an expanded way of conceptualizing the problem and how to respond to it.\"139 Widdus and Larson write that: It is time for vaccination programs to recognize that in this era when increasingly facts alone do not drive decisions, it is important to understand the complex and diverse perceptions held by vaccination resisters. To help design effective interventions, there must be equal attention to, and investment in, understanding of what shapes the beliefs and decisions of those who accept vaccination and those segments of the population who are hesitant.140 A particular stream of this literature focuses on vaccine rumors. Larson describes the Vaccine Confidence Project, which she founded, as follows: Drawing on models of information surveillance to detect disease outbreaks, my team built a monitoring system to detect the emergence, evolution, and impacts of vaccine rumors. We take the pulse, monitor the rumor eather, look for brewing storms - rumors with the potential to spiral out of control - as well as map the cultural, and historical contexts where rumors are more likely to get traction. We want to see how far and how fast kernels of concerns spread, how they evolve and adapt in different cultural and political settings, and then map the overall ecology of vaccine rumors. [We] try to step back and look at the issue of vaccine dissent and disruption differently, as an ecosystem, tracing the conncetions and patterns of vaccine emotions and consequent behaviors, locally and globally.141 Sociological and anthropological studies are also particularly helpful to understand the arguments invoked by individuals to justify their vaccine hesitancy and/or refusal. The goal of this study is not to examine the content of these arguments, why they are formed or how they spread. However, a short overview of these arguments, before delving into the main question at hand, seems necessary in order to create a distinction between the reasons why one might refuse vaccination, and the reasons why many antivaxxers do not change their opinion in light of scientific evidence. So who becomes an antivaxxer? And why? In the United States, today, mothers account for the majority of the people in the anti-vaccination movement, which can be explained by the fact mothers are usually more responsible for choices related to the health and well-being of children. According to Reich, these mothers tend to be white, college-educated and in a higher socioeconomic strata. Moreover, they tend to be in the same networks as other mothers who are wary of vaccination.142 Another type prone to anti-vaccination attitudes? \"Social media-savvy millennials,\" writes Larson, \"regularly feature in surveys as being the more vaccine-skeptical age group, eager to find their own evidence, make their own choices.\"143 As Goldenberg writes: \"A unique feature of vaccine hesitancy in the industrialized North is that the most vocal vaccine hesitators and refusers are affluent and educated, that is, they are people who are largely supported by the systems of power and privilege in place.\"144 22 In a 2015 article, Betsch et al offer a typology of the four kinds of people who do not vaccinate their kids, in a model they named the \"Four C Model\". According to them, vaccinal refusal can be due to complacency, (in)convenience, skewed calculation of utility or lack of confidence.145 Betsch et al urge decision-makers and interveners to tailor their solutions based on these different causes of anti-vaccination, in order effectively reach each of these types of antivaxxers: \"When people do not vaccinate because of complacency, use informational interventions to explain disease risks and to stress social benefits of vaccination. When people do not vaccinate because it is inconvenient, remove barriers, support self-control, and add incentives. When people do not vaccinate because they lack confidence in vaccines, it is important to correct myths. When people do not vaccinate because they calculate that risks outweigh benefits, emphasize thee social benefit of vaccination and add incentives.\"146 In a country as politically polarized as the United States, the question of whether vaccine hesitancy is linked to political ideology seems obvious. Somewhat surprisingly, though, it has often been noted that antivaxxers are spread out on both sides of the aisle, and that organized anti-vaccination movements can be found in both Republican and Democratic areas. Some have suggested that there are two antivax poles in the U.S: the Republican South and the Democratic West.147 The first of these opposes vaccination on more libertarian grounds, fearing first and foremost the \"State\", regulation and elites. The West, by comparison, is more leftist, and antivaxxers at this pole oppose vaccination because of a lack of trust in modern medicine, Big Pharma and capitalism. While there are definitely political undertones to these arguments, political ideology or political party affiliation, in an American sense, are not the leading forces behind anti-vaccination. Religion doesn't seem to explain anti-vaccination attitudes, either. Only 10-12% of Americans believe that vaccination is contrary to their religious beliefs.148 This is somewhat paradoxal, given that exemptions are mostly granted on the grounds of \"religion\" or \"personal belief.\" It is true that some religious communities refuse or actively oppose vaccination. The Amish, who reject modernity and new technologies, unsurprisingly do not vaccinate their children, which has led to isolated outbreaks of measles and polio in their communities.149 Jehovah's Witnesses used to refuse vaccination, but have, since the 1990s, recognized that vaccines are beneficial and changed their vaccination practices.150 Mormons of the Church of Latter Day Saints are a peculiar case study: they do not oppose vaccination; in fact, they actively support it and are involved in worldwide vaccination efforts.151 The Church of Christ, Scientist is the only Christian sect to adopt an official anti-vaccination stance.152 For them, disease can only be cured by prayer.153 There is thus clearly a lot of variability within broad religious groups. As noted by the immunologist Fran\u00e7oise Salvadori and the historian Laurent-Henri Vignaud in their book Antivax, religion in the anti-vaccination movement often serves as a mask to conceal other worries.154 Larson concurs: \"religion is sometimes used as a guise for other underlying concerns, beliefs, 23 or political stances, or to appeal to the trust networks within a community of shared beliefs.\"155 Vaccine opponents since the 18th century have had a conservative, moralist discourse that condemns vaccines as an immoral intrusion and violation of a God-made body.156 In their 2019 article, Benecke et al write that: \"After surveying 1000 parents of children younger than 13 years of age who were living in the United States, researchers found that thee morals of purity and liberty were most associated with vaccine hesitancy. [...] [T]hose who value purity disapprove \"of acts that are deemed 'disgusting' or 'unnatural,'\" which they associate with vaccination.\"157 Just as the smallpox vaccine was once seen by moralists as too easy a cure for the unhygienic way of life having allowed the disease, moralist, \"religious\" antivaxxers today see the HPV vaccine as an incitement to debauchery for the young women it targets. Like birth control, vaccination is perceived to be \"against nature.\" The Vatican has in the past expressed a worry that foetal cells were being used in vaccines.158 In 1994, a fake news story claiming that the tetanus vaccine caused sterility was propagated by the \"pro-life\" Catholic group Human Life International.159 Adherents in more than 60 countries believed the fake news, and there was a significant drop in tetanus vaccination coverage.160 In many countries with difficult colonial histories, this fake news story activated an old anxiety - that a colonizer was trying to annihilate the indigenous population by any means. When it comes to anti-vaccination, therefore, religious reasons are rarely isolated from other reasons. So, if it is neither political ideology nor religion in a traditional sense that motivate vaccine hesitancy, what is this \"personal belief\" antivaxxers are invoking? As noted by Larson, \"[v]accine decisions are rarely determined by a single belief, but rather from an interweaving of different strands of values and beliefs [...] This web of beliefs helps to rationalize and navigate uncertainties, fears, and anxieties around vaccines, particularly when the trust relationship with those providing the vaccines is tenuous.\"161 What are some of these values and beliefs? In the following section, I will briefly summarize three beliefs or arguments for resistance that are at the crux of the modern anti-vaccination movement in the United States. First, most antivaxxers today oppose vaccination on the basis of a conception of \"nature\" that leads them to believe that vaccines, and the \"artificial\" immunization it provides, are harmful or, at the very least, unnecessary. Second, many antivaxxers are engaged in conspiracy thinking that reflects their mistrust in government and other elites. Third, science is hard to understand - and like other people of the general public, antivaxxers can hardly distinguish good science from bad science and pseudoscience, especially today, in the era of the internet and fake news. And unlike other people of the general public, antivaxxers have an interest in believing, producing and propagating pseudoscience about vaccines that confirms their beliefs. 24 1.3.1. Vaccines as Unnatural Rousseauist naturalism has been one of the most popular and acute obsessions of antivaxxers since the 18th century. Today, it is widespread among antivaxxers who are more educated and wealthier.162 Their discourse is a melting pot of convictions, mixing criticism of consumer society, ecologism, broader developmental vision and affirmation of Malthusian or even eugenic ideas. Larson states that: \"There is something powerful, almost religiously compelling for some, when it comes to trust in nature.\"163 People who oppose vaccination on the basis of naturalism invoke an idealized conception of \"nature,\" which is sacred, works in cycles, has laws, and should be not modified.164 Naturalists believe the individual should be seen holistically, with regard to his physical body as well as his emotions, his mental state, his spirit, his energy.165 They believe in giving birth at home, eating only organic, GMO- and chemical- free foods, adopting esoteric diet plans, \"natural\" birth control methods, homeopathy, naturopathy, and raising children \"naturally,\" which, unsurprisingly, means unvaccinated.166 Diseases like measles are interpreted as rites of passages, a sort of divine providence which ultimately purifies and strengthens.167 Technology and science modify this \"nature\" and are thus perceived with anxiety and fear.168 Naturalists are wary of antibiotics, GMOs, electronics, and, of course, vaccines. Reich writes that: Parents' concerns about vaccines emerge from larger anxieties about science, technology, and health. These views, at core, shape whether vaccines represent a life-saving innovation or a technology that carries unknown harms. For parents who prioritize natural living and imagine that manmade inventions are intrinsically inferior and potentially dangerous compared to naturally occurring things, vaccines come to represent risk.169 The naturalist argument starts off on the wrong foot - it is built on a skewed conception of humans and their environments that unduly emphasizes a dichotomy between the \"natural\" and the \"artificial\". There are constant references to this dialectic of opposition in anti-vaccination discourses - it is a contextual reference, a prism through which antivaxxers analyse information.170 In a 2015 study based on interviews, observations and analyses of online forums, Reich found that antivax parents saw their children's bodies as naturally perfect and necessitating protection from intrusion. From this perspective, vaccines are seen as an artificial, manufactured, and thus harmful, intervention: \"parents view their children's bodies as naturally complete and uncontaminated and thus reject the notion that it should be exposed to toxins they see vaccines as presenting.\"171 Like antivaxxers in the 18th century, naturalist opponents to vaccination today believe that adopting a certain lifestyle will protect them from disease: \"parents highlight the ways their own natural living serves to enhance their children's immunity rendering vaccines unnecessary.\"172 Even the manner in which vaccines are administered, i.e. mostly injections, is decried as artificial - as it the immunity it provides, which antivaxxers believe to be inferior to the \"natural\" immunity provided by infection with \"the real thing\". Some parents go as far as organizing \"pox parties,\" \"measles parties\" 25 and \"flu parties\" where they voluntarily contaminate their children. Some Facebook groups are marketplaces for pox-contaminated objects.173 In the words of Salvadori and Vignaud: \"It's all a matter of probability and antivaxxers play roulette without knowing it.\"174 Naturalist ideas persist despite the fact that the immunity provided by vaccines, which is obtained through a \"natural\" response of the body, is at least as strong as \"natural\" immunity. In some cases, even, immunity from a vaccine proves to be superior to \"natural\" immunity - such as with tetanus, which unlike its vaccine does not protect against future infection.175 In such cases, \"artificial\" preventive immunity is more effective than \"natural\" immune memory. Confusion around these issues, on which there is much scientific consensus, might be due to how hard it is to understand the nature of vaccines themselves (no pun intended): \"vaccines are of that liminal place between humans and nature [...] a kind of domestication of a wild thing, in that it involves our ability to harness a virus and break it like a horse, but its action depends on the natural response of the body to the effects of that once-wild thing.\"176 Antivaxxers also fear a supposed toxicity of vaccines. Chemical products are seen as necessarily toxic because they aren't \"natural.\"177 As noted by Biss, though \"toxoid\" refers to a toxin that has been rendered no longer toxic, \"the existence of a class of vaccines called toxoids probably does not help quell widespread concerns that vaccination is a source of toxicity.\"178 Legends of contamination abound - Biss writes that \"[t]he idea that \"toxins,\" rather than filth or germs, are the root cause of most maladies is a popular theory of disease among people like me. The toxins that concern us range from particle residue to high-fructose corn syrup.\"179 In vaccines, preservatives (which serve to present vaccine contamination) and adjuvants (which increase the effectiveness of the vaccine) are both sources of anxiety for antivaxxers.180 In 1999, such anxieties about one preservative in particular, thimerosal, were so great that the American Academy of Pediatrics and the US National Vaccine Advisory Committee recommended the removal of thimerosal from childhood vaccines while further investigation into its safety was underway, despite the fact that there was no evidence of it being harmful in the past six decades. Such measures are a double-edged sword: they are meant to soothe fears and anxieties, but can instead create them. Larson observes that \"the public perceived the precautionary recommendation as confirming a problem, and vaccine acceptance started to drop.\"181 As Paracelsus said, the dose makes the poison.182 Ignoring this leads antivaxxers to believe that what is found in vaccines is toxic; it also makes them believe in \"immune overwork,\" or the idea that we may be giving \"pure\" babies too many vaccines. In fact, birth - the sudden arrival in a world filled with filth and germs - is, for a baby's body, a shock much greater than vaccines, which contain minuscule (and decreasing) amounts of antigenic substances.183 These amounts are also considerably smaller than those found in any external environment the child may grow up in, and considerably smaller than those found in his own body.184 26 Biss makes a interesting point: Fear of toxicity strikes me as an old anxiety with a new name. Where the word filth once suggested, with its moralist air, the evils of the flesh, the word toxic now condemns the chemical evils of our industrial world. This is not to say that concerns over environmental pollution are not justified - like filth theory, toxicity theory is anchored in legitimate dangers - but that the way we think about toxicity bears some resemblance to the way we once thought about filth. Both theories allow their subscribers to maintain a sense of control over their own health by pursuing personal purity.185 She adds that this idea of bodily purity which was also at the root of eugenic movements and laws against interracial marriage and sodomy: \"Quite a bit of human solidarity has been sacrificed in pursuit of preserving some kind of imagined purity.\"186 The \"nature\" invoked by these parents is monolithic and static, \"the one true thing that predates humankind and remains pure and unadulterated. To them, nature is the perfect model for human behavior because it is separate from and unpolluted by human manipulation.\"187 As noted by Biss, \"natural\" is equated with \"pure,\" \"safe,\" \"benign.\" That is why antivaxxers find comfort and allies in alternative medicine practitioners: One of the appeals of alternative medicine is that it offers not just an alternative philosophy or an alternative treatment but also an alternative language. If we feel polluted, we are offered a \"cleanse.\" If we feel inadequate, lacking, we are offered a \"supplement.\" If we fear toxins, we are offered \"detoxification.\" If we fear that we are rusting with age, physically oxidizing, we are reassured with \"antioxidants.\" These are metaphors that address our base anxieties. And what the language of alternative medicine understands is that when we feel bad we want something unambiguously good.188 The beliefs about health and vaccines that naturalist antivaxxers and alternative medicine practitioners hold aren't based on science, and they don't seem to have been influenced by the scientific progress of the past three decades - whether that is germ theory, concepts of immunology or even the basic experimental and statistical principles on which modern biomedical sciences are based.189 They are promoters of a parallel, even counter culture of health whose basis is so far from rationality that discussion with them proves to be near impossible for allopathic health interveners.190 There is a danger in the medical establishment borrowing antivaxxers' language, such as when the WHO preaches the benefits of \"natural\" breastfeeding, because it unduly perpetuates the idea that nature is superior to technology and science, and that the separation between the two is clear.191 Biss continues: \"the use of natural as a synonym for good is almost certainly a product of our profound alienation from the natural world.\"192 Salvadori and Vignaud add that \"this optimistic vision of nature is forgetful of the fact that until the development of hygiene, antibiotics and vaccines, when our only defense against microbes and disease was nature, humanity's life expectancy was 25 years, a number that barely increased from the Paleolithic age until the Industrial Revolution.\"193 Infectious diseases were the first cause of mortality until Pasteur. Today, in the United States, the average life expectancy is 78 years, and many of the diseases responsible for most deaths of the past centuries have been eliminated or 27 eradicated - by vaccines. In the words of Salvadori and Vignaud, \"if children who are raised \"naturally\" do not contract measles despite being unvaccinated, it is because most of their playmates are.\"194 The case of anti-vaccination in Steiner-Waldorf schools is interesting to understand who tends to believe in such naturalist conceptions, and how those beliefs are reinforced within communities. This alternative education movement is based on ecology, the absence of constraints and free thought. The anthropologist Elisa Sobo, who published in 2015 a study of a Waldorf school in California, explains it this way: Waldorf pedagogy takes an ostensibly non-interventionist approach to learning, contending that academic skills emerge as a child is ready. The teacher's job, accordingly, is to scaffold and optimize this process rather than impart \"knowledge.\" To this end, Waldorf school environments are as \"natural\" as possible, with wood furnishings, organic comestibles, and no electronics. Waldorf pedagogy has its roots in anthroposophy, a holistic philosophy promoted by Waldorf education's founder, Rudolf Steiner (1861-1925).195 There is a social culture of vaccine delay and refusal in Californian Waldorf private alternative schools; Sobo notes that vastly disproportionate numbers of un- and under-vaccinated children attend these schools. In Californian Waldorf schools, the overall rate of personal belief exemptions is 57,2%, with some schools reaching a staggering 87%. Sobo also underscores notable post-enrollment refusal increases, which show the \"socially cultivated nature\" of vaccine refusal in these schools. Indeed, according to Sobo, the school acts as an incubator of anti-vaccination sentiments. Most Waldorf parents are highly educated, and they are dedicated to the well-being of their child. But the idea that vaccination is \"unnecessary, toxic, developmentally inappropriate, and profit driven\" has taken hold of Waldorf schools, a belief that has come to take a central place in the shared identity of this community. There are social mechanisms that forge and sustain a cultural norm that reinforces the group.196 In Waldorf schools: Findings indicated that institutionally supported skepticism regarding governmental and corporate interests and parents' community-promoted self-identity as independent thinkers funneled attention toward alternative information sources. Such sources - which supported talk of vaccine toxicity, ineffectiveness, needlessness (except to those with a profit motive), and developmental inappropriateness for small bodies - were more likely to be publicized within the school community via social networks than were mainstream scientific materials. This was because of community rules favoring alternative perspectives and stigmatizing conventional ones. Parents who vaccinated therefore remained silent about having done so, and information that was circulated never included pro-vaccine messages. Parents who perceived themselves as part of a special community with particular lifestyle expectations were reinforced socially for accepting and further disseminating what they learned from alternative sources. [...] This increased frequency of vaccine refusal, and the equation between non-vaccination, the independence of mind that it is taken to signify, and Waldorfian identity make it harder and harder to contravene the norm without threatening one's sense of group membership, or creating cognitive dissonance. Put another way, cultural cognition leads Waldorf parents to make vaccine choices that support locally normative understandings and thereby reinforce favored social ties.197 In Waldorf schools, anti-vaccination is thus the \"strong theory,\" wide-ranging, reductive displaces other ways of thinking\"198 - and contravention to the norm proves nearly impossible for 28 hesitant parents in these settings. The results of Sobo's study of Waldorf schools are nicely complemented by those of Reich, who studied geographic \"clusters\" of vaccine hesitant mothers: As mothers build networks with other sympathetic mothers, they gain information, alternative ways of understanding illness and health, and support for vaccine refusal. As both audience and expert, they share strategies for navigating mixed interactions. These networks may be local or they may be virtual, spanning huge distances, and may result from daily interaction, or contact that is more sporadic. Yet, they embrace norms of reciprocity that support their sense of themselves as enlightened and empowered customers. Social capital in this context can powerfully create and maintain subcultural norms that contradict broader social norms and provide sources of individual support for doing so.199 In another study, Poltorak et al found that vaccine decisions are based \"not on a singular deliberative calculus and the information and education that informs it, but on contingent and unfolding personal and social circumstances in an evolving engagement.\"200 Their research included multiple methods, including interviews with mothers that brought out the highly social nature of the decision not to vaccinate, which could be influenced \"by personal histories, by birth experiences and related feelings of control, by family health histories, by their readings of their child's health and particular strengths and vulnerabilities, by particular engagements with health services... and by friendships and conversations with others.\"201 Waldorf parents and \"geographically-clustered\" anti-vaccination mothers are part of a larger context where \"helicopter parenting\" and \"hockey mom\" behaviours are encouraged. This parenting trend praises over-investment of parents - mainly mothers - in the upbringing of children, and places on them the burden to make independent, thoughtful choices in areas as varied as education, nutrition, technology, and health. As explained by Reich, \"parents who reject vaccines do so from a cultural position in which they aim to be good parents who will optimize their children's health, even before birth.\"202 They \"accept they are ultimately responsible for children's health outcomes and take their choices seriously. As such, they prioritize their own values, perceptions, and beliefs over information communicated by experts.\"203 Benecke et al add that \"ideas about neoliberalism and skewed perceptions of feminist concepts of bodily autonomy and parental decision-making trump medical expertise.\"204 In this context, vaccine mandates emerge as a hurtful questioning of \"maternal instinct\" and of the care provided by the mother.205 Reich's findings suggest that upper-class women may oppose vaccination as a means for expressing independence. Larson agrees: The sentiment of feeling \"shut down\" from having a conversation about vaccine risks comes up again and again. It is a strong thread running through the arguments among vaccine-reluctant mothers who feel that they aren't - or weren't - vaccine skeptical until they felt their questions were being dismissed, their views being put down, which only fueled their suspicions of risks and of having the truth withheld. Meanwhile, many have sought out their own answers, come to their own conclusions, and are not willing to budge.206 According to Reich, \"vaccine resistance lies at the intersection of two ideologies: one that expects parents to intensively invest in their children and the other that calls for individuals to become savvy 29 consumers of technology and health interventions.\"207 She adds that \"well-off parents spend \"immense time and energy strategizing how to keep their children healthy while often ignoring the larger, harder-to-solve questions around them.\"208 Sobo agrees: \"Western culture today emphasizes active, informed health care consumerism, in which patients - and parents - are responsible for educating themselves so that they may make wise health care choices.\"209 The intersection of individualist parenting and savvy consumerism is a dangerous one, because understanding the importance of vaccination requires thinking beyond one's own interests and one's own child - a mentality with one foot in the grave in this era of \"individualist parenting.\" 1.3.2. Conspiracy Thinking and Lack of Trust In 2009, as fear of the H1N1 virus spread, so did conspiracy theories about its vaccine. For people inclined to conspiracy thinking, 2009 provided many red flags. First, the vaccine was developed quickly, which was seen as suspect.210 A second red flag was its adjuvant: squalene, which many people believed was toxic.211 When a vaccine without this adjuvant was developed, doubt became conviction.212 The World Health Organization (WHO) was denounced as opaque, and when the virus didn't turn out as deadly as the WHO had predicted, accusations flew that the organization had made up the threat for its own benefit.213 For the first time, the internet became the transmission channel of these theories, which gained unprecedented popularity.214 2009 became a turning point, a historic rupture: in France, the percentage of people who declared themselves favorable to vaccination dove from 90% to 61%.215 There is conspiracy thinking like this when it comes to vaccines, perhaps because vaccine science is hard to explain and many scientists and authorities just don't bother trying.216 The conspiracy theory that vaccines are just a way for governments and companies to get rich, at the peril of the population, has been around since the time of Edward Jenner.217 So has the theory that vaccines are used by colonizers to sterilize and/or annihilate indigenous populations, which then morphed into a more generally applicable theory that vaccines are tool of the dominant against the oppressed, colonialism aside.218 Conspiracy theorists have also argued that diseases were being fabricated by scientists (ostensibly for profit, too). The list goes on, often with a common thread: \"the primary driver, especially in the context of vaccines, seems to be a belief that a desire for profit is being placed ahead of the welfare of the people and the production of good research,\" writes health law and policy professor Timothy Caulfied.219 In fact, research suggests that openness to conspiracy thinking is one of, if not the best predictor of opposition to vaccines.220 A study on medical conspiracy thinking in the United States found that conspiracy thinking was correlated with avoidance of \"orthodox medicine\" and preference for alternative treatments.221 An Australian study concluded that there were four main reasons for vaccine refusal: reaction to a 30 deprivation of liberty, fear of needles and blood, individualistic worldview, and, in first position, propension to conspiracy thinking.222 Perhaps conspiracy thinking is popular because it seems to make sense. Theories about toxic adjuvants and vaccine risks and scamming scientists \"connect a priori unrelated facts and arguments into a convergence\" where \"everything is presented as logical, with airs of a reassuring rationality.\"223 This rationality is more easily accessible than that of scientists.224 Conspiracy theorists' arguments are neither verifiable nor refutable, so rational discussion proves powerless in efforts of persuasion.225 Those who try to argue with conspiracy theorists are quickly brushed off as naive.226 The fact that parents receive documents from the CDC abundantly detailing the risks of vaccines and explaining how to report adverse events to the VICP probably doesn't help, either.227 Fundamentally, conspiracy thinking is about power, and lack of trust in those who possess it. A 2014 study found that, regardless of political affiliation, distrust of vaccines was correlated with distrust of government.228 Conspiracy theorists are people who have lost trust in the elites of power - political, scientific, industrial - who are monolithic sources of cultural authority.229 Larson explains that: Public notions of being controlled, and a feeling of being denied voice and choice, have been the Achilles heel of immunization from its start. Some of these sentiments arise out of principle and others out of historic experiences of being controlled by authorities, thus instilling anxiety and distrust especially in the face of mass vaccination campaigns or mandates.230 She adds: \"Dignity is a fundamental rudder of humanity. Somehow, in the rush to vaccinate and protect \"the herd,\" respect for those feelings and beliefs has been compromised.\"231 Conspiracy thinking is a discourse; a way of participating, of having a foot in a game from which most are excluded. 1.3.3. Science, Bad Science and Pseudoscience Most Americans find science to be credible and scientists trustworthy.232 In fact, according to the 2012 General Social Survey, only military leaders elicit greater public confidence than the members of the scientific community.233 However, as Kahan, Scheufele and Jamieson point out, \"popular understanding of how scientists generate knowledge is freighted with misleading simplifications. The gap between how people think science works and how it actually does can itself generate confusion that undermines public confidence.\"234 Beyond religious and mystico-naturalist reasons for opposing vaccination, and beyond conspiracy theories, many antivaxxers rely on scientific arguments to make their case - or, rather, arguments that have the appearance of science. Salvadori and Vignaud write that: 31 By placing themselves on the same ground as researchers, vaccine developers or doctors, using the same words and the same methods (or so they believe), antivaxxers hope to gain credibility and influence the debate, even if at the risk of leaning on what they denigrate. The \"merchants of doubt\" seem to have little faith in scientific truth, but nevertheless feel an obligation to comply with the constraints of the methods of argumentation and demonstration of scientists and experts. Curves and graphs, supposedly without appeal, are seized by skeptics to demonstrate supposed causal links. It does not matter if the data put forward is incomplete or imprecise, the indicators irrelevant, and the parameters difficult to compare, or if concomitance is confused with causality: the illusion of method suffices.235 Antivaxxers who are attracted by the idea of having science on their side are aided by \"alternative experts\" who promote pseudoscientific theories, providing them with arguments that have an aura of science, even if completely bogus. Perhaps the best example is Robert Sears, or \"Dr Bob,\" who wrote The Vaccine Book, which proposes an alternative vaccination schedule.236 This book was a bestseller; it found its audience in the many parents who aren't opposed to vaccination but who fear that their children are getting too many vaccines over a short period of time. As Olga Khazan writes in The Atlantic, \"alternative schedules - vaccines spread out over a long period of time - are a common middle-ground between mainstream doctors and anti-vaxers.\" However, \"most medical organizations say they are unproven and risky, since children can still contract diseases while waiting to receive their shots.\"237 These antivaxxers are also aided by bad science - by fraud and dishonesty by members of the scientific community. Indeed, according to Salvadori and Vignaud, there is an increasing level of fraud in laboratories, which may be due to the publishing requirements that determine scientists' careers.238 The most infamous example of scientific fraud when it comes to vaccines is without a doubt the 1998 study led by the former physician Andrew Wakefield, published in the renowned journal The Lancet, which suggested a link between the MMR vaccine and autism. Although the published article stated that this causal association was not \"definitively proved,\" following publication, Wakefield embarked on a tour of self-promotion where he gave press conferences and recorded alarmist videos reiterating his results.239 The media coverage around this publication was frenzied, turning a hypothesis into a certitude. Vaccination rates dropped dramatically in England and the United States, which led to outbreaks of measles, mumps and rubella cases.240 In fact, Wakefield's article was a fraud - not an error of communication, or a case of misunderstanding by the public of scientific results, or a problem of accuracy or tone on the part of the media - just plain fraudulent.241 This came to light when other scientists were alarmed that they could not reproduce Wakefield's findings, an integral part of the scientific process.242 A journalist from the Sunday Times, Brian Deer, investigated; he found out that Wakefield had been paid more than $700,000 by a lawyer representing claimants in a class action suit against the manufacturer of the MMR vaccine, and that he had falsified his results to \"serve the cause.\"243 Moreover, Wakefield was in a conflict of interests, as he had just filed a patent for a new monovalent vaccine against measles that he had developed.244 32 The Wakefield affair prompted a boom of studies investigating the connection between the MMR vaccine and autism, which none found, including one from Denmark that involved more than 650,000 children.245 In 2011, the Institute of Medicine commissioned a report on the vaccine \"adverse events\". A committee of eighteen medical experts reviewed 12,000 studies and found no evidence of a link between the MMR vaccine and autism.246 Paul Offit, a vaccine expert and the chief of infectious diseases at Children's Hospital of Philadelphia who published \"Autism's False Prophets: Bad Science, Risky Medicine, and the Search for a Cure,\" sums it up this way: \"The question of whether vaccines cause autism is not the subject of any ongoing scientific debate.\"247 And yet, despite this scientific consensus, vaccination rates fell following the Wakefield controversy and, as Larson notes, in the UK, \"[i]t took nearly 15 years to recover MMR vaccine rates to where they were before the 1998 publication. Meanwhile, autism fears went global.\"248 A 2011 National Survey found that one in four Americans continue to believe in the risk of autism caused by vaccines.249 As Biss writes: Wakefield's study forwarded a hypothesis that was already in the air, a hypothesis that held particular appeal for women still haunted by the legacy of the refrigerator mother theory. Those who went on to use Wakefield's inconclusive work to support the notion that vaccines cause autism are not guilty of ignorance or science denial as they are guilty of using weak science as it has always been used - to lend false credibility to an idea that we want to believe for other reasons.250 In this context, refutation seems useless: \"Fears of vaccines do not seem easily quieted by an abundance of expert risk-benefit analyses assuring us that the good they do is far greater than the harm.\"251 Knowing how to interpret scientific results is difficult, and communicating them possibly even more so.252 Many have deplored the way in which the popular press sometimes presents vaccine controversies as if there is debate among experts.253 This can unduly give credence to anti-vaccination arguments that are rejected by the vast majority of experts.254 \"Both sides\" journalism when it comes to scientific findings, the quality of which can be judged by objective factors, seems misguided, and publication of untrustworthy science seems downright negligent. In an era of increasing academic specialization, fragmentation of knowledge, and fake news, the role of science journalists becomes that much more important.255 Unfortunately, that role is in decline.256 In On Immunity, Biss quotes the writer Maria Popova: We live in a media culture that warps seeds of scientific understanding into sensationalist, definitive headlines about the gene for obesity or the language of homosexuality and maps where, precisely, love or fear or the appreciation of Jane Austen is located in the brain - even though we know that it isn't the clinging to answers but the embracing of ignorance that drives science.257 Khazan adds that \"fact-checking often doesn't fit into increasingly tight media budgets, or isn't much of a priority, so dubious health claims about prolonged fasting or avoiding gluten ricochet around the internet.\"258 In this context, \"as news consumers increasingly seek out their own preferred sources, finding 33 reliable expert advice becomes a choose-your-own-adventure game.\"259 Today, opinion is forged on social media, where algorithms reinforce the cognitive biases of humans, such as the cherry-picking of information, confirmation bias, the tendency to favor the spectacular, and overestimation of one's own competence.260As explained by Larson in The Lancet: Complex determinants of vaccination, such as alternative health beliefs, politics, histories, trust, relationships, and emotions, contribute to the overall stagnation of childhood and adult vaccine uptake globally. Vaccine anxieties are not new, but the viral spread of concerns, reinforced by a quagmire of online misinformation, is increasingly connected and global. [...] The dissenting voices have become highly connected networks, undermining one of the most effective disease prevention tools.261 In Stuck, she writes that: Vaccine reluctance and refusal are not new, but the viral spread of doubt and questioning today travels at unprecedented speed and read, with many, many more vaccines and combinations of vaccines to question. Twitter handles or Facebook pages can be powerful influencers, and, while a resource for positive change, they have also been a platform for politicians, celebrities, and other opinion leaders to instill alternative views, questions, and sometimes purposeful misinformation about vaccines. Algorithms in the background ampliofy the scale and polarization of opinions while online translation tools with less than perfect translation - missing nuance and sometimes meaning - contribute to the confusion.262 She adds: The risk of digital wildfires in a hyperconnected world is particularly relevant to the growing constellations of vaccine skeptics and their impacts on global health. [...] Rumors, anxieties and fears can spread like wildfires, clustering around shared sentiments - making them look even more ubiquitous than they really are, and sometimes triggering behaviours that most individuals would not have dared on their own.263 In a 2019 article aiming to \"provide an overview of the major social, psychological, and technological factors\" that led to the recent resurgence of measles in the United States, Benecke and DeYoung examine the role of social media in spreading misinformation about vaccines.264 They write that \"[m]edical knowledge that was once held exclusively by medical professionals is now accessible to anyone and can be shared in posts that become 'viral.'\"265 They note that according to research, as many as 50% of tweets on vaccination contain anti-vaccination beliefs. Moreover, an analysis of YouTube videos found that 32% of videos on immunization opposed vaccination, and that these videos had higher ratings and more views than pro-vaccination ones. Another study found that, when searching on Google the terms \"vaccination\" and \"immunization\", 43% of the first 100 sites that appeared were anti-vaccination. It also seems, according to an experimental study, that spending only 5 to 10 minutes on an anti-vaccination website increases perceptions of vaccination risks, while decreasing perceptions of the risks of vaccine omission.266 A large part of the discussion around vaccines happens online, on the discussion boards of anti-vaccination websites. There, parents find a haven for expressing their worries, confirming their beliefs and sharing their stories. These parents and other anti-vaccination activists \"have relied on the profound power 34 of storytelling to infect an entire generation of parents with fear and doubt.\"267 At first glance, as Larson observes, these anti-vaccination websites often look harmless: ...these websites have become sophisticated in their choice of names and narratives, which make them sound very open and parent-friendly, intending to support \"informed decision-making,\" yet clearly having a strong bias against vaccines, which only becomes apparent after reading further down the pages and following the rabbit hole of hyperlinks.268 Furthermore, \"the widespread involvement of bots and malware promoted by foreign powers in online public health discourse is skewing discussions about vaccination. [...] This amplifies the misinformation that parents are exposed to, and it fuels the belief that the science behind vaccine efficacy and safety is still debatable.\"269 When it comes health, many individuals do see themselves as experts. In an article about \"The Baffling Rise of Goop\", Gwyneth Paltrow's alternative health empire, Khazan relays the stance of the editors at Goop: \"We chafe at the idea that we are not intelligent enough to read something and take what serves us, and leave what does not.\"270 Peter Beinart of The Atlantic spoke to Reich about this. He writes that: [S]tarting in the 1970s, alternative-health movements \"repositioned expertise as residing within the individual.\" This ethos has grown dramatically in the internet age, so much so that \"in arenas as diverse as medicine, mental health, law, education, business, and food, self-help or do-it-yourself movements encourage individuals to reject expert advice or follow it selectively.\" Autodidacticism can be valuable. But it's one thing to Google a food to see whether it's healthy. It's quite another to dismiss decades of studies on the benefits of vaccines because you've watched a couple of YouTube videos. In an interview, Reich told me that some anti-vaccine activists describe themselves as \"researchers,\" thus equating their scouring of the internet on behalf of their families with the work of scientists who publish in peer-reviewed journals.271 However, as Biss writes, \"[t]he idea that the customer is always right, imported to medicine, is a dangerous dictum.\"272 Research shows that \"public understanding of science is imperfect at best.\"273 In 2012, a survey of the National Science Board found that only 33% of a representative sample correctly answered questions about the scientific process such as, for example, questions about experimental design and probability. More research shows that people do not understand epidemiological risk factors, and that they have a skewed perception of their individual risk.274 Incomprehensibly, a 2011 survey by the University of Michigan found that 24% of parents expressed \"some trust\" in celebrities regarding the safety of vaccines.275 Meanwhile, many antivaxxers express distrust in their doctors. Literature abounds on the role that medical professionals play in the anti-vaccination debate. Among other research, a 2012 study led by researchers at Emory and Johns Hopkins suggested that parents who thought their doctors were reliable sources of information were less likely to engage on their own online research about vaccine safety.276 Reich points out that the problem is that pediatricians spend much less time with their patients than they used to: \"[c]hanging insurance companies' reimbursement practices to reward doctors for taking the time 35 to reassure patients that vaccines are safe could push vaccination rates back up.\"277 Benecke and DeYoung argue that \"[e]ffectively countering the anti-vaccine movement should be addressed through understanding mechanisms for increasing trust between the medical community and parents.\"278 Public health workers also have to adjust how they work if they want to effectively intervene. Harrison and Wu write that \"[p]ublic confidence in vaccination programs depends on the work they do for the community - social, political, and moral as well as biological. The concept of public health and its programs must be broader than the delivery of the vaccine technology itself.\"279 Biss eloquently concludes as follows: Science is, as scientists like to say, \"self-correcting,\" meaning that errors in preliminary studies are, ideally, revealed by subsequent studies. One of the primary principles of the scientific method is that the results of a study must be reproducible. Until the results of a small study are duplicated by a larger study, they are little more than a suggestion for further research. Most studies are not incredibly meaningful on their own, but gain or lose meaning from the work that has been done around them. And, as the medical researcher John Ioannidis has observed, \"most published research findings are false.\" The reasons for this are many, and include bias, study size, study design, and the very questions the researcher is asking. This does not mean that published research should be disregarded, but that, as Ioannidis concludes, \"What matters is the totality of the evidence.\" Thinking of our knowledge as a body suggests the harm that can be done when one part of that body is torn from its context. Quite a bit of this sort of dismemberment goes on in discussions about vaccination, where individual studies are often used to support positions or ideas that are not supported by the body as a whole. \"Any science may be likened to a river,\" proposes the biologist Carl Swanson. \"It has its obscure and unpretentious beginning; its quiet stretches as well as its rapids, its periods of drought as well as of fullness. It gathers momentum with the work of many investigators and as it is fed by other streams of thought; it is deepened and broadened by the concepts and generalizations that are gradually evolved.\" When one is investigating scientific evidence, one must consider the full body of information, or survey the full body of water. And if the body is large, this becomes an impossible task for one single person. A committee of eighteen medical experts took two years, for instance, to examine 12,000 peer-reviewed articles in order to prepare their 2011 report on vaccine side effects for the Institute of Medicine. [...] In addition to confirming the relative safety of vaccines, their report illustrated the kind of collaboration required to navigate the information now available to us. We do not know alone.280 Key Messages : Drivers of vaccine hesitancy and refusal There is no single profile of the antivaxxer. However, research shows that antivaxxers tend to be mothers who are, more often than not, white, college-educated, and with an above-average income level. Surveys have also shown that millennials are the most vaccine-skeptical age group. There is a large body of research on the different characteristics of individuals that are associated with anti-vaccination attitudes. Among these variables are political ideology and religion, which have both been found to be weak predictors of anti-vaccination attitudes. Vaccine decisions seem to be influenced by different, interrelated values and beliefs. Chief among these are a deep devotion to an idealized conception of \"nature\"; distrust in governments and elites, which is reflected in conspiracy thinking; and pseudoscientific claims about the necessity, efficacy, and safety of vaccines. 36 REFERENCES: CONTEXT 1 Jennifer A. Reich, Calling the Shots: Why Parents Reject Vaccines (New York: NYU Press, 2016), 23. 2 Fran\u00e7oise 2019), 15-16. 3 Reich, Calling the Shots, 24. 4 Reich, Calling the Shots, 24-25. 5 Eula Biss, On Immunity: Eula Biss, On Immunity, 51. 7 Eula Biss, On Immunity, 52. 8 Salvadori and Vignaud, Antivax, 40. 9 Salvadori and Vignaud, Antivax, 40. 10 Reich, Calling the Shots, 27. 11 Salvadori and Vignaud, Antivax, 63. 12 Salvadori and Vignaud, Antivax, 66. 13 Reich, Calling the Shots, 27. 14 Elizabeth Earl. \"The Victorian Anti-Vaccination Movement,\" The Atlantic. July 15, 2015. https://www.theatlantic.com/health/archive/2015/07/victorian-anti-vaccinators-personal-belief-exemption/398321/ (accessed 2020). 15 Salvadori and Vignaud, Antivax, 73. and Vignaud, Antivax, 80. 22 Michael Specter. \"Resistant,\" The New Yorker. May 23, 2011. https://www.newyorker.com/magazine/2011/05/30/resistant (accessed 2020). 23 Salvadori and Vignaud, Antivax, 79. Vignaud, Antivax, 81. 28 Elena Conis, \"The History of the Personal Belief Exemption,\" Pediatrics 146, 4 (2020): e20192551. 29 Heidi Larson, Stuck: How Vaccines Rumors Start - and Why They Don't Go Away (Oxford: Oxford University Press, 2020), 62-63. 30 Salvadori and Vignaud, Antivax, 83. 31 Salvadori Antivax, 84. 32 Specter, \"Resistant.\" 33 Specter, \"Resistant.\" 34 Larson, Stuck, 22. 35 Specter, \"Resistant.\" 36 Salvadori and Vignaud, Antivax, 80-81. 37 Reich, Calling the Shots, 29-30. 38 Reich, Calling the Shots, 30. 39 Salvadori and Vignaud, Antivax, 81. 40 Biss, On Immunity, 47. and Vignaud, Antivax, On Immunity, 92. 52 Salvadori Vignaud, Antivax, 144. 37 53 Salvadori 44. 54 Peter Beinart. \"What the Measles Epidemic Really Says About America, \" The Atlantic. August 2019. https://www.theatlantic.com/magazine/archive/2019/08/measles-as-metaphor/592756/ (accessed 2020). 55 Salvadori and Vignaud, Antivax, 145. the Measles Epidemic Really Says About America.\" 66 Reich, Calling the Shots, 49. 67 Salvadori and Vignaud, Antivax, 154. 68 the Vignaud, Antivax, 104. 72 Beinart, About America.\" 73 Salvadori and Vignaud, Antivax, 138, 151. 74 Reich, Calling the Shots, 52. 75 Jacoba Urist. \"How Schools Are Dealing With Anti-Vaccine Parents,\" The Atlantic, February 5, 2015. https://www.theatlantic.com/education/archive/2015/02/schools-may-solve-the-anti-vaccine-parenting-deadlock/385208/ (accessed 2020). 76 Conis, \"The History of the Personal Belief Exemption.\" 77 Biss, On Immunity, 95. 78 Emma Green. \"Anti-Vaxers Aren't Stupid,\" The Atlantic, February 16, 2016. https://www.theatlantic.com/health/archive/2016/02/anti-vaxers-arent-stupid/462864/ (accessed 2020). 79 Biss, On Immunity, 95. 80 Salvadori and Vignaud, Antivax, 167. Vignaud, Antivax, 167. 84 James Hamblin. \"Why The Government Pays Billions to People Who Claim Injury by Vaccines,\" The Atlantic, May 14, 2019. https://www.theatlantic.com/health/archive/2019/05/vaccine-safety-program/589354/ (accessed 2020). 85 Hamblin, \"Why the Government Pays Billions to People Who Claim Injury By Vaccines.\" ; Salvadori and Vignaud, Antivax, 168. 86 Hamblin, \"Why the Government Pays Billions to People Who Claim Injury By Vaccines.\" 87 Salvadori and Vignaud, Antivax, Antivax, 168. 89 Hamblin, \"Why the Government Pays Billions to People Who Claim Injury By Vaccines.\" 90 Hamblin, \"Why the Government Pays Billions to People Who Claim Injury By Vaccines.\" 91 Hamblin, \"Why the Government Pays Billions to People Who Claim Injury By Vaccines.\" 92 Salvadori and Vignaud, Antivax, 244. 93 Hamblin, \"Why the Government Pays Billions to People Who Claim Injury By Vaccines.\" 94 Hamblin, \"Why the Government Pays Billions to People Who Claim Injury By Vaccines.\" 95 Biss, On Immunity, 35. 96 Salvadori and Vignaud, Antivax, 244. 97 Reich, Calling the Shots, 64-66. 98 Centers for Disease Control and Prevention, \"Required Vaccines for Child Care and School,\" May 17, 2019. https://www.cdc.gov/vaccines/parents/records/schools.html (accessed 2020). 99 National Conference of State Legislatures, \"States With Religious and Philosophical Exemptions from School Immunization Requirements,\" June 26, 2020. https://www.ncsl.org/research/health/school-immunization-exemption-state-laws.aspx (accessed 2020) 100 Conis, \"The History of the Personal Exemption.\" and Mavis Biss, \"Are Anti-vaxxers Conscientious Objectors?\" The Atlantic, July 29, 2019. https://www.theatlantic.com/family/archive/2019/07/anti-vaxxers-measles-conscience-morals/594646/ (accessed 2020). 38 102 Maya J. Goldenberg, Vaccine Hesitancy: Public Trust, Expertise, and the War on Science (Pittsburgh: University of Pittsburgh Press, 2021), 111. 103 Heidi Larson, \"The state of vaccine confidence,\" The Lancet 392, 10161 (2018), 2244-2246, 2244. 104 Larson, Stuck, 66. 105 Saad B. Omer et al., \"Nonmedical Exemptions to School Immunization Requirements,\" The Journal of the American Medical Association 296, 14 (2006): 1757-1763. 106 and Measles Resurgence in the United States,\" Global Pediatric Health 6 (2019): 1-5. 107 Biss, On Immunity, 27. 108 Jacqueline K. Olive, Peter J. Hotez, Ashish Damania, and Melissa S. Nolan, \"Correction: The state of the antivaccine movement in the United States: A focused examination of nonmedical exemptions in states and counties,\" PLoS Med 15,7 (2018). 109 Olive et al., \"Correction: The state of the antivaccine movement in the United States: A focused examination of nonmedical exemptions in states and counties.\" 110 Olive et al, \"Correction: The state of the antivaccine movement in the United States: A focused examination of nonmedical exemptions in states and counties.\" 111 Hamblin, \"Why the Government Pays Billions to People Who Claim Injury By Vaccines.\" 112 Beinart, \"What the Measles Epidemic Really Says About America.\" 113 Goldenberg, Vaccine Hesitancy, 3-4. 114 Goldenberg, Vaccine Hesitancy, 4. 115 Goldenberg, Vaccine Hesitancy, 4. 116 Ranee Seither et al., \"Vaccination Coverage with Selected Vaccines and Exemption Rates Among Children in Kindergarten - United States, 2018-19 School Year,\" MMWR Morb Mortal Wkly 905-912. 117 Seither et al, \"Vaccination Coverage with Selected Vaccines and Exemption Rates Among Children in Kindergarten - United States, 2018-19 School Year.\" 118 Roxanne Nelson, \"US measles outbreak concentrated among unvaccinated children,\" The Lancet 19 (2019): 248. 119 Urist, \"How Schools Are Dealing With Anti-Vaccine Parents.\" 120 Allison Kempe et al., \"Parental Hesitancy About Routine Childhood and Influenza Vaccinations: A National Survey,\" Pediatrics 146, 1 (2020). 121 Dan M. Kahan, \"Protecting or Polluting the Science Communication Environment?: The Case of Childhood Vaccines,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 421-432, 426. 122 Kahan, \"Protecting or Polluting the Science Communication Environment?: The Case of Childhood Vaccines,\" 426. 123 Kahan, \"Protecting or Polluting the Science Communication Environment?: The Case of Childhood Vaccines\", 426. 124 Dan M. Kahan, \"A Risky Science Communication environment for Vaccines,\" Science 342, October 4 (2013), 53-54, 54. 125 Specter, \"Resistant.\" 126 Specter, \"Resistant.\" 127 Nelson, \"US measles outbreak concentrated among unvaccinated children.\" 128 Centers for Disease Control and Prevention, \"Measles Cases and Outbreaks,\" August 19, 2020. https://www.cdc.gov/measles/cases-outbreaks.html (accessed 2020) 129 Centers for Disease Control and Prevention, \"Measles Cases and Outbreaks.\" 130 Centers for Disease Control and Prevention, \"Measles Cases and Outbreaks.\" 131 Centers for Disease Control and Prevention, \"Measles Cases and Outbreaks.\" 132 Centers for Disease Control and Prevention, \"Measles Cases and Outbreaks.\" 133 Centers for Disease Control and Prevention, \"Measles Cases and Outbreaks.\" 134 Kathleen Hall Jamieson, \"The Need for a Science of Science Communication: Communicating Science's Values and Norms,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 15-25, 21. Measles About America.\" 136 Beinart, \"What the Measles Epidemic Really Says About America.\" 137 Conis, \"The History of the Personal Belief Exemption.\" 138 Larson, Stuck, 50. 139 Emily A. Harrison and Julia W. Wu, \"Vaccine confidence in the time of COVID-19,\" European Journal of Epidemiology, 35 (2020): 325-330, 325. 140 Roy Widdus and Heidi Larson, \"Vaccine mandates, public trust, and vaccine confidence: understanding perceptions is important,\" J Public Health Pol 39 (2018): 170-172, 171-172. 141 Larson, Stuck, xxxi. 142 Jennifer A. Reich, \"'We are fierce, independent thinkers and intelligent': Social capital and stigma management among mothers who refuse vaccines,\" Social Science & Medicine 257 (2020): 112015. 143 Larson, Stuck, 98. 39 144 Goldenberg, Vaccine Hesitancy, 7. 145 Cornelia Betsch, Robert B\u00f6hm, and Gretchen B. Chapman, \"Using Behavioral Insights to Increase Vaccination Policy Effectiveness,\" Policy Insights from the Behavioral and Brain Sciences 2, 1 (2015): 61-73. 146 Cornelia Betsch, Robert B\u00f6hm, and Gretchen B. Chapman, \"Using Behavioral Insights to Increase Vaccination Policy Effectiveness,\" Policy Insights from the Behavioral and Brain Sciences 2, 1 (2015): 61-73. 147 Antoine Devoir, April 8, 2019. https://www.ledevoir.com/opinion/idees/551654/anti-vaxxers-un-probleme-de-culture-scientifique-ou-politico-religieux (accessed 2020) 148 and Vignaud, Antivax, 192. 154 Savaldori and Vignaud, Antivax, 155 Larson, Stuck, 104. 156 193. 157 Benecke and and Vignaud, Antivax, 188. 160 Salvadori and Vignaud, Antivax, 161 Larson, Stuck, 107. 162 Savaldori and Vignaud, Antivax, 210. 163 Larson, Stuck, 104. 164 and Vignaud, Antivax, 197. 165 Savaldori and Vignaud, Antivax, 166 Larson, Stuck, 100. 167 and Vignaud, Antivax, 201. 168 Savaldori and Vignaud, Antivax, 210. 169 Jennifer A. Reich, \"Of natural bodies and antibodies: Parents' vaccine refusal and the dichotomies of natural and artificial,\" Social Science & Medicine 157 (2016): 103-110, 104. 170 Savaldori and Vignaud, Antivax, 210. 171 Jennifer A. Reich, \"Of natural bodies and antibodies: Parents' vaccine refusal and the dichotomies of natural and artificial,\" 104. 172 Jennifer A. Reich, \"Of natural bodies and antibodies: Parents' vaccine refusal and the dichotomies of natural and artificial,\" 103. 173 Savaldori and 216-217. Biss, \"The Illusion of 'Natural',\" The Atlantic, September 30, 2014. https://www.theatlantic.com/health/archive/2014/09/the-illusion-of-natural/380836/ (accessed 2020) 177 Savaldori and Vignaud, Antivax, 254. 178 Biss, On Immunity, 74-75. 179 Biss, On Immunity, 75. 180 Larson, Stuck, 39-40. 181 Larson, Stuck, 40. 182 Savaldori and Vignaud, Antivax, 183 Savaldori \"The Illusion 185 On Immunity, 75. 186 Biss, \"The Illusion of 'Natural'.\" 187 Reich, \"Of natural bodies and antibodies: Parents' vaccine refusal and the dichotomies of natural and artificial,\" 104. 188 Biss, On Immunity, 40. 189 Savaldori and Vignaud, Antivax, 197. 211-212. 195 Elisa J. Sobo, \"Social Cultivation of Vaccine Refusal and Delay among Waldorf (Steiner) School Parents,\" Medical Anthropology Quarterly 29, 3 (2015): 381-399, 384. 40 196 Sobo, \"Social Cultivation of Vaccine Refusal and Delay among Waldorf (Steiner) School Parents,\" 383. 197 Sobo, \"Social Cultivation of Vaccine Refusal and Delay among Waldorf (Steiner) School Parents,\" 393. 198 Biss, On Immunity, 38. 199 Reich, \"'We are fierce, independent thinkers and intelligent': Social capital and stigma management among mothers who refuse vaccines.\" 200 Sobo, \"Social Cultivation of Vaccine Refusal and Delay among Waldorf (Steiner) School Parents,\" 383. 201 Sobo, \"Social Cultivation of Vaccine Refusal and Delay among Waldorf (Steiner) School Parents,\" 383. 202 Reich, \"Of natural bodies and antibodies: Parents' vaccine refusal and the dichotomies of natural and artificial,\" 109. 203 Reich, \"Of natural bodies and antibodies: Parents' vaccine refusal and the dichotomies of natural and 109. 204 Benecke and DeYoung, \"Anti-Vaccine Decision-Making and Measles States,\" 2. 205 Savaldori and Vignaud, Antivax, 211. 206 Larson, Stuck, 99. 207 Reich, \"Of natural bodies and antibodies: Parents' vaccine refusal and the dichotomies of natural and artificial,\" 104. 208 Beinart, \"What Epidemic Really Says About America.\" 209 Sobo, \"Social Cultivation of Vaccine Refusal and Delay Waldorf (Steiner) School Parents.\" 210 Savaldori and Vignaud, and Vignaud, Antivax, 267. 219 Timothy Caulfied, The Vaccination Picture (Toronto : Viking, 2017), 77. 220 Beinart, \"What the Measles States,\" 3. 228 Beinart, \"What the Measles Epidemic Really Says About America.\" 229 Savaldori and Vignaud, Antivax, 270. 230 Larson, Stuck, 23-24. 231 Larson, Stuck, 28. 232 Dan M. Kahan, Dietram A. Scheufele, and Kathleen Hall Jamieson, \"Why Science Communication?\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 1-14, 4. 233 Dan M. Kahan, Dietram A. Scheufele, and Kathleen Hall Jamieson, \"Why Science Communication?\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 1-14, 4. 234 Dan M. Kahan, Dietram A. Scheufele, and Kathleen Hall Jamieson, \"Why Science Communication?\" Doctors,\" The Atlantic, January 2017. https://www.theatlantic.com/health/archive/2017/01/when-the-doctor-is-a-vaccine-skeptic/513383/ (accessed 2020) the Measles Epidemic Really Says About America.\" 246 Biss, On Immunity, 35. 247 Biss, On Immunity, 111-112. 248 Larson, Stuck, 38. 41 249 Savaldori and Vignaud, Antivax, 233. 250 Biss, On Immunity, 70. Biss, On Immunity, 35. 252 Savaldori and Vignaud, Antivax, 292. 253 Caulfied, The Vaccination Picture, 125. 254 Graham Dixon and Christopher Clarke, \"The effect of falsely balanced reporting of the autism-vaccine controversy on vaccine safety perceptions and behavioral intentions\" Health Education Research 28, 2 (2012): 352. 255 Olga Khazan, \"The Baffling Rise of Goop,\" The Atlantic, (accessed 2020) 259 Larson, of vaccine confidence,\" 2244-2245. 262 Larson, Stuck, xxii. 263 Larson, Stuck, 69. 264 Benecke and DeYoung, \"Anti-Vaccine Decision-Making and Measles Resurgence Benecke and DeYoung, \"Anti-Vaccine Decision-Making and Measles Benecke and DeYoung, \"Anti-Vaccine Decision-Making and Measles Benecke and DeYoung, \"Anti-Vaccine Decision-Making and Measles Resurgence in the 79. 269 Benecke and DeYoung, \"Anti-Vaccine of Goop.\" Epidemic Really Says About America.\" 272 Biss, On Immunity, 99. 273 Sobo, \"Social Cultivation of Vaccine Refusal and Delay among Waldorf (Steiner) School Parents,\" 382. 274 Sobo, \"Social Cultivation of Vaccine Refusal and Delay among Waldorf (Steiner) School Parents,\" 382. 275 Khazan, Says About America.\" 277 Beinart, \"What the Measles Epidemic and DeYoung, \"Anti-Vaccine Decision-Making and Measles Resurgence in the United States,\" 3. 279 Harrison and Wu, \"Vaccine confidence in the time of COVID-19,\" 326. 280 Biss, On Immunity, 142-143. 42 Chapter 2 - Conceptual Model and Research Question 2.1. Literature on the Effectiveness of Dissemination of Scientific Evidence to Change Behaviours There has been, for the better part of the past century, a growing awareness that research findings \"are not making their way into practice in a timely fashion.\"1 This gap between research and use by stakeholders, combined with increasing emphasis on the importance that programs, treatments and decisions be evidence-based, has led to a boom of research on \"finding ways to minimize what might be described as the knowledge-to-action (KTA) gap.\"2 Many different terms have been used to refer to some aspect of the KTA an article seeking to resolve the lack of clarity in this terminology, Graham et al. note that the most prominent term in Canada is \"knowledge translation\" (KT), although \"knowledge transfer\" is also commonly used, notably in fields other than health care.4 The Canadian Institute for Health Research defines \"knowledge translation\" as \"a dynamic and iterative process that includes synthesis, dissemination, exchange and ethically-sound application of knowledge.\"5 Graham et al. describe the primary purpose of KT as addressing \"the gap between what is known from research and knowledge synthesis and implementation of this knowledge by key stakeholders with the intention of improving health outcomes and efficiencies of the health care system.\"6 Dissemination and diffusion, in contrast, are more specific and do not account for the knowledge creation part of KT: \"They often refer to the promulgation of knowledge products to increase stakeholders' awareness of them or the specific and discrete strategies used to promulgate knowledge products.\"7 The CIHR identifies dissemination as one of four key elements in the KT process, along with synthesis, exchange, and ethically sound application of knowledge.8 Chapman et.al., in an article focusing on dissemination, note that it is a \"core strategy\" of KT that \"involves identifying the appropriate audience and tailoring the message and medium to the audience. Dissemination of health-related information is the active, tailored, and targeted distribution of information or interventions via determined channels using planned strategies to a specific public health or clinical practice audience, and has been characterized as a necessary but not sufficient antecedent of knowledge adoption and implementation.\"9 In the field of KT, \"knowledge\" refers mostly to scientific research, and \"key stakeholders\" refer first and foremost to clinicians or practitioners and policy- and decision-makers. Indeed, the vast majority 43 of research in the field of KT has been focused on interventions aimed at and processes involving health policy-makers and practitioners.10 The Knowledge Transfer Planning Guide from the Institute for Work & Health summarizes different mechanisms that can be used to transfer knowledge to these audiences. Citing research by Grimshaw, the Guide notes academic detailing and education outreach, interactive education sessions, reminder messages, and interventions tailored to overcome identified barriers tend to be effective, while audit and feedback, opinion leaders and patient-mediated intervention show variable effectiveness.11 Meanwhile, didactic lectures and education materials seem generally ineffective as stand-alone interventions.12 Much less has been published about the effectiveness of KT mechanisms aimed at the general public. Reviews have noted mixed results.13 Chapman et.al.'s 2020 systematic review analysed KT dissemination strategies with a focus on healthcare recipients. They included 44 studies describing the effectiveness of various strategies to disseminate health knowledge to the public, patients and caregivers. The interventions were categorized in a six-type typology developed by Health System Evidence14 for \"consumer targeted strategies.\" Among these six, three are related either to the facilitation of self-care or to participation in health systems decisions. The other three strategies concern information or education provision, behaviour change support and communication and decision-making facilitation. Overall, results of the review show that simple communication or information strategies are generally not effective and that the only interventions for which there is evidence of effectiveness are combined (multi-faceted), intensive and prolonged interventions.15 These results concur with those of a 2016 review of literature on evidence-informed decision-making, in which Langer, Tripney and Gough found that passive dissemination of evidence had no discernable impact on evidence use.16 Moreover, in a review of broader social science literature, the same authors found that while relevant, science communication generally brought about no evident effects.17 There is also a large body of research on interventions aimed specifically at promoting vaccination, as measured by mainly three outcomes: knowledge about vaccines or vaccine-preventable diseases, intention to vaccinate and vaccination behaviour. In an early review of evidence in 2000, Briss et al offered a taxonomy of these different interventions, and analysed the evidence on the effectiveness of these interventions, which include client reminder/recall, multicomponent interventions that include education, vaccination requirements for child care, school, and college attendance, community-wide education only, clinic-based education only, client or family incentives, and client-held medical records.18 The type of intervention of concern here is community-wide education. They defined such interventions as \"interventions [that] provide information to most or all of a target population in a geographic area,\" with a goal to \"improve the availability of information regarding vaccinations and increase knowledge,\" thereby changing behaviour.19 Educational messages can be delivered by various methods (e.g., mail, radio, 44 newspapers, television, and posters). Community-wide education can result in increases in vaccination coverage by increasing acceptance and demand for vaccinations among clients\" - although they found no convincing evidence, even then, of the effectiveness of these interventions.20 In 2013, Willis et.al. published another taxonomy of \"communication interventions\" that includes seven categories aimed at three target groups (parents, communities, and health care providers): inform or educate (what is of interest here); remind or recall; teach skills; provide support; facilitate decision making; enable communication; and community ownership.21 Evidence on simple information or education interventions suggest that these interventions, taken alone, are mostly ineffective at changing vaccination behaviour. Many studies have noted that while providing information or education may increase knowledge about vaccines, this new knowledge did not in turn lead to greater vaccine uptake.22 For example, Dempsey et al found that \"[p]roviding parents with a written information sheet about HPV did lead to improvement in their knowledge about HPV but did not result in substantial increases in HPV vaccine acceptability.\"23 In 2015, a large review of reviews by Dub\u00e9 et al. found that: Many traditional educational tools (e.g. information pamphlets) had little or no impact on vaccine hesitancy. Furthermore, some communication interventions could even reinforce vaccine hesitancy, as shown by a recent study by Nyhan et al. These researchers conducted a randomised controlled trial in the United States using four interventions to refute claims of a link between the measles, mumps and rubella (MMR) vaccine and autism, based on current public health communication. The study showed that none of the interventions significantly increased parental intention to vaccinate although it did reinforce the decision of those who were already intending to do so. Most importantly, these interventions decreased the intention to vaccinate among parents who had the least favourable attitudes towards vaccines. This highlights the importance of carefully designed public health messages, and that messages need to be tailored for the specific target group, because messaging that too strongly advocates vaccination may be counterproductive, reinforcing the hesitancy of those already hesitant.24 Nyhan also studied the effects of corrective information on the false belief that it is possible to contract the flu from the flu vaccine, and arrived at the same conclusion - corrective information significantly reduced intent to vaccinate among respondents who had a high level of concern about the side effects of vaccines.25 Other studies have found similar results.26 A 2015 systematic review by Harvey et. al. also found that effects of education interventions varied depending on income (a lower income predicting that educational interventions significantly increase childhood immunisation uptake).27 Moreover, they found that a direct discussion between parents and a professional expert had a greater effect on vaccine uptake than receiving information in written form.28 In 2017, a qualitative study seeking to understand the factors that influence mothers' confidence in vaccines assessed \"whether short, education materials affect parental confidence in childhood vaccinations,\" and found that \"[n]one of the videos or infographic posters used in the study clearly positively affected parents' confidence levels, nor were there any materials that resonated the same across groups.\"29 45 A distinct but related field of research, which has grown tremendously in the past few years but done so a bit in the margins of KT, is science communication, or rather, \"the science of science communication.\" This refers to \"an empirical approach to defining and understanding audiences, designing messages, mapping communication landscapes, and - most important - evaluating the effectiveness of communication efforts.\"30 In other words, the science of science communication seeks to \"systematically evaluate how scientists and others convey scientific information, how the public receives and interprets it, and the social and political aspects of these dynamics.\"31 Dan Kahan, Dietram A. Scheufele, and Kathleen Hall Jamieson observe that: Ironically, those communicating about science often rely on intuition rather than scientific inquiry not only to ascertain what effective messaging looks life but also to determine how to engage different audiences about emerging technologies and get science's voice heard. For decades, one plausible explanation for this state of affairs was the relative absence of empirical work in science communication. This is no longer a problem.32 Kahan, in an article published in Science in 2013, adds that: [T]he science of science communication that this body of work comprises can now be used not just to explain controversy over risk but also to predict, manage, and in theory avoid conditions likely to trigger it. [...] Evidence-informed risk communication strategies are essential to identify and counteract any influence that could cause ungrounded fears of vaccines to spread to the general population. Ironically, one such influence is empirically uninformed risk communication. [...] Empirically uninformed and counterproductive risk communication is the inevitable by-product of the absence of a systematic, evidence-based alternative. Decades of study show that the sources of public controversy over decision-relevant science are numerous and diverse. There is, however, a single factor that connects them: The failure of democratic societies to use scientific knowledge to protect the science communication environment from influences that prevent citizens from recognizing that decision-relevant science contributes to their well-being.33 In another paper, he further notes that substantial work has been done in this field \"cataloging recurring influences that can disrupt the processes the public uses to recognize valid decision-relevant science,\" but, unfortunately, \"[b]luntly stated, the public health establishment currently lacks either the institutions or the culture necessary to make use of this research.\"34 In sum, the bodies of evidence of KT and vaccination-specific studies suggest that interventions to promote vaccination that are based on passive, community-wide education are mostly ineffective in changing attitudes and behaviours in the long term; at the very least, they show mixed results. In addition to these research traditions, an emerging field of study, science communication, has done substantial empirical work filling in the gaps of KT by studying specifically communication interventions aimed at a general public. Research on science communication has highlighted the multitude of factors to be considered in such interventions. Despite this, actual interventions aimed at antivaxxers still seem based mostly on passive, community-wide education - specifically the type of intervention that KT, vaccine studies and science communication have shown to be ineffective. For example, Toronto Public Health launched in October 2019 an advertising campaign aimed at promoting vaccination consisting of videos of less than a minute 46 explaining why it's important to get immunized, from the perspective of children.35 Immunize Canada is a coalition of organizations whose members include a large number of medical organizations and public health agencies throughout Canada. According to its 2017 terms of reference, this organization contributes to the promotion of vaccination by \"collect[ing] and mak[ing] available accurate and credible information on vaccines,\" by \"maintain[ing] and increas[ing] public trust on immunizations by responding to inaccurate information on immunization with factual, evidence-based information\" and by \"engag[ing] the media in campaigns and messages to promote immunization.\"36 In the United States, the organization Family Medicine for America's Health started in 2016 a campaign for promoting vaccination where the main intervention was a patient handout (brochure) explaining basic facts about vaccines.37 Moreover, the American Academy of Pediatrics (AAP) launched a campaign where pediatricians explain, including through blog posts, why vaccination matters,38 although, to be fair, this was part of the CDC-initiated National Immunization Awareness Month (NIAM) in August, which includes multi-component interventions.39 Overall, though, a lot of efforts for the promotion of vaccination are still based on the communication of information and education, despite evidence that this is not an efficient way to change the opinion of vaccine-hesitant and -resistant individuals. Given the rise of anti-vaccination attitudes, it is alarming that better, evidence-based interventions are not more often utilized and it is essential that the large sum of money invested in the promotion of vaccination be used more efficiently. Developing a more complex and realistic model of intervention could contribute to improve concrete communication interventions aimed at antivaxxers. If such interventions were more effective, we might observe higher childhood vaccination rates, thereby protecting children from catching preventable diseases. Moreover, effective science communication matters beyond vaccination. As argued by Jamieson in her article \"The Need for a Science of Science Communication,\" science holds a privileged cultural status that \"vests its claims with special rhetorical force\" in public debates.40 By distinguishing itself from politics, it \"retains its privileged cultural status it has earned as a result of its commitment to knowledge-producing and -protecting norms and institutionalized structures that have over time generated reliable knowledge.\"41 When science communication interventions fail or even backfire, they put this privileged status in peril: \"the science itself is called into question and science communication is vulnerable to attack as veiled political communication,\"42 thus \"eroding the capacity of custodians of scientific knowledge [...] to ground debate.\"43 Science communication efforts, such as those aimed at antivaxxers, should be evidence-based, which implies taking into account the various factors that the evidence has shown to matter in these interventions. 47 2.2. Conceptual Model While vaccine refusal remains relatively rare, too many American parents still have anti-vaccination attitudes. The causes of this vaccine hesitancy have been thoroughly studied. Furthermore, many have attempted to fight against anti-vaccination attitudes by disseminating trustworthy scientific knowledge. Unfortunately, empirical work evaluating the effectiveness of these interventions suggests that these communication interventions often fail.44 Why? The aim of this study is to provide a multidisciplinary overview of why attempts at convincing with science are fraught with difficulties. It is particularly concerned not with how anti-vaccination attitudes are formed, but rather with why they are so hard to change with science. When confronted with scientific evidence, why do most antivaxxers tend to maintain their opinion? In other words, why do they resist? The passive, community-wide communication interventions mentioned above are based on a model of intervention which simply stipulates that the provision of knowledge should change antivaxxers' attitudes and behaviours. This is commonly known as the KAP model (knowledge, attitude, practice). In science communication, it has been called the \"knowledge deficit model,\" but the idea is the same. Goldenberg explains the knowledge deficit model this way: The \"knowledge deficit model,\" first identified by Brian Wynne (1991), presumes that expert forms of knowledge provide a sufficient basis for deciding the most important public policy questions. It follows that lay beliefs that run counter to this expert knowledge are unacceptable and must be corrected through education and public relation strategies. Those who disagree do so because they simpy do not understand the science.45 Key Messages : Literature on the effectiveness of dissemination of scientific evidence to change behaviours The fields of knowledge translation and the \"science of science communication\" have grown into impressive corpora of research on the best ways to ensure utilization of scientific knowledge. However, in comparison to research focused on utilization of scientific evidence by practitioners, clinicians, policy- and decision-makers, there has been very little research on knowledge translation aimed at a general public, such as the concerned, well-intended parents who make up the anti-vaccination movement. Research suggests that interventions based on passive, community-wide education and communication are mostly ineffective in changing attitudes and behaviors in the long-term. And yet, this is precisely the type of intervention that is used to try to persuade antivaxxers, to no avail. 48 In an article summarizing the development of the science of science communication, Akin and Scheufele add that: In its early years, scholars in this area of inquiry adhered - at least implicitly - to the idea that the primary goal of science communication is to raise the level of scientific literacy among nonexpert audiences. This view, often called the \"deficit model\" was widely embraced by bench scientists and cast science communication as a one-way process of diffusing scientific facts and findings (e.g., Batt 2008). [...] [T]he knowledge deficit model has strongly influenced past efforts to engage the public in science, despite the fact that such efforts showed minimal success. [...] The deficit model often carried with it the assumption that public disapproval or lack of support for science could be attributed to a shortage of public knowledge about the topic. Consistent with those assumptions, effective communication about science primarily involved conveying well-crafted information via skilled science communicators such as journalists or scientists themselves with the goal of building a more scientifically literate public that would also be more supportive of the scientific enterprise (Scheufele 2013; Nisbet and Scheufele 2009).46 This is not to say that researchers in the knowledge translation field have not developed other models of intervention. In fact, KT has borne many complex, nuanced, realistic and well-tested models to promote the effective utilization of scientific knowledge by different types of sophisticated actors, including political decision-makers, managers, practicioners, clinicians, etc.47 However, as previously noted, much less has been achieved in the way of the development of such a model when it comes to the general public.48 Even within the KAP framework, there are more sophisticated elaborations, such as Cutlip, Center & Broom (1993)49, Macnamara (199250, 199951 and 200252) and Lindenmann (1993).53 But even with this added complexity, the presumption remains that dissemination of information will lead to a change of opinion, which in turn will lead to behaviour change. But how will people come to change their opinion? Through which mechanisms will people change their opinion? The rational decision model, as summarized by Kahneman & Tversky54, Wyer & Srull55 56 and Heracleous,57 offers an answer. The mechanism through which information is supposed to change opinions is through a rational decision-making process. In other words, people, when faced with the decision to vaccinate or not vaccinate, should use the information provided, weigh the advantages and disadvantages of each of the alternatives, and come up with an analysis that clearly leads to the conclusion that vaccination is the superior alternative. When health workers, public health officials, government entities or the media disseminate scientific evidence in order to change antivaxxers' behaviour, the underlying assumption is that this indeed happens. Based on this literature, if we synthesize the main ideas of the various iterations of this KAP or knowledge deficit model, we can conceptualize attempts at convincing people through science like this [Figure 2]: 49 In this conceptual model or theory of change, boxes represent steps in the process leading from diffusion of scientific evidence to vaccination behaviour and arrows represent specific processes (involving various underlying mechanisms) leading from one box to the other. According to the model, information based on scientific evidence is disseminated through various channels. A certain proportion of the target population will be reached by the information (coverage). An even smaller proportion will have the tools necessary in order to understand and make sense of this information. We would then expect individuals to engage in a rational decision-making process, comparing the costs and benefits of two alternatives (vaccination and non-vaccination). Since this analysis based on current and sound scientific evidence should inevitably favour vaccination, the results of this analysis should be that individuals perceive vaccination as a clearly superior (in terms of respective costs and benefits) alternative. Consequently, individuals should develop positive attitudes towards vaccination which would lead to their intent to undergo vaccination, and subsequent vaccination behaviour. 2.3. Research Question What I call \"resistance\" is the failure of this theory of intervention, as evidenced by the data of Chapter 1.2 and the abundant literature cited in Chapter 2.1. Where does this causal chain break? In more practical terms, why do interventions relying on the dissemination of sound scientific evidence fail to change the behaviour of antivaxxers? My objective is to identify and summarize, in a transdisciplinary manner, streams of literature that have provided answers to this question. In other words, I want to delve into research traditions that have studied the question of resistance to science in one way or another, and try to integrate their overarching theories without being bound by disciplinary variations in methods, vocabulary, concepts, etc. The above conceptual model will be updated throughout the text to show how these streams of literature conceptualize the chain of events that happens when scientific evidence is disseminated, and the important variables that may come into play. There is no clearcut answer to my research question; rather, its purpose is to steer a reflection on the mechanisms behind resistance to science, polarization, and effective communication. Figure 2. - The KAP or knowledge deficit model of diffusion of scientific evidence 50 Akin and Scheufele write that \"[t]he nature of many contemporary science issues makes understanding the dispositional mechanisms that guide public viewpoints increasingly salient.\"58 I seek to answer that call and contribute to the growing body of research on the science of science communication. Research Question Why do interventions relying on the dissemination of sound scientific evidence fail to change the behaviour of antivaxxers? 51 REFERENCES: CONCEPTUAL MODEL AND RESEARCH QUESTION1 Ian D. Graham et al., \"Lost in Knowledge Translation: Time for a Map?\" The Journal of Continuing Education in the Health Professions, 26 (2006): 13-24, 14. 2 Graham, \"Lost in Knowledge Translation: Time for a Map?\", 14. 3 Graham, \"Lost in Knowledge Translation: Time for a Map?\", 14. 4 Graham, \"Lost in Knowledge Translation: Time for a Map?\", 14-16. 5 Sharon E. Straus, Jacqueline Tetroe, Ian D. Graham, and Eman Leung, \"Section 1.1 Knowledge to action: what it is and what it isn't,\" Canadian Institutes of Health Research, August 8, 2010. https://cihr-irsc.gc.ca/e/41928.html (accessed 2020) 6 Graham, \"Lost in Knowledge Translation: Time for a Map?\", 14. 7 Graham, \"Lost in Knowledge Translation: Time for a Map?\", 17. 8 Evelina Chapman et al., \"Knowledge translation strategies for dissemination with a focus on healthcare recipients: an overview of systematic reviews,\" Implementation Science 15:14 (2020), 2. 9 Chapman et al., \"Knowledge translation strategies for dissemination with a focus on healthcare recipients: an overview of systematic reviews,\" 2. 10 See, for example: Mitchell N. Sarkies, Kelly-Ann Bowles, Elizabeth H. Skinner, Romi Haas, Haylee Lane, and Terry P. Haines, \"The effectiveness of research implementation strategies for promoting evidence-informed policy and management decisions in healthcare: a systematic review,\" Implementation Science 12, 132 (2017). 11 Rhoda Reardon, John Lavis, and Jane Gibson, \"From Research to Practice: A Knowledge Transfer Planning Guide,\" Institute for Work & Health (2006) 6-7. 12 Reardon, Lavis, and Gibson, \"From Research to Practice: A Knowledge Transfer Planning Guide,\" 8. 13 See for example: Langer et al, The Science of Using Science: Researching the Use of Research Evidence in Decision-Making; Breckon and Dodson, \"Using Evidence: What Works?\" 14 John N. Lavis et al., \"Developing and refining the methods for a 'one-stop shop' for research evidence about health systems,\" Health Research Policy and Systems 13, 10 (2015). 15 Chapman et al., \"Knowledge translation strategies for dissemination with a focus on healthcare recipients: an overview of systematic reviews,\" 10. 16 Laurenz Langer, Janice Tripney, and David Gough, The Science of Using Science: Researching the Use of Research Evidence in Decision-Making (London: EPPI-Centre, Social Science Research Unit, UCL Institute of Education, University College London, 2016): 28. 17 Langer et al, The Science of Using Science: Researching the Use of Research Evidence in Decision-Making, 28. 18 Peter A. Briss et al., \"Reviews of Evidence Regarding Interventions to Improve Vaccination Coverage in Children, Adolescents, and Adults,\" American Journal of Preventive Medicine 18, 1S (2000): 97-140. 19 Briss et al., \"Reviews of Evidence Regarding Interventions to Improve Vaccination Coverage in Children, Adolescents, and Adults,\" 104. 20 Briss et al., \"Reviews of Evidence Regarding Interventions to Improve Vaccination Coverage in Children, Adolescents, and Adults,\" 104. 21 Natalie Willis et al., \"\"Communicate to vaccinate\": the development of a taxonomy of communication interventions to improve routine childhood vaccination,\" BMC International Health and Human Rights 13:23 (2013), 10. 22 Brendan Nyhan and Jason Reifler, \"Does correcting myths about the flu vaccine work? An experimental evaluation of the effects of corrective information,\" Vaccine 33 (2015): 459-464. 23 Amanda F. Dempsey, Gregory D. Zimet, Robert L. Davis, and Laura Koutsky, \"Factors That Are Associated With Parental Acceptance of Human Papillomavirus Vaccines: A Randomized Intervention Study of Written Information About HPV,\" Pediatrics 117, 5 (May 2006): 1486-1493, 1486. 24 Eve Dub\u00e9, Dominique Gagnon, Noni E. MacDonald and the SAGE Working Group on Vaccine Hesitancy, \"Strategies intended to address vaccine hesitancy: Review of published reviews,\" Vaccine 33 (2015): 4191-4203, 4200. 25 Nyhan and Reifler, \"Does correcting myths about the flu vaccine work? An experimental evaluation of the effects of corrective information.\" 26 Timothy Caulfied, The Vaccination Picture (Toronto: Viking, 2017), Sara Pluviano, Watt, and Sergio lingers in memory: Failure of three pro-vaccination strategies,\" PLoS ONE 12, 7 (2017): e0181640. 27 Hannah Harvey, Nadja Reissland, and James Mason, \"Parental reminder, recall and educational interventions to improve early childhood immunisation uptake: A systematic review and meta-analysis,\" Vaccine 33 (2015): 2862-2880. 28 Harvey, Reissland, and Mason, \"Parental reminder, recall and educational interventions to improve early childhood immunisation uptake: A systematic review and meta-analysis.\" 29 Judith A. Mendel-Van Alstyne, Glen J. Nowak, Ann L. Aikin, \"What is 'confidence' and what could affect it?: A qualitative study of mothers who are hesitant about vaccines,\" Vaccine 36 (2018): 6464-6472, 6468. 30 Dan M. Kahan, Dietram A. Scheufele, and Kathleen Hall Jamieson, \"Why Science Communication?\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 1-14, Heather Akin and Dietram A. Scheufele, \"Overview of the Science of Science Communication,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 25-34, 25. 32 Kahan, Scheufele, and Jamieson, \"Why Science Communication?\", 1. 33 Dan M. Kahan, \"A Risky Science Communication environment for Vaccines,\" Science 342, October 4 (2013): 53-54, 54. 34 Dan M. Kahan, \"Protecting or Polluting the Science Communication Environment?: The Case of Childhood Vaccines,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 421-432, 421. 35 The Canadian Press, \"Toronto Public Health launches advertising campaign aimed at promoting vaccination,\" Global News, October 7, 2019. https://globalnews.ca/news/6002457/toronto-public-health-vaccination-advertisement/ (accessed 2020) 36 Immunize Canada, \"Immunize Canada: Term of Reference,\" June 15, 2017. https://immunize.ca/sites/default/files/Resource%20and%20Product%20Uploads%20(PDFs)/Immunize%20Canada/Terms%20of%20Reference/2017/Immunize%20Canada%20ToR%20June%202017.pdf (accessed 2020) 37 American Academy of Family Physicians. News story now unavailable, previously accessed in 2020 at: https://www.aafp.org/news/family-medicine-americas-health/20160812hip-immunizations.html 38 American Academy of Pediatrics, \"Immunization Campaigns: National Immunization Awareness Month.\" https://www.aap.org/en-us/about-the-aap/aap-press-room/campaigns/Pages/NIIW.aspx (accessed 2020) 39 Centers for Disease Control, \"National Immunization Awareness Month,\" July 13, 2020. https://www.cdc.gov/vaccines/events/niam/index.html (accessed 2020) 40 Kathleen Hall Jamieson, \"The Need for a Science of Science Communication: Communicating Science's Values and Norms,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 15-25, 15. 41 Jamieson, \"The Need for a Science of Science Communication: Communicating Science's Values and Norms,\" 17. 42 Jamieson, \"The Need for a Science of Science Communication: Communicating Science's Values and Norms,\" 18. 43 Jamieson, \"The Need for a Science of Science Communication: Communicating Science's Values and Norms,\" 22. 44 Jonathan Breckon and Jane Dodson, \"Using Evidence: What Works?\", Alliance for Useful Evidence (2016): 12; Langer et al., The Science of Using Science: Researching the Use of Research Evidence in Decision-Making, 28. 45 Maya J. Goldenberg, Vaccine Hesitancy: Public Trust, Expertise, and the War on Science (Pittsburgh: University of Pittsburgh Press, 2021), 39. 46 Akin and Scheufele, \"Overview of the Science of Science Communication,\" 25. 47 Graham, \"Lost in Knowledge Translation: Time for a Map?\" 48 Chapman et al., \"Knowledge translation strategies for dissemination with a focus on healthcare recipients: an overview of systematic reviews.\" 49 Scott M. Cutlip, Allen H. Center, and Glen M. Broom, Effective public relations (6th ed.) (Englewood Cliffs, NJ: Prentice-Hall, 1985). 50 Jim Macnamara, \"Evaluation: The Achilles Heel of the public relations profession,\" International Public Relations Review 15, 4 (1992): 19. 51 Jim Macnamara, \"Research in public relations: A review of the use of evaluation and formative research,\" Asia Pacific Public Relations Journal 1, 2 (1999): 107-133. 52 Jim Macnamara, \"Research and evaluation,\" in C. Tymson & P. Lazar, The New Australian and New Zealand Public Relations Manual (Sydney: Tymson Communications, 2002) 100-134. 53 Walter K. Lindenmann, \"An 'Effectiveness Yardstick' to measure public relations success,\" PR Quarterly 38, 1 (1993): 7-9. 54 Daniel Kahneman and Amos Tversky, \"Prospect Theory: An Analysis of Decision under Risk,\" Econometrica 47, 2 (March 1979): 263-292. 55 Robert S. Wyer, Jr., and Thomas K. Srull, \"The processing of social stimulus information: A conceptual integration,\" in Person memory: The cognitive basis of social R. Hastie, Thomas K. Srull, \"Human Cognition in Its Social Context,\" Psychological 322-359. 57 Loizos Th. Heracleous, \"Myth or Reality?\" Management 7, 4 (1994): 16-23. 58 Akin and Scheufele, \"Overview of the Science of Science Communication,\" 31. 53 Chapter 3 - Method For this review, I asked myself a tough question: why do interventions relying on the dissemination of sound scientific evidence fail to change the behaviour of antivaxxers? In a way, I might as well have asked myself: why do Democrats and Republicans disagree? Why do people lie? What is a decision based on? According to Schumacher, there are two types of problems in the world.1 Convergent problems are those that can be solved; whether these convergent problems are simple or complicated, we can study them in a rigorous and precise way and come to a single, acceptable solution. Divergent problems are different: the more we study them, the more their complexity becomes evident, and the harder it becomes to offer up a clear solution. Instead, the solutions that are proposed for divergent problems are often multidimensional and sometimes contradictory. The question of why some people aren't persuaded by dissemination of sound scientific evidence is a clear example of a divergent problem. As the literature discussed in Chapter 2 shows, there are many different perspectives on the subject and many different solutions. Simplistic and unidimensional interventions have proven to be ineffective at tackling the issue. A variety of review methodologies have been utilized to aggregate and integrate evidence on divergent problems like this one, but I'm not sure that there is a clear-cut answer to such a broad question, and pretending that I could provide one was never my goal. The question I asked myself was meant to orient a reflection on the mechanisms behind resistance to science, polarization, and effective communication. I wanted to look into which research traditions had analysed this question, and try to integrate, in a transdisciplinary manner, their overarching theories. In developing my methodology, I was first inspired by the approach of Edgar Morin. Morin is a philosopher and sociologist who has written extensively about complexity and complex thought, notably in his magnum opus La M\u00e9thode. Morin, while recognizing the important role that academic disciplines played in the development of science, criticizes their rigidity today. Morin argues that when different disciplines examine the same problem, they each provide outlooks and explanations that, while interesting, are incomplete, fragmented, and insufficient to understand the whole of the problem. The evidence that each discipline provides, if taken alone, is too specific and partial to come close to Truth or Reality. Morin writes that such knowledge has accumulated \"in increasingly narrow and closed disciplinary cavities\" (\"alv\u00e9oles\").2 Academic disciplines compartmentalize knowledge: \"The dominant methodology produces an increased obscurantism, since there is no longer any association between the disjointed elements of knowledge, no way to engram and to think them.\"3 54 According to Morin, the accumulation of knowledge has happened in \"the paradigm of simplicity\", which is a paradigm of disjunction and reduction.4 Morin's call is to accumulate knowledge in a \"paradigm of complexity\" based on distinction, conjunction, and implication, with a \"transdisciplinary\" or \"non-disciplinary\" approach.5 Morin's transdisciplinary M\u00e9thode is a fundamental overhaul of dominant paradigms; while Morin has written thousands of pages on the subject, his work remains opaque. Morin defines \"principles\" to guide reflection: the dialogic principle (\"principe dialogique\"), according to which thinkers should embrace duality within unity, complementarity coexisting with antagonism;6 the organizational recursion principle (\"principe de r\u00e9cursion organisationnelle\"), which stipulates that effects are also causes of what produces them;7 and the hologrammatic principle (\"principle hologrammatique\"), which states that the part is in the whole, and the whole in the part.8 However, beyond such abstract principles, Morin does not provide a cl\u00e9-en-main methodology for researchers like me. So, with Morin's principles I mind, my attention turned to a methodology developed by Trisha Greenhalgh and her colleagues: meta-narrative systematic reviewing. A systematic review, according to Greenhalgh, is \"a literature review undertaken according to an explicit, rigorous and transparent method.\"9 There are many established approaches to producing such reviews, but many of these pose challenges when it comes to making sense of complex evidence about divergent problems, evidence that is often vast and heterogeneous.10 For example, about the research mandate which led her to develop the meta-narrative approach, Greenhalgh writes that: \"An important early finding of our research was the impossibility of sorting the primary studies into a single theoretical taxonomy. Fewer than 20% of studies had an explicit theoretical basis, and [...] there was no unifying principle. There was also a highly inconsistent approach to research design.\"11 Research on a specific question \"waxe[s] and wane[s] within different scientific communities at different times.\"12 The meta-narrative approach draws on Kuhn's concepts of scientific paradigms and scientific revolutions, which he developed in his 1962 book The Structure of Scientific Revolutions.13 According to Kuhn, scientific progress happens according to a predictable pattern: \"a creative, exploratory pre-paradigmatic phase; a paradigmatic phase in which data are steadily gathered using agreed methods and instruments (and explained using an accepted body of jargon); and a decline phase in which anomalies begin to appear in the collected data which demand new concepts and theoretical models to explain them fully, thus setting the stage for scientific revolution.\"14 In a meta-narrative review, the initial unit of analysis is \"the unfolding 'storyline' of a research tradition over time.\"15 Conducting a meta-narrative review involves mapping these storylines in order to \"trace the influence of seminal theoretical and empirical work on subsequent research within a tradition.\"16 According to Greenhalgh, in this search and mapping phase, researchers ask themselves the following 55 questions: What are the parameters of the research tradition, that is, its scope, historical roots, key concepts and assumptions, and theoretical basis? What research questions, and in what priority, have researchers in this tradition asked about a specific topic, and what methods and instruments have they favoured? What are the principal empirical findings from the quality literature in this research tradition? How have earlier findings led to refinements in the theory, design, and/or direction of the empirical work? And finally, what are the strengths and limitations of this research tradition, and what weight should it be given compared to other research traditions on the same topic?17 A list of \"key meta-narratives\" emerges from this phase, and researchers can then identify the authors and writings that are considered seminal influences in each research tradition.18 These seminal sources, in turn, provide researchers the \"unwritten rules\" of the paradigm: \"core concepts, theoretical models, and preferred methods and instruments.\"19 More papers having cited these seminal sources are identified through manual and electronic snowballing, and appraised based on the quality criteria set out in the seminal sources (often in book chapters).20 Finally, in the synthesis phase, the goal is to, first, \"identify all the key dimensions of the problem that have been researched\"; second, \"taking each dimension in turn, [to] give a narrative account of the contribution (if any) made to it by each separate tradition\"; and third, to \"treat conflicting findings as higher-order data and explain them in terms of contestation between the different paradigms from which the data were generated.\"21 Like Morin, Greenhalgh is thus preoccupied with how knowledge accumulated within disciplinary paradigms is too rarely integrated. Also like Morin, Greenhalgh stresses the importance of adhering to certain general principles when conducting a meta-narrative review. The first is pragmatism: Because of the amorphous and unsorted nature of the literature in the early stages of the review, 'what to include' is not self-evident, nor can this question be resolved by reference to a checklist or set of standards.22 The second is pluralism: The challenge is to expose the tensions, map the diversity and communicate the complexity of how the various different traditions contribute to an understanding of the problem as a whole.23 The third is historicity: The defining characteristic of a narrative is the sequencing of events in time in such a way that a 'plot' emerges, in which key scientific discoveries and insights lead to further work that adds pieces to an agreed jigsaw or, less commonly, to work that shakes the foundations of the prevailing paradigm. [...] [I]t could be argued that the structured reporting format that strips individual studies bare of their historical and social context is what makes conventional systematic reviews so indigestible that few people read them.24 The fourth is contestation: Heterogeneity of research questions, methods, results and conclusions is itself data. Contestation between research traditions allows the researcher to move from simple description (and lamentation that studies are 'conflicting') to higher-level interpretation that uses similar principles to those applied to the analysis of contradictions and 'disconfirming cases' in primary qualitative research (Denzin et al, 1994). The goal of the 56 synthesis phase of meta-narrative review is to find epistemological (and indeed pragmatic and realistic) explanations for differences in findings and recommendations made by researchers from different traditions, thereby adding to the richness of the overall picture. [...] meta-narrative review explicitly seeks to expose and unpack the 'incommensurabilities' that underpin conflicting data.25 The fifth is peer review: Where the research field is highly complex and the methods emergent rather than predefined, peer review is especially important, and must be formative (i.e. intended to feed into the research process) rather than summative (i.e. intended to judge its outputs). [...] [The authors] sought continually to test our emerging findings against the judgement of others using a formal external review group and informal discussion with colleagues outside the project team.26 However, as I was forced to recognize the opacity of Morin's work, I was also forced to recognize the challenges that Greenhalgh's approach presents for a lone Master's student in the midst of her first real research effort: conducting a rigorous meta-narrative systematic review is time-, cost-, and resource-intensive. Properly searching, mapping, appraising, and synthesizing hundreds of articles on such a complex question is beyond what can be expected of an aspiring researcher like me. I thus decided to conduct a more iterative, non-systematic review of the literature on this topic, while adhering to the principles of Morin and of meta-narrative reviewing. The transdisciplinary nature of this problem made it challenging to rely on a keyword strategy to search for literature, because different research traditions have explored this question using different vocabulary and conceptualizations. For example, as all keywords that have been used to describe the kind of interventions that I refer to in my research question. I thus adopted a more iterative search strategy, in accordance with the pragmatism principle. Through readings and discussions with experts, I identified research traditions that have examined my question. The result was a \"heuristic list\" of traditions, or \"key meta-narratives\": literature on knowledge transfer; the science of science communication; work on scientific literacy; organizational theory literature on decision-making; empirical work on cognitive biases and heuristics and risk perception, notably in cognitive psychology and behavioural economics; social psychology, including work on conformity; political science literature on polarization and echo chambers; network studies on the diffusion of information; interdisciplinary work on fake news and conspiracy theories; and literature on public communication campaigns. I read syntheses, mostly books and encyclopaedias entries, to identify the seminal authors who have made a core conceptual or empirical contribution to the understanding of my research question. I was looking for the authors who started a scientific revolution in the sense of Kuhn. This was an iterative process which closely resembled the one described by Greenhalgh for meta-narrative systematic reviews. These seminal authors were selected because their work was impactful in the research tradition. One way to assess 57 this was by how many times their work was cited according to Web of Science. Another way was that, often, other authors in the research tradition would, in their books or journal articles, clearly state that these authors were seminal. There was no restriction on the year of publication of the work, but all of this work had to be published in either English or French. In a meta-narrative review, the identification of seminal work would be a jumping-off point for subsequent steps: more authors would be identified on the basis of having cited the seminal work, and inclusion of studies would be judged based on the quality criteria set out in the seminal work. I took a different path: since my goal was not to provide an exhaustive summary of each, but rather an overview, I interpreted the seminal work to be representative of the research tradition and only snowballed citations in order to identify other seminal authors. Based on these seminal works, I grouped my heuristic list of research traditions into three categories, or views. What distinguishes these categories is their general explanation of why interventions based on simple dissemination of scientific evidence fail - or, in other words, where the chain of the KAP or knowledge-deficit model is broken, and by which variables. The first view is that resistance to scientific evidence can be explained by a lack of information and a lack of understanding. The answer thus lies at the beginning of the intervention model, at the coverage and understanding phases. The second view is that resistance to scientific evidence can be explained by a slew of cognitive biases and heuristics that skew judgment. The answer thus lies in the risk perception phase. The third view is that the crux of the matter is not individual reasoning but culture: resistance to scientific evidence can be explained by adherence to the values of one's idealized cultural way of life, which matters more than knowledge, understanding, or reasoning. The answer thus lies in the attitudes phase. My results (in the next section) are presented according to these three categories. For each of these views, I provided a chronological, historical summary of the seminal literature in the different research traditions that adhere to one of the views (in accordance with the historicity principle). This corresponds to the synthesis phase of Greenhalgh's meta-narrative review methodology. I wanted to highlight the ways in which these different streams of literature interact, how they agree and disagree, and on what they focus. Finally, the intervention model was updated for each research tradition in order to visually represent how they conceptualize differently the problem of resistance to science. Such an approach to synthesis is in accordance with the pluralism and contestation principles of meta-narrative reviewing. Overall, I relied on 39 articles or books for Chapter 1 (Context), 35 for Chapter 2 (Conceptual Model and Research Question), 17 for Chapter 3 (Method), 32 for Chapter 4.1 (The Knowledge Deficit Model and Scientific Literacy), 28 for Chapter 4.2 (The Psychological Approach), and 15 for Chapter 4.3 (The Cultural Theory of Risk and Cultural Cognition). 58 59 REFERENCES: METHOD1 E.F. Schumacher, A Guide for the Perplexed (New York: Harper Perennial, 1977). 2 Edgar Morin, Introduction \u00e0 la pens\u00e9e complexe (Prague: \u00c9ditions Od\u00e9on, 1974), (my translation) 3 Morin, Introduction \u00e0 la pens\u00e9e complexe, 20. (my translation) 4 Morin, Introduction \u00e0 la pens\u00e9e complexe, 79. 5 Morin, Introduction \u00e0 la Morin, Introduction \u00e0 la Morin, Introduction \u00e0 la pens\u00e9e complexe, 99. 8 Morin, Introduction \u00e0 la pens\u00e9e complexe, 137. 9 Trisha Greenhalgh, Glenn Robert, Fraser Macfarlane, Paul Bate, Olympia Kyriakidou, and Richard Peacock, \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" Social Science & Medicine 61 (2005): 417-430, 418. 10 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 417. 11 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 418. 12 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 419. 13 Thomas Kuhn, The Structure of Scientific Revolution (Chicago: Chicago University Press, 1962). 14 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 418-419. 15 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 417. 16 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 417. 17 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 420-421. 18 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 421. 19 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 421. 20 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 421. 21 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 420. 22 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 427. 23 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 427. 24 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 427. 25 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 428. 26 Greenhalgh et al., \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" 428. 60 Chapter 4 - Results 4.1. The Knowledge Deficit Model and Scientific Literacy In Chapter 2, I made the case that anti-vaccination attitudes don't arise due to a lack of information on vaccines. Nevertheless, it seems necessary to explore further the literature on \"knowledge deficit\" and \"scientific literacy\" since, by far, the oldest and most ubiquitous explanation of why some people have negative attitudes towards some science issues such as vaccination is that they lack proper knowledge and understanding of them. The \"knowledge deficit\" model is implictly based on rational choice theory, which postulates a rational agent who takes into account all available information in order to make a logical choice in line with his preferences. Miller, Hickson and Wilson summarize the claims of rational choice theory as such: Neo-classical economic assumptions lie at the heart of rational choice models of decision making. Predicated on the supposition that individuals normally act as maximizing entrepreneurs, decisions are thought to be arrived at by a step-by-step process which is both logical and linear. Essentially, the decision-makers identify the problem or issue about which a decision has to be made, collect and sort information about alternative potential solutions, compare each solution against predetermined criteria to assess degree of fit, arrange solutions in order of preference and make an optimizing choice. Often such models leave out, or assume, the implementation stage which in principle follows the formal decision itself. Throughout the thrust is to maximize rewards and minimize costs for those involved.1 In other words, the \"economic man,\" in addition to having all the information relevant to his decision, also has a well-organized and stable system of preferences, as well as great \"computational skills,\" in the words of Herbert A. Simon.2 Giving people more information about decision-relevant science and improving their \"computational skills\" when it comes to science - i.e., their \"scientific literacy,\" their \"understanding of science\" - matters because it will allow them to make more rational decisions. The reason why antivaxxers do not change their behaviours in light of new scientific evidence is because their scientific illiteracy skews their understanding of the evidence [Figure 3]. This variable, scientific literacy (or illiteracy), has been the subject of much writing since the mid-20th century. Allum et al. write that: There has been no fiercer debate in the public understanding of science (PUS) than the one that centers on the contested relationship between public opinion and public knowledge about science and technology. [...] The main driver behind this research program at the outset was the need - at least as it was perceived by scientists and governments - to understand why publics in North America and Europe were becoming more skeptical about science as a \"force for good.\" [...] One of the key insights from the programs of research that were set in train in the 1980s is that both European and American publics possess low levels of basic \"textbook\" knowledge about science. For some, findings of this nature are taken as strong empirical confirmations of the existence of a \"scientifically illiterate\" public and provide the first pillar in the construction of the pervasive \"deficit model\" of public understanding of science (Irwin and Wynne, 1996; Sturgis and Allum, 2001). The deficit model sees public resistance to science and technology as underpinned by ignorance, superstition and fear. Public skepticism about technological 61 innovations [...] would be markedly reduced if citizens were better able to grasp the science upon which they are based. That is, a judgment when informed by scientific fact would tend to be more favorable and consistent with expert opinion than one expressed without recourse to such \"objective\" knowledge.3 Goldenberg writes that: \"The Bodmer report (1985) is commonly cited as the first to propose the theory that public ignorance of science prevents citizens from making mature, rational decisions in support of scientifically backed policies, although a similar sentiment was expressed earlier by the US National Commission on Excellence in Education (1983).\"4 In 2000, R\u00fcdiger C. Laugksch of the University of Cape Town published a review of the literature on the concept of scientific literacy, which he says has become a \"well-recognized educational slogan, buzzword, catchphrase, and contemporary educational goal.\"5 \"Scientific literacy\" has been used interchangeably with \"public understanding of science,\" the former being more popular in the United States, and the latter being more popular in Britain.6 According to Laugksch, the term \"scientific literacy\" was first used in the late 1950s; he identifies Paul Hurd7 as the first to have used the term in print, with the publication Science Literacy: Its Meaning for American Schools.8 Laugksch explains that in the 1950s, there was a concern in the American science community about obtaining public support for science in the context of the Space Race.9 Many American parents in those years also became concerned with increasing scientific and technological sophistication and sought an education for their children that would equip them to thrive in this new era.10 An \"initial period\" saw many authors advocate for scientific literacy, and often use the term without a clear definition of what they meant by it.11 Thus followed a period of \"serious interpretation\"12 that revealed the various meanings of \"scientific literacy.\"13 Lewenstein argues that after the Second World War, \"public understanding of science\" took on a different meaning. According to Lewenstein, the four major groups advocating for public understanding of science (commercial publishers, the scientific community, science writers, and government agencies), while having different reasons for doing so, all adopted the same definition of \"public understanding of science.\" Contrary to their explicit rhetoric, advocacy for \"public understanding of science\" was less about understanding science than about appreciating how science benefits society.14 He writes: Figure 3. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on scientific literacy 62 [A]dvocates of popular science who used the term 'understanding' were in fact seeking public appreciation of science. That is, they were seeking to improve the attitude of members of the public toward science as a body of knowledge, science as a way of knowing about the world, scientists as individuals, and the particular requests for support and funding that came from scientific institutions. All of these concerns were lumped together under the label of 'science'.15 Citing work by Durant16 and Jenkins17, Laugksch writes that scientific literacy refers to \"what the general public ought to know about science,\" which \"commonly implies an appreciation of the nature, aims, and general limitations of science, coupled with some understanding of the more important scientific ideas.\"18 So while modern advocacy for public understanding of science definitely still seeks appreciation of science, Hallman argues that modern definitions of scientific literacy go beyond appreciation and \"focus on a more holistic set of core competencies that enable people to engage with science throughout their lives.\"19 The question thus becomes what these \"core competencies\" are. The basic conceptualization of scientific literacy as what ought to be known about science \"masks different meanings and interpretations,\" which has led some to call scientific literacy an \"ill-defined and diffuse concept.\"20 William K. Hallman explains that various definitions of scientific literacy abound: [W]hen people talk about science literacy it is rarely clear whether they mean the public's knowledge of particular science facts; their awareness of particular discoveries; familiarity with controversies involving science; the public's grasp of the scientific method, norms and practices; the ability to comprehend and criticize the priorities and actions of scientific institutions; their ability to engage in civic discussions and decisions about issues involving science; or the public's support for or attitudes toward science.21 The concept has received so many different interpretations that it now refers to virtually all aspects of science education. Regarding the conceptual definitions of scientific literacy, Laugksch identifies work by Pella et al.22 as \"one of the earliest attempts to provide an empirical basis for the definition of scientific literacy.\"23 Pella et al. characterized a scientifically literate person as someone who has an understanding of: (1) the interrelationships of science and society; (2) the ethics that control the scientist in his work; (3) the nature of science; (4) the difference between science and technology; (5) the basic concepts in science; and (6) the interrelationships of science and the humanities.24 Showalter25 elaborated on Pella et al's work and proposed a seven-dimension definition of scientific literacy. According to this definition, the precision of which is rare, the scientifically literate person: (1) understands the nature of scientific knowledge; (2) accurately applies appropriate science concepts, principles, laws, and theories in interacting with his universe; (3) uses processes of science in solving problems, making decisions, and furthering his own understanding of the universe; (4) interacts with the various aspects of his universe in a way that is consistent with the values that underlie science; (5) understands and appreciates the joint entreprises of science and technology and the interrelationship of these with each other and with other aspects of society; (6) has developed a richer, more satisfying, more exciting view of the universe as a result of his science education and continues to extend this education 63 throughout his life; (7) has developed numerous manipulative skills associated with science and technology.26 Shen27, in a more simple definition, suggested that there were three types of scientific literacy: (1) \"practical scientific literacy\", which refers to \"possession of the kind of scientific knowledge that can be used to solve practical problems\"; (2) \"civic scientific literacy\", which \"enable[s] citizens to become sufficiently aware of science and science-related public issues in order for the average citizen to become involved in the decisionmaking process related to such issues as, for example, health, energy, natural resources, food, the environment, and so forth\"; and (3) \"cultural scientific literacy\", which is mostly limited to the intellectual community and which is \"motivated by a desire to know something about science as a major human achievement.\"28 Branscomb29 proposed yet another definition of scientific literacy, this one rooted in the term's etymology. She defined it as \"the ability to read, write, and understand systematized human knowledge\" and proposed eight categories of scientific literacy: (1) methodological; (2) professional; (3) universal; (4) technological; (5) amateur; (6) journalistic; (7) science policy literacy; and (8) public science policy literacy.30 In 1983, Jon Miller wrote an influential article for a special issue of the Journal of the American Academy of Arts and Sciences which asked authors to give their opinion on scientific literacy.31 Miller provided a three-dimensional definition of scientific literacy: (1) an understanding of the norms and methods of science (i.e., the nature of science); (2) an understanding of key scientific terms and concepts (i.e., science content knowledge), and (3) an awareness and understanding of the impact of science and technology on society.32 Laugksch writes that this article, by \"proposing a particular, bounded, and multidimensional model of scientific literacy [...] comprised an important consolidation of this concept.\"33 Arons34 built on Miller's definition, adding a list of attributes emphasizing the intellectual abilities required of a scientifically literate person.35 Other authors36 also reflected on scientific literacy as the ability to apply scientific knowledge and reasoning skills to solve problems and make decisions.37 In 1989, the American Association for the Advancement of Science launched Project 2061, which sought to improve scientific literacy. The project's definition of scientific literacy listed what content students should master, and was similar to that of the National Science Education Standards (NSES). Project 2061's definition of scientific literacy was different from others because it included knowledge of key concepts in the social sciences in addition to natural sciences, as well as \"understanding of the scientific endeavor\", knowledge of \"common themes\" that \"transcend disciplinary boundaries\", and knowledge of \"some episodes in the history of the scientific endeavor [that] are of surpassing significance to our cultural heritage.\"38 64 Hazen and Trefil39 emphasized the distinction between doing and using science, and argued that scientific literacy only concerns the latter. Laugksch explains that: They thus define scientific literacy as \"the knowledge you need to understand public issues. It is a mix of facts, vocabulary, concepts, history, and philosophy\" [...] Such a conceptual definition of scientific literacy is linked to Hirsch's (1987) concept of \"cultural literacy\" [...] Hirsch's premise is that effective communication between two parties (whether between individuals or groups) requires an estimate of how much relevant information can be taken for granted in the other party, as this assumed background knowledge reflects a necessary familiarity of the current mainstream culture, whether in language, history, or science. A store of shared knowledge - \"cultural literacy\" - is therefore important in national communication [...]40 To \"cultural\" scientific literacy, Shamos41 added two other forms of scientific literacy. The first is \"functional\" scientific literacy, which refers to, in addition having a command of scientific vocabulary, having the ability to converse, read, and write coherently about science in a nontechnical but meaningful context.42 The second is \"true\" scientific literacy, which involves knowing about the scientific entreprise. Laugksch cites this passage by Shamos, which explains such an individual: ...is aware of the major conceptual schemes (the theories) that form the foundations of science, how they were arrived at, and why they are widely accepted, how science achieves order out of a random universe, and the role of experimentation in science. This individual also appreciates the elements of scientific investigation, the importance of proper questioning, of analytical and deductive reasoning, of logical thought processes, and of reliance upon objective evidence.43 Laugksch ends his overview of the literature defining scientific literacy with a summary based on interpretations of the nature of the word \"literate\". He notes that the word \"literate\" has generally been used in a descriptive sense, but that \"it is the evaluative sense of the term - the mastery of a body of knowledge - that provides an understanding of the intended meaning.\"44 The classical meaning of the word literate, which is derived from the Latin litteratus, describes a person who is learned. But literate has also been used to describe something more like competency, i.e., an intermediate level of ability. Finally, it has also been used to refer to a \"minimal acceptable level of knowledge or skills required to function in some set of roles in a specific society.\"45 Laugksch then categorizes the above-mentioned definitions within these three meanings of literate, noting that: \"When moving across the literate categories from \"learned\" to \"function in society,\" an increasingly greater emphasis is placed on being able to carry out a task with the acquired scientific literacy attributes, and on being able to use these attributes to cope in everyday life.\"46 In the United States, two nationally-representative surveys aim to measure some aspect of scientific literacy. The first is carried out by the Pew Research Center, a nonpartisan fact tank, and the second is carried out by the National Science Board. The latter is often referred to as the \"Indicators\" survey. Allum et al. write that: Measurement of these constructs in surveys has a long history and one that is not without its share of contentiousness. Since the seminal study of Davis (1958), the idea that it is possible to assess the distribution of general scientific knowledge in mass publics has gained currency. Following on from this early study, the National Science Foundation (NSF) began, in the US during the late 1970s, a series of surveys of public attitudes and knowledge about science and technology as part of its \"Science Indicators\" program. A variety of techniques for measuring knowledge about science were implemented in the early surveys, based mainly on 65 self-reports, but in 1988, following collaboration between Jon Miller in the US and John Durant and colleagues in Britain, a series of factual quiz type questions that tapped \"textbook\" knowledge of science were developed (Durant et al., 1989; Miller, 1998). Known as the \"Oxford Scale,\" these items, or various subsets, have been employed in a large number of public opinion surveys about science and technology ever since. The items are intended to capture one or more dimensions of what Miller refers to as \"civic scientific literacy\" (Miller, 1983, 1998). These dimensions are indicative of an understanding of the content of science (scientific facts), the processes of science (scientific method) and - although this dimension has rarely been measured - an understanding of the impacts of science and technology on society.47 The Pew survey measures, according to the wording of their report, \"scientific knowledge,\" and consists of 11 textbook-like true-or-false or \"life and chart reading,\" and \"scientific processes.\"48 In 2019, the Pew survey found that 39% of respondents got between 9 and 11 correct answers, which they classify as \"high science knowledge,\" while 35% got 5 to 8 correct answers (\"medium science knowledge\"), and 29% got 0 to 4 correct answers (\"low science knowledge\").49 The best predictor of high scientific knowledge was, unsurprisingly, education: respondents with a college and postgraduate degree averaged more than 8 and 9 correct answers, respectively, while respondents \"some college\" education averaged 6.8 correct answers, and respondents with high school degrees (or less) only 5 correct answers.50 This is an important difference. For the two questions measuring \"public understanding of the scientific method,\" only 60% of respondents could identify that adding a control group was the best of four options to test whether an ear infection medication is effective, and only 52% could correctly identify a scientific hypothesis about a computer slowing down.51 The results of the Pew survey align with those of the National Science Board Indicators. The Indicators survey is longer and is divided into four sections: Americans' overall views about science; their attitudes about specific science and technology issues; their understanding of science and technology-related facts and processes; and their interest in and source of science- and technology-related news and public involvement in science- and technology-related activities.52 Regarding public attitudes about science and technology in general, the Indicators survey found that in 2018, the vast majority of Americans continued to have positive attitudes towards science, which has been the case for several decades. Most Americans also found scientists to be highly trustworthy, with only the military scoring higher than scientists among the ranked institutions.53 84% of respondents agreed that science should receive funding from the federal government. Respondents with less education and lower income levels were generally less positive about science and technology, trusted scientists less, and were somewhat less supportive of government funding for science (but still largely positive).54 Regarding public attitudes about specific science and technology issues, the Indicators survey found that Americans have become increasingly concerned with various environmental and technological developments of the past years.55 Attitudes about vaccination were unfortunately not measured. 66 Regarding \"interest, information sources, and involvement,\" the Indicators survey found measured public interest in specific scientific issues, and found that overall, interest in science topics was positively associated with education.56 The survey also found that more Americans relied on the Internet for science- and technology- related news compared to previous years, with 57% of Americans citing the Internet as their primary source of information about science and technology, a 9% increase since 2001.57 The survey also found that interest in activities such as zoos, aquariums, and museums has been stable for years.58 The section of the survey that deals with \"public familiarity with science and technology facts,\" most resembles the Pew survey about scientific knowledge in that it also measures \"scientific literacy\" or \"scientific knowledge\" through textbook-like, true-or-false or multiple-choice questions about physical and biological science. It refers interchangeably to \"scientific literacy\" and \"understanding of science.\"59 The survey found that Americans correctly answered an average of 62% of the questions, which is similar to the averages of recent years and to the historical average since 1992.60 65% of respondents could correctly answer two questions about probability, but only 24% of respondents could adequately describe a scientific study as \"involving something to do with testing theories or hypotheses, conducting experiments, or making systematic comparisons.\"61 Again, education was the best predictor of higher scientific knowledge and higher understanding of the scientific process.62 According to both surveys, science knowledge also varies by gender, race and age, although the effect of these variable is much less significant than that of education. Neither the Indicators survey nor the Pew survey ask any questions about social sciences. Both reports clearly acknowledge the limits of the surveys, both in terms of measurement and of why the results matter. Regarding measurement, the Pew survey report indicates that: \"Science covers numerous fields and encompasses a vast amount of information, and the index of science knowledge can cover only a small slice of this information. However, the rationale for the scale stems from the fact [that] people who happen to know more from this set of questions are also likely to know more about the vast array of science information, generally.\"63 The Indicators survey report similarly states that the questions do \"not address the full range of scientific subjects that could be included. Further, these questions were selected several decades ago based on the likelihood that they would remain stable over time rather than as an effort to capture any specific body of scientific knowledge. Consequently, the survey data do not represent a deep or comprehensive measurement of scientific knowledge. These questions might instead be understood as a way capture the degree to which people have paid attention to science over their life or might be expected to do so in the future.\"64 Hallman further explains: The difficult challenge of choosing representative questions is complicated by the fact that the evolution of science introduces consequential new terms and concepts. Yet to compile data for longitudinal and cross-cultural comparisons it is necessary to retain prior questions to maintain consistency, and adding questions lengthens the survey, increasing costs and placing additional demands on the participants (Miller, 2012). 67 Determining which questions to retain or add is difficult for a number of reasons. Answers to single items drawn from a particular scientific domain are not necessarily indicative of knowledge of either that domain or of broader scientific knowledge and so should not be interpreted on their own. Instead, to measure scientific literacy, the items are meant to be combined into scales. Yet the internal reliability of a number of these scales has been questioned (Pardo and Calvo 2004). In addition, there are some problems with cross-cultural equivalence (Peters 2000), as well as an inability to discriminate between respondents when a large number of questions are somewhat easy to answer (Kahan 2015, 2016; Allum et al. 2008; Pardo and Calvo 2004). The response categories of items, which are limited to true, false, or I don't know, may also be problematic. [...] Another problem is that, in scoring these quiz items, \"don't know\" (DK) answers are typically combined with those that are scored as incorrect (Bauer 1996). [...] Yet these responses represent different states of knowledge; not knowing the answer is clearly different from believing that the wrong thing is true. [...] [Moreover], \"propensity to guess\" is not uniformly distributed within the population.65 In addition to problems with the knowledge questions, Allum et al. point out some issues with the attitude items: Most of the criticism that has been made in this area concerns the general attitude questions. Although designed to elicit overall orientations towards organized science, they may suffer from being too general. This is in the sense that people will answer in idiosyncratic ways because there is no unequivocal focus in the wording of an individual question. Thus, some people may respond to a question that asks about the contribution of science and technology to modern life thinking nuclear power, while others respond on the basis of their views about mobile phones.66 Overall, in Hallman's words: [T]he most commonly used measures of science literacy focus squarely on knowledge of a small collection of science facts along with a few questions regarding probability and experimentation with control groups and a few questions concerning attitudes regarding trust and support for science. These measures are inadequate for the task of fully assessing science literacy.67 The results of these reports have been widely used in discussions about the level of scientific literacy in the US, which some describe as horribly low or and others as relatively high. Questions about what these surveys actually measure are usually left out of the alarmist messages that cite them, and many have used the surveys in arguments linking scientific literacy with public attitudes about science. Indeed, many have argued that increasing scientific literacy is the key to more positive attitudes about science, and to dissipating ongoing controversy surrounding certain scientific issues such as vaccination. In fact, there is evidence that greater scientific literacy (as measured by such surveys) predicts more positive attitudes about science generally, but evidence linking scientific literacy to more positive attitudes about specific science issues is scarce. As argued by Hallman: Advocates of increased science literacy argue that widespread public understanding of science benefits individuals, culture, society, the economy, the nation, democracy, and science itself. Yet the relatively crude measures currently employed to assess science literacy are insufficient to demonstrate these outcomes.68 Both the Pew survey report and the Indicators survey report explicitly caution against reading too much into their results. The Indicators survey report clearly states that: \"Although this report tracks a set of questions aimed to assess knowledge of several basic scientific facts, substantial research has shown that general measures of science knowledge typically only have small - although meaningful - relationships 68 with how people make decisions in their public and private lives.\"69 The Pew survey report is even clearer. In a section titled \"Science knowledge is often hailed as important for society, but its role in public attitudes can be nuanced,\" the survey acknowledges that \"[a]s a practical matter, science knowledge can help individuals navigate a variety of everyday situations, such as making health care decisions or deciding what to eat.\"70 However: Many in the scientific community have looked to public knowledge and understanding about science as a potential driver of support for specific positions that align with scientific consensus in areas of \"settled science.\" But a long history of research in pursuit of what is often called a \"deficit model\" of public attitudes finds little support for the idea. A meta-analysis of past research has shown a modest positive relationship between science knowledge and people's general support for science or scientific research. However, levels of science knowledge do not typically have a direct relationship with positions on specific issues, such as whether to mandate the vaccine for measles, mumps and rubella for children who attend public schools. And on some issues, science knowledge can have a more complicated, indirect role. When it comes to public views about climate and energy issues, partisanship appears to serve as an anchoring point in how people apply their knowledge...71 Allum et al. set out to review the empirical evidence on the link between knowledge and attitudes about science. They conclude that, overall, the empirical evidence \"points to a weak correlation between knowledge about scientific facts and processes and positive attitudes towards science. However, there is evidence that this link is weaker, and may sometimes be negative, for attitudes to specific technologies.\"72 For example, Evans and Durant (1995)73 found that, in the UK, \"whilst \"textbook\" knowledge of general science is positively correlated with favorable attitudes to science in general, for specific technologies or scientific fields, a variety of correlations are found, including a negative one for morally contentious science such as human embryo research.\"74Allum et al write that: [T]he empirical research concerning the so-called \"deficit model\" of PUS has shown that a simple, positive, linear relationship between attitudes and knowledge about science under all circumstances is an over-simplification. Yet there is also plenty of evidence that knowledge, information and awareness can and do affect the way citizens relate to science and technology in differing contexts. That it is important to understand the contexts in which knowledges of various kinds are brought to bear on judgments about science and technology is a case that has been forcefully made by critics of early survey work on PUS (e.g. Irwin and Michael, 2003; Michael, 1996, 2002; Wynne, 1996). It is perhaps therefore surprising that there has been relatively little in the way of constructive engagement with this notion using the wealth of available survey data that has accrued up until now. Instead, there appears to have developed a bifurcation in theoretical and empirical research along largely methodological lines, with little cross-fertilization of ideas (see Sturgis and Allum, 2004 for a more focused discussion on this point).75 Allum et al. conclude by describing the importance of the relationship as \"shallow but broad,\" noting that \"it is focused, one might even say 'local,' types of knowledge that are most important if we are to understand how opinions are generated amongst different publics with different interests and modes of interacting with science and technology in everyday life.\"76 Research should thus focus on understanding the social and psychological mechanisms generating the observed associations.77 Hallman concludes: This suggests that increasing general knowledge about science does not necessarily translate into agreement with the scientific consensus about controversial science topics. In fact, when specific science issues are 69 controversial, the associations between general science knowledge and positive attitudes generally disappear and are often replaced by polarization along ideological, religious, or political divides through motivated reasoning (Kahan et al. 2012). Overall, the level of \"textbook knowledge\" that people have is generally a poor predictor of their attitudes toward, appreciation of, and support for science. In short, the idea that teaching people more science facts will yield a public that is more deferential to science, scientists, or even scientific consensus is questionable.78 So, according to the knowledge deficit model, the key to persuading antivaxxers is to give them more facts. If they knew more about vaccines - about their necessity, their efficacy, their safety - they would have more favorable attitudes towards them. We should teach antivaxxers about science: about scientific principles and methods, about why following such principles and methods leads us to answers that are probably more true than other ways of acquiring knowledge. If they knew all of this, the theory goes, they would make more rational decisions because they would have more information and more computational capacities. This is why interventions that aim to persuade antivaxxers are mostly communication of facts through pamphlets, websites, commercials, blog posts, articles, their favorite celebrity telling them about thimerosal... But the case of antivaxxers is the perfect example of an instance where the link between knowledge and attitudes is shoddy - of where increased scientific knowledge might predict positive attitudes towards science in general, but does not necessarily predict positive attitudes about vaccination specifically [Figure 4]. As noted in Chapter 2.1 (Literature on the Effectiveness of Dissemination of Scientific Evidence to Change Behaviours), many studies focusing specifically on vaccination have found that interventions to promote vaccination that are based on simple communication of facts are mostly ineffective at changing attitudes and behaviours in the long term.79 Frew and Lutz note that when parents lack information about vaccines, communicating scientific evidence to them empowers them to make an informed decision for their child.80 But most parents who make up the anti-vaccine movement do not lack information. A review published by Harvey et al. in Vaccine found that: \"Interventions that raise the basic level of parental knowledge are therefore more effective in areas where understanding is low compared to countries where it is comparatively higher and educational barriers to immunisation may be more subtle and linked to vaccine belief.\"81 As noted by Reich82 and others,83 parents (mothers, more often than not) who refuse or Figure 4. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on the relationship between knowledge and attitudes 70 delay vaccination for their children are most likely to be college-educated and well-informed about vaccines: \"These mothers have time and resources with which to gather information, customize healthcare and nutrition choices, and buck public health law without fear of formal sanctions.\"84 Most antivaxxers drive cars, use cellphones and the internet, live in houses that have heat and electricity, and bring their kids to the hospital if they have a broken arm. They might not be resistant to science and technology generally, but they are to vaccines. Antivaxxers already have access to the information we spend so much time and resources repeating to them. It isn't a lack of information that drives their attitudes and behaviours; resistance towards vaccination is part of their identity, and they are impervious to more scientific evidence. Not only does increased knowledge about vaccines fail to persuade them, it might also create a backfire effect. Researchers, including Nyhan, who found that corrective information significantly reduced intent to vaccinate among respondents who had a high level of concern about the side effects of vaccines,85 have provided empirical evidence that calls into question the soundness of the knowledge deficit model. 71 Key Messages : The knowledge deficit model and scientific literacy The oldest and perhaps most widespread explanation of resistance to scientific evidence is that people have not received the right evidence, or enough evidence, or that they lack the education or skills necessary to comprehend the evidence. This knowledge deficit model puts the emphasis on one key variable: scientific literacy. The theory is that increasing understanding of science and knowledge of science facts would markedly reduce skepticism of and resistance to science. Since the middle of the 20th century, a lot of writing has been devoted to debating the definition of scientific literacy, i.e. what it actually implies, and figuring out how to properly measure it. In the US, two nationally-representative surveys (the Pew and the Indicators) are regularly conducted to measure the state of scientific knowledge and attitudes towards science among the American public. Many have argued that increasing scientific literacy is the key to more positive attitudes about science, and to dissipating ongoing controversy surrounding certain scientific issues such as vaccination. While scientific literacy may be necessary for the \"understanding\" element of the model, and while there is some evidence of a link between between increased scientific literacy and more positive attitudes towards science generally, there is no evidence that increased scientiific literacy will lead to more positive attitudes towards specific science issues such as vaccination. In fact, antivaxxers tend to be well-educated and scientifically literate, and have been exposed repeatedly to sound evidence about vaccines. Their resistance is not due to lack of information. Moreover, there is empirical evidence of a \"backfire effect\" of providing them with corrective information, which may not only fail to increase their intent to vaccinate, but even reduce it. 72 REFERENCES: THE KNOWLEDGE DEFICIT MODEL AND SCIENTIFIC LITERACY1 Susan J. Miller, David J. Hickson, and David C. Wilson, \"Decision-Making in Organizations,\" in Handbook of Organization Studies, eds. Stewart Clegg, Cynthia Hardy, and Thomas Lawrence (London: Sage, 1996) 294. 2 Herbert A. Simon, \"A Behavioral Model of Rational Choice,\" The Quarterly Journal of Economics 69, 1 (1955): 99-118, 99. 3 Allum, Sturgis, Tabourazi, and attitudes across a meta-analysis,\" 35. 4 Maya J. Goldenberg, Vaccine Hesitancy: Public Trust, Expertise, and the War on Science (Pittsburgh: Pittsburgh University Press), 21. 5 R\u00fcdiger C. Laugksch, \"Scientific Literacy: A Conceptual 6 Laugksch, \"Scientific A Conceptual Overview,\" 71. 7 Paul Hurd, \"Science literacy: Its meaning for American schools,\" Education Leadership, 13-16. 8 Laugksch, \"Scientific A Conceptual Overview,\" 72. 12 Douglas A. Roberts, \"Scientific literacy. Towards a balance for setting goals for school science programs.\" (Ottawa: Minister of Supply and Services, 1983). 13 Laugksch, \"Scientific Literacy: A Conceptual Overview,\" 72. 14 Lewenstein, \"The meaning of 'public understanding of science' in the United States after World War II,\" 62. 15 Bruce V. Lewenstein, \"The meaning of 'public understanding of science' in the United States after World War II,\" Public Understanding of Science 1, 1 (1992): 45-68, 45-46. 16 John R. Durant, \"What is scientific literacy?\" in Science and culture in Europe, eds. J.R. Durant and J. Gregory (London: Science Museum, 1993): 129-137. 17 Edgar Jenkins, \"Scientific literacy,\" in The international encyclopedia of education, eds. T. Husen and T.N. Postlethwait, Volume Laugksch, 71. 19 William K. Hallman, \"What the Public Thinks and Knows About Science - and Why It Matters,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, A Conceptual Overview,\" 71. 21 Hallman, \"What the Public Thinks and Knows About Science - and Why It Matters,\" 61. 22 Milton O. Pella, George T. O'hearn, and Calvin W. Gale, \"Referents to scientific literacy,\" Journal of Research in Science Teaching 4 (1966): 199-208. 23 Laugksch, V.M. Showalter, \"What is united science education? Part 5. Program objectives and scientific literacy\" Prism II (1974). 26 Laugksch, \"Scientific Literacy: A Conceptual Overview,\" 76-77. 27 Benjamin S.P. Shen, \"Scientific literacy and the public understanding of science,\" in Communication of scientific information, ed. S.B. Day (Basel: Karger, 1975): 44-52; Benjamin S.P. 28 Laugksch, Conceptual Overview,\" 77. 29 Anne W. Branscomb, \"Knowing how to know, Science, Technology, & Human Values 6, 36 (1981): 5-9. 30 Laugksch, and B.A. Wier, \"Scientific literacy: Perspectives of schools administrators, teachers, students, and scientists from an urban mid-Atlantic community,\" in This year in school science. Scientific literacy, eds. A.B. Champagne, better understanding of science,\" in Communicating science to the public, eds. D. Evered & M. O'Connor (London: A Conceptual Overview,\" 79. 39 Robert M. Hazen and James Trefil, Science matters: Achieving scientific literacy (New York: Anchor Books Doubleday, 1991). 40 Laugksch, \"Scientific Literacy: A Conceptual Overview,\" 80. 41 Morris Herbert Shamos, The myth of scientific literacy (New Brunswick, NJ: Rutgers University Press, 1995). 42 Laugksch, \"Scientific Literacy: A Overview,\" 80. Dimitra Tabourazi, and Brunton-Smith, \"Science knowledge and attitudes across cultures: a meta-analysis,\" Public Understanding of Science 17 (2008): 35-54, 38. 48 Pew Research Center, \"What Americans Know About Science,\" (2019), 2. 49 Pew Research Center, \"What Americans Know About Science,\" 3. 50 Pew Research Center, \"What Americans Know About Science,\" 4. 51 Pew Research Center, \"What Americans Know About Science,\" 7. 52 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" (May 15, 2020), 6. 53 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 11. 54 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 10-15. 55 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 19-22. 56 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 29-30. 57 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 30. 58 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 32. 59 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 23. 60 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 23. 61 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 27. 62 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 28. 63 Pew Research Center, \"What Americans Know About Science,\" 3. 64 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 23. 65 Hallman, \"What the Public Thinks and Knows About Science - and Why It Matters,\" 66. 66 Allum, Sturgis, Tabourazi, and Brunton-Smith, \"Science a meta-analysis,\" 39. 67 Hallman, \"What the Public Thinks and Knows About Science - and Why It Matters,\" 68. 68 Hallman, \"What the Public Thinks and Knows About Science - and Why It Matters,\" 68. 69 National Science Board, \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" 23. 70 Pew Research Center, \"What Americans Know About Science,\" 8. 71 Pew Research Center, \"What Americans Know About Science,\" 9. 72 Allum, Sturgis, Tabourazi, Brunton-Smith, \"Science knowledge and attitudes across cultures: a meta-analysis,\" 36. 73 Geoffrey Evans and John R. Durant, \"The Relationship between Knowledge and Attitudes in the Public Understanding of Science in Britain,\" Public Understanding of Science 4, 1 (1995): 57-74. 74 Allum, Sturgis, Tabourazi, Allum, Sturgis, Tabourazi, Allum, Sturgis, Tabourazi, a meta-analysis,\" 52. 78 Hallman, \"What the Public Thinks and Knows About Science - and Why It Matters,\" 68. 79 Peter A. Briss et al., \"Reviews of Evidence Regarding Interventions to Improve Vaccination Coverage in Children, Adolescents, and Adults,\" American Journal of Preventive Medicine 18, 1S (2000): 97-140; Natalie Willis et al., \"\"Communicate to vaccinate\": the development of a taxonomy of communication interventions to improve routine childhood vaccination,\" BMC International Health and Human Rights 13:23 (2013); Hannah Harvey, Nadja Reissland, and James Mason, \"Parental reminder, recall and educational interventions to improve early childhood immunisation uptake: A systematic review and meta-analysis,\" Brendan Nyhan and Jason Reifler, \"Does correcting myths about the flu vaccine work? An experimental evaluation of the effects of corrective information,\" Vaccine 33 (2015): 459-464; Amanda F. Dempsey, Gregory D. Zimet, Robert L. Davis, and Laura Koutsky, \"Factors That Are Associated With Parental Acceptance of Human Papillomavirus Vaccines: A Randomized Intervention Study of Written Information About HPV,\" Pediatrics 117, 5 (May 2006): 1486-1493; Eve Dub\u00e9, Dominique Gagnon, Noni E. MacDonald and the SAGE Working Group on Vaccine Hesitancy, \"Strategies intended to address vaccine hesitancy: Review of published reviews,\" Vaccine 33 (2015): 4191-4203. 74 80 Paula M. Frew & Chelsea S. Lutz. \"Interventions to increase pediatric vaccine uptake: An overview of recent findings,\" Human Vaccines & Immunotherapeutics 13, 11 (2017): 2503-2511, 2505. 81 Harvey, Reissland, and Mason, \"Parental reminder, recall and educational interventions to improve early childhood immunisation uptake: A systematic review and meta-analysis.\" 82 Reich, Jennifer A. \"'We are fierce, independent thinkers and intelligent': Social capital and stigma management among mothers who refuse vaccines,\" Social Science & Medicine 2019). 84 Reich, Jennifer A. \"'We are fierce, independent thinkers and intelligent': Social capital and stigma management among mothers who refuse vaccines.\" 85 Nyhan and Reifler, \"Does correcting myths about the flu vaccine work? An experimental evaluation of the effects of corrective information.\" 75 4.2. The Psychological Approach There is another narrative to explain antivaxxers' resistance to science. This alternative explanation emerged in the fields of cognitive psychology and behavioural economics. According to this approach, the crux of the problem of communicating science to people is that people are imperfect information processors.1 They have cognitive biases and rely on heuristics that prevent them from properly evaluating evidence on risk.2 According to Goldenberg, the idea that biased cognition might explain persistent anti-vaccination attitudes emerged as a challenge to the dominant knowledge deficit narrative following Nyhan's 2014 study on the \"backfire\" effect of corrective information about vaccine myths.3 The psychological approach \"identifies recurring cognitive and affective dynamics that cause individuals to form risk perceptions systematically different from ones we might expect if such individuals were behaving consistently with rational decision theory.\"4 Some iteration of this idea has been an object of writing for centuries; one of many examples is Adam Smith, the father of modern economic thinking, who wrote a book on human \"passions\" years before his masterwork The Wealth of Nations.5 But Herbert A. Simon is perhaps the first 20th-century scholar to articulate a comprehensive critique of the limits of the rational choice model. Simon was a polymath who spent most of this career at Carnegie Mellon University and who was well-known in a vast range of social science fields, notably economics, organizational theory, political science, and artificial intelligence.6 Simon argued that people, when making decisions, are not perfectly rational, and wrote that: \"Broadly stated, the task is to replace the global rationality of economic man with a kind of rational behavior that is compatible with the access to information and the computational capacities that are actually possessed by organisms, including man, in the kinds of environments in which such organisms exist.\"7 In his 1947 book Administrative Behavior, Simon writes that \"[i]t is impossible for the behavior of a single, isolated individual to reach any high degree of rationality. The number of alternatives he must explore is so great, the information he would need to evaluate them so vast that even an approximation to objective reality is hard to conceive.\"8 Miller et al. summarize the constraints identified by Simon: The issue for decision is likely to be unclear or open to varying interpretation; information about alternatives may be unavailable, incomplete or misrepresented; and criteria by which potential solutions are to be evaluated are often uncertain or not agreed. In addition, the time and energy available to decision-makers to pursue a maximizing outcome is both limited and finite. Searching for better choices can simply take too long. The net result of these constraints is that the outcome is likely to be a 'satisficing' rather than an optimizing choice: one which both satisfies and suffices in the circumstances, for the time being. The absolutely rational model is beyond reach. Decision-making does not work that way. Simon accepts that managers have to operate within a 'bounded rationality'. They intend to be rational, and indeed their behaviour is reasoned - it is not irrational, which is an important distinction - but it is unrealistic to expect them to meet the stringent requirements of wholly rational behaviour.9 76 In sum, according to Simon, the psychological limits of people, particularly when it comes to their computational and predictive skills, makes them operate under conditions of \"bounded\" (as opposed to perfect) rationality, and strive for a \"satisfying\" (as opposed to optimal) outcome.10 These concepts of bounded rationality and satisficing have been influential in an array of social sciences, but Simon himself stated that his hypotheses rested on \"common experience,\" for lack of \"empirical knowledge of the decisional processes that will be required for a definitive theory.\"11 A few years later, in 1959, Johns Hopkins psychology professor Ward Edwards, seemed to share the concerns of Simon. Edwards deplored that economic theory and public policy relied on theories about decision-making that had not been investigated by psychologists, those best suited to study how people actually make decisions.12 At the time, a popular idea in decision-making sciences was that when evaluating odds, people did not do advanced Bayesian statistics, but behaved as if they did.13 In his book The Undoing Project, which recounts the careers of Daniel Kahneman and Amos Tversky, the writer Michael Lewis explains that: The best working theory in social science just then was that people were rational - or, at the very least, decent intuitive statisticians. They were good at interpreting new information, and at judging probabilities. They of course made mistakes, but their mistakes were a product of emotions, and the emotions were random, and so could be safely ignored.14 Kahneman and Tversky, going against the tide of the time, disagreed, and sought to prove that people, far from mostly making statistically correct evaluations of risks, make systematic mistakes in judgment.15 Over the next decade, Kahneman and Tversky laid the bases for the \"empirical knowledge\" about actual decisional processes that Simon longed for. Their first paper together, published in 1971, was \"Belief in the Law of Small Numbers,\" in which they showed that even trained statisticians \"failed to intuit how much more variable a small sample could be than the general population - and that the smaller the sample, the lower the likelihood that it would mirror the broader population.\"16 They published \"Subjective Probability: A Judgment of Representativeness\" in 1972, followed by \"Availability: A Heuristic for Judging Frequency and Probability\" and \"On the Psychology of Prediction\" in 1973. In these papers, they presented different rules of thumb (heuristics) that people rely on to make judgments that cause them to make predictable errors. By early 1973, they decided to write a summary paper outlining the key insights of these four publications; \"Judgment Under Uncertainty: Heuristics and Biases\" was published in Science in 1974, and it is widely considered to be the seminal paper in this research tradition. Lewis states that Kahneman and Tversky's work initiated an \"academic culture war.\"17 Kahneman and Tversky often relied on hypothetical questions and simple scenarios - Kahneman once called it \"the psychology of single questions\" - and critics attacked these methods. The same Ward Edwards who had once invited psychologists to improve the decision-making theories of economics and public policy wrote 77 to Tversky, his former student: \"I think your data collection methods are such that I don't take seriously a single 'experiment' finding you present.\"18 However, Kahneman writes that today, \"[b]y and large [...] the idea that our minds are susceptible to systematic errors is now generally accepted.\"19 He adds: Historians of science have often noted that at any given time scholars in a particular field tend to share basic assumptions about their subject. Social scientists are no exception; they rely on a view of human nature that provides the background of most discussions of specific behaviors but is rarely questioned. Social scientists in the 1970s broadly accepted two ideas about human nature. First, people are generally rational, and their thinking is normally sound. Second, emotions such as fear, affection, and hatred explain most of the occasions on which people depart from rationality. Our article challenged both assumptions without discussing them directly. We documented systematic errors in the thinking of normal people, and we traced these errors to the design of the machinery of cognition rather than to the corruption of thought by emotion. Our article attracted much more attention than we had expected, and it remains one of the most highly cited works in social science (more than three hundred scholarly articles referred to it in 2010). Scholars in other disciplines found it useful, and the ideas of heuristics and biases have been used productively in many fields, including medical diagnosis, legal judgment, intelligence analysis, philosophy, finance, statistics, and military strategy.20 The next decades saw Kahneman, Tversky, Richard Thaler, and many other scientists catalogue dozens of cognitive biases and heuristics that skew judgment. The development of this research tradition is a perfect example of a scientific revolution in the sense of Thomas Kuhn.21 In his 2012 megahit Thinking, Fast and Slow, Kahneman offered a summary of his overarching theory of decision processing, which has been called the dual process theory of reasoning. Kahneman's starting point is the law of least effort, which he says applies not only to physical but also to cognitive exertion: \"if there are several ways of achieving the same goal, people will eventually gravitate to the least demanding course of action. [...] Laziness is built deep into our nature.\"22 Kahneman posits that there are \"two systems of the mind\", System 1 and System 2: System 1 operates automatically and quickly, with little or no effort and no sense of voluntary control. System 2 allocates attention to the effortful mental activities that demand it, including complex computations. The operations of System 2 are often associated with the subjective experience of agency, choice, and concentration.23 In other words, System 1 governs some cognitive efforts - those that are more rapid, associative, and intuitive - while System 2 governs others - those that are slower, more complex, and more often than not calculative and statistical.24 The division of labor between these systems is efficient, because System 1 is generally good at making the vast majority of decisions in day-to-day life. It has models of familiar situations that are mostly accurate; it makes short term predictions that are mostly accurate; and its initial reactions to stimuli are quick and mostly appropriate.25 Relying only on System 2 would be close to impossible, as it is too slow, inefficient and effortful to substitute for System 1 in making day-to-day, routine decisions.26 The idea that heuristics are \"rules of thumb\" for the mind to make decisions with realistic mental resources circles back 78 to Simon's theory of \"bounded rationality\", which stated that decisions are made under conditions of limited time, knowledge, and energy.27 We thus rely mostly on System 1. However, this can lead to errors in judgment.28 Kate Kenski explains that: System 1 is often associated with the concept of peripheral processing, whereas System 2 is identified with central processing. When one encounters difficulty in making a judgment, the effortful side kicks in. But when no red flags or warnings appear, the efficient and automatic system processes information quickly. Efficiency, however, does not always result in accurate judgments. Many of the cognitive shortcuts, known as heuristics, which we utilize to make efficient decisions result in errors in judgment.29 Kenski adds that \"[t]he use of heuristics appears to be endemic to the human condition as is potential bias from using those cognitive shortcuts.\"30 Going into detail about these mechanisms or about the countless cognitives biases and heuristics that have been identified is beyond the scope of this paper. Many reviews have already done so. However, it is clear that reliance on heuristic processing provides part of the answer of why intervention models based on simple communication of facts fail to change the opinion of antivaxxers. Akin and Landrum write that: \"The technical nature of many scientific issues, their increasing tendency to be politically polarizing, and the fact that science communication usually involves complex data and numbers, are all factors that promote the use of heuristic processing.\"31 Some cognitive biases and heuristics are of particular interest in the case of antivaxxers. The following section will provide a succinct overview of: the availability heuristic, the affect heuristic, probability neglect, confirmation bias, overconfidence, and bias blind spot. Akin and Landrum call these \"phenomena of reasoning\": \"information filtered and processed through the cognitive heuristics, biases, and values of the audience members such that the same information can be interpreted by different individuals to mean very different things.\"32 They distinguish phenomena of reasoning from \"phenomena of selection\": \"audience interpretation of information are related to (a) what information sources they themselves choose [...] and (b) the way in which those sources selectively present information.\"33 In sum, information processing is a function both of individuals' cognitive biases and heuristics and of the message. According to Cass Sunstein, whose work bridged the gap between literature on cognitive biases and heuristics and law, the availability heuristic is \"probably the most important for purposes of understanding risk-related law,\"34 writing elsewhere that in the social context, \"all heuristics are equal, but availability is more equal than the others.\"35 Availability was one of the first heuristics identified by Kahneman and Tversky, who in 1973 wrote that \"[a] person is said to employ the availability heuristic whenever he estimates frequency or probability by the ease with which instances or associations could be brought to mind.\"36 In other words, the availability heuristic refers to making judgments by using the evidence that comes to mind most easily.37 Kahneman and Tversky explain that: Life-long experience has taught us that instances of large classes are recalled better and faster than instances of less frequent classes, that likely occurrences are easier to imagine than unlikely ones, and that associative 79 connections are strengthened when two events frequently co-occur. Thus, a person could estimate the numerosity of a class, the likelihood of an event, or the frequency of co-occurrences by assessing the ease with which the relevant mental operation of retrieval, construction, or association can be carried out. [...] That associative bonds are strengthened by repetition is perhaps the oldest law of memory known to man. The availability heuristic exploits the inverse form of this law, that is, it uses strength of association as a basis for the judgment of frequency. In this theory, availability is a mediating variable, rather than a dependent variable as is typically the case in the study of memory.38 The ease with which information is retrieved from memory is determined partly by ecological frequency, but also by the extent of media coverage.39 The concept of an \"availability cascade\" was developed by Timur Kuran and Sunstein to explain the development of certain collective beliefs, based on the concept of information cascade, as mediated by the availability heuristic. An availability cascade is a self-reinforcing cycle where an idea, usually a rather simplistic explanation for a complex process, gains currency in the popular discourse because of its simplicity and apparent acumen. The idea gains traction; individuals adopt it because others within their network adopt it. This new popularity hinges on its increased availability. Kahneman explains the concept in Thinking, Fast and Slow: An availability cascade is a self-sustaining chain of events, which may start from media reports of a relatively minor event and lead up to public panic and large-scale government action. On some occasions, a media story about a risk catches the attention of a segment of the public, which becomes aroused and worried. This emotional reaction becomes a story in itself, prompting additional coverage in the media, which in turn produces greater concern and involvement. The cycle is sometimes sped along deliberately by \"availability entrepreneurs,\" individuals or organizations who work to ensure a continuous flow of worrying news. The danger is increasingly exaggerated as the media compete for attention-grabbing headlines. [...] The issue becomes important because it is on everyone's mind, and the response of the political system is guided by the intensity of public sentiment. The availability cascade has now reset priorities. Other risks, and other ways that resources could be applied for the public good, all have faded into the background.40 Availability is related to another heuristic: affect, which refers to using feelings, instead of knowledge, to make judgments.41 These two heuristics are linked because, as Kahneman clarifies, \"the ease with which ideas of various risks come to mind and the emotional reactions to these risks are inextricably linked. Frightening thoughts and images occur to us with particular ease, and thoughts of danger that are fluent and vivid exacerbate fear.\"42 Affect refers to subtle, often unconscious feelings, the role of which has long been recognized by behavioural theories but rarely interpreted to be a component of judgment and decision-making.43 The notion of an affect heuristic was developed by Paul Slovic, notably in the 2007 article \"The affect heuristic\": The basic tenet of this paper is that images, marked by positive and negative affective feelings, guide judgment and decision making. Specifically, it is proposed that people use an affect heuristic to make judgments. That is, representations of objects and events in people's minds are tagged to varying degrees with affect. In the process of making a judgment or decision, people consult or refer to an \"affect pool\" containing all the positive and negative tags consciously or unconsciously associated with the representations. Just as imaginability, memorability, and similarity serve as cues for probability judgments (e.g., the availability and representativeness heuristics), affect may serve as a cue for many important judgments. Using an overall, readily available affective impression can be far easier - more efficient - than weighting the pros and cons or retrieving from memory many relevant examples, especially when the required judgment or decision is complex or mental resources are limited. This characterization of a mental short-cut leads to labeling the use of affect a \"heuristic\".44 80 Thus, as with availability, affect is a way for System 1 to make a quick, efficient judgment with limited information and resources. It is, in the words of Kahneman, an instance of \"substitution,\" where the answer to a hard question (what do I think about it?) is replaced by the answer to a much easier question (how do I feel about it?).45 Availability and affect are both related to the pattern Sunstein has coined \"probability neglect.\" Kahneman writes that: You may know that there is really (almost) nothing to worry about, but you cannot help images of disaster from coming to mind. As Slovic has argued, the amount of concern is not adequately sensitive to the probability of harm; you are imagining the numerator - the tragic story you saw on the news - and not thinking about the denominator. [...] The combination of probability neglect with the social mechanisms of availability cascades inevitably leads to gross exaggeration of minor threats, sometimes with important consequences.46 Sunstein further explains: When it comes to risk, a key question is whether people can imagine or visualize the worst-case outcome. When the worst case produces intense fear, surprisingly little role is played by the stated probability that that outcome will occur. An important function of strong emotions is thus to drive out quantitative judgments, including judgments about probability, by making the best case or the worst case seem highly salient. But it is important to note that probability neglect can occur even when emotions are not involved. A great deal of evidence shows that whether or not emotions are involved, people are relatively insensitive to differences in probabilities, at least when the relevant probabilities are low.47 This is not to say that people are completely indifferent to large variations in the probability of a risk, but rather than when emotions (especially strong ones) are involved, judgment deviates from rationality: \"when intense emotions are engaged, people tend to focus on the adverse outcome, not on its likelihood. That is, they are not closely attuned to the probability that harm will occur.\"48 And, inversely: \"When people neglect probability, they may also treat some risks as if they were nonexistent, even though the likelihood of harm, over a lifetime, is far from trivial.\"49 There are some specific errors that humans are prone to make when interpreting quantitative information. In general, people \"overweight salient information such as recent news and underweight less salient data such as long-term averages.\"50 In an article on quantitative heuristics and biases, Hardy and Jamieson touch on a few particular misunderstandings and misuses of quantitative trend data. For example, people focus and overweight high points and final points of trendlines (peak and end rule) and the most recently presented data (recency effect or serial position effect). These biases are variants of the availability heuristic: data that is more salient, intense or recent is given too much weight because it is more easily retrieved from memory. In addition, Peters notes that people who have lower numeracy skills may be more prone to rely on heuristics to make sense of complex, numeric scientific information.51 Overall, as with availability and affect, probability neglect is an example of System 1 performing a quick, intuitive, and noncalculative mental shortcut in the name of efficiency, leading to skewed decision-making.52 81 In the case of science-resistant groups such as antivaxxers, another cognitive phenomenon is clearly at play: confirmation bias. Oswald and Grosjean provide the following definition: confirmation bias \"means that information is searched for, interpreted, and remembered in such a way that it systematically impedes the possibility that the hypothesis could be rejected - that is, it fosters the immunity of the hypothesis.\"53 Kenski concurs: \"Confirmation bias refers to the tendency to focus on information that validates the narrative, understanding, or hypothesis that one has in his or her mind.\"54 Confirmation bias leads individuals to favour information that is consistent with the beliefs they already hold and to dismiss information that isn't.55 An example of confirmation bias is participants in an experiment giving higher ratings to studies supporting their existing views, while pointing out the shortcomings in research contradicting them.56 In a case of confirmation bias, \"one selectively gathers, or gives undue weight to, evidence that supports one's position while neglecting to gather, or discounting, evidence that would tell against it.\"57 Confirmation bias resembles, but differs from, a \"positive test strategy\" (PTS), which refers to individuals searching for results to confirm their hypothesis, if results can be found: \"A PTS a such does not necessarily lead to preservation of the hypothesis, since the person doing the testing exerts only a restricted influence on the outcome of the search for new information, and is moreover inclined predominantly to ask diagnostically relevant questions.\"58 In comparison: A true confirmation bias seems to occur primarily when the hypotheses tested are already established, or are motivationally supported. In general, we may say that the confirmation bias consists in favouring expectancy-congruent information over incongruent information. This may happen in different ways: (a) memories congruent with the hypothesis are more likely to be accessed than memories that are incongruent with it; (b) undue weight is given to the importance of congruent information, possibly because of the concentration on the hypothesis, and the neglect of alternative explanations; (c) those sources with information that could reject the hypothesis are avoided, provided that the person knows a priori the opinion of the source.59 Moreover, there is a difference between \"building a case\" consciously versus unconsciously.60 Nickerson explains that confirmation bias \"connotes a less explicit, less consciously one-sided case-building process. It refers usually to unwitting selectivity in the acquisition and use of evidence.\"61 According to Nickerson, this bias may stem from a \"desire to believe\", an example of the \"Pollyanna principle,\" which states that \"people are likely to give preferential treatment to pleasant thoughts and memories over unpleasant ones\"; they \"find it easier to believe propositions they would like to be true than propositions they would prefer to be false.\"62 Confirmation bias may also stem from a commitment or an attachment to consistency.63 The concept of confirmation bias converges with that of \"selective judgment,\" which Natalie Jomini Stroud defines as \"the biased processing of information whereby confirmatory messages are readily adopted and integrated into one's mental framework and contradictory ones are dismissed outright or subject to enhanced scrutiny that can minimize their impact on one's beliefs and attitudes.\"64 It also 82 resembles \"motivated reasoning\" in the sense of Kunda (1990), although motivated reasoning may be a broader concept.65 Confirmation bias - our tendency to seek and favour evidence confirming our beliefs - thus makes it hard to renounce our initial sentiments about things, including science issues, and appropriately consider relevant evidence, especially when this evidence runs counter to what we believe (or want to believe).66 Kenski writes that \"[t]hose prone to confirmation bias tend to be overconfident.\"67 Like confirmation bias, Kahneman explains, overconfidence hinges on a desire to settle on a coherent interpretation and suppress doubt and ambiguity.68 Kahneman writes that: \"The confidence that individuals have in their beliefs depends mostly on the quality of the story they can tell about what they see, even if they see little. We often fail to allow for the possibility that evidence that should be critical to our judgment is missing - what we see is all there is.\"69 And when individuals are overconfident in their views, corrective information may prove useless: \"One challenge to those seeking interventions to overcome confirmation bias is that education and information do not necessarily mitigate the effects of confirmation bias on attitudes.\"70 One example of evidence to this effect is the aforementioned study by Nyhan and Reifler, who found that people who had serious concerns about the side effects of the flu vaccine were less likely to get the vaccine after having been shown information debunking the myth that a side effect of the flu vaccine is catching the flu.71 Confirmation bias and overconfidence are related to another bias: bias blind spot, which refers to the tendency of individuals to recognize the existence and operation of systematic biases in other people's thinking but not their own.72 In other words, bias blind spot \"deals with the perception that one's own proclivity for being biased is not as pronounced as the perceived bias in others.\"73 The notion comes chiefly from the 2002 article \"The bias blind spot: perception of bias in self versus others\" by Pronin et al., who summarize it as follows: We propose that people recognize the existence, and the impact, of most of the biases that social and cognitive psychologists have described over the past few decades. What they lack recognition of, we argue, is the role that those same biases play in governing their own judgments and inferences.74 Understanding and awareness of biases in human judgment, and the ability to recognize the impact of these biases on others, \"neither prevents one from succumbing nor makes one aware of having done so.\"75 Moreover, people assume that others are more likely to be influenced by the media than they, an idea called the \"third-person effect.\"76 Pronin et al. warn that \"[m]isunderstanding, mistrust, escalation of conflict, and unwarranted pessimism about the ability to find common ground with those with whom we disagree become likely consequences when we attribute disagreements and bias not to ordinary psychological processes but to evil strategic designs or the unique traits of our \"opponents.\"77 83 These cognitive biases and heuristics - \"phenomena of reasoning\" - may be exacerbated by the characteristics of the information sources and contents - \"phenomena of selection.\" Akin and Landrum explain that these are twofold: there is, first, the question of which sources of information people choose; and, second, there is the question of the way in which those sources present the information.78 This first question can be referred to as \"selective exposure\" and/or \"selective attention.\" Selective exposure refers to \"the motivated selection of messages matching one's beliefs and the preference for like-minded messages over those that express counterattitudinal perspectives.\"79 Selective exposure \"occurs when individuals' prior beliefs and/or values determine what sources and information they choose to attend to and to deem credible.\"80 It is, in other words, information selection steeped in confirmation bias; a coherency mechanism to affirm currently held beliefs and avoid cognitive dissonance.81 Work has underscored the links between polarization, including polarization regarding scientific issues, and selective exposure.82 More work has also shown how \"echo chambers,\"83 \"epistemic bubbles\"84 and \"filter bubbles\"85 reinforce and amplify beliefs through repetition and insulation from rebuttal. In a recent article, C. Thi Nguyen clarifies the similarities and distinctions between these three concepts.86 In Echo Chamber, a book about Rush Limbaugh and the conservative media establishment, Kathleen Hall Jamieson and Joseph N. Cappella define the concept as follows: The metaphor of an echo chamber captures the ways messages are amplified and reverberate through the conservative opinion media. We mean to suggest a bounded, enclosed media space that has the potential to both magnify the messages delivered within it and insulate them from rebuttal. [...] this \"echo chamber\" creates a common frame of reference and positive feedback loops for those who listen to, read, and watch these media outlets. At times, the \"echoing\" is literal and works through direct citation. [...] We mean \"echo\" in a second sense as well: each outlet legitimizes the other.87 In an echo chamber, explains Nguyen, the system of selection and exclusion lacks coverage-reliability, \"the completeness of relevant testimony from across one's whole epistemic community.\"88 It is normal for individuals to need to trust others as legitimate sources of information; no one human can manage the amount of information needed to make decisions and must depend on the expertise of others to guide their action (this is a point we will circle back to later).89 But in an echo chamber, \"natural, useful, and necessary attitudes of individual and institutional trust\" are perverted; all outside beliefs are strategically and defensively discredited, on the basis that they come from the outside, without regard for their actual epistemic worth.90 Jamieson and Cappella summarize the effects of the echo chamber: The conservative opinion media speak to and reinforce the identity of an in-group\u2014that is, an insulated interpretive community protected from attitudinal assault by those of opposing view. They do so through definitions and arguments that encapsulate conservative positions while attacking the other side in evocative emotional language, balkanizing knowledge by featuring information and interpretations of it that advantage their side, and, particularly in Limbaugh's case, polarizing perceptions of their opponents through disparaging labels and ridicule. 91 84 In an echo chamber, one \"preaches to the choir\": \"An audience with opinions, attitudes, beliefs, and behaviours that are already in line with those of the host will not be readily changed or will have little room to change as a result of the source's [...] rhetoric.\"92 The notion of the echo chamber also captures the idea that many people who listen to certain media come to them already predisposed towards their content93: \"the impulse to absorb ideologically agreeable information draws conservative partisans to the protective shelter of the conservative media, where reassuring frames of argument decrease their susceptibility to other ideological points of view.\"94 Overall, then, previously held beliefs lead to exposure to media content that is consistent with these beliefs, which minimally confirms, and maybe amplifies, them; \"the sounds heard in the chamber are indeed echoes of initial opinion.\"95 Jamieson and Cappella note that echo chambers have an upside, which is that they encourage engagement and increase ideological coherence;96 however, they outline the downsides of echo chambers, which are far more numerous: 1. Insulate the audience from alternative media sources by casting them as untrustworthy, \"liberal,\" and rooted in a double standard hostile to conservatives and conservatism. 2. Protect their audience from the influence of those opposed to the conservative message by balkanizing and polarizing their perception of opponents and their arguments 3. Contest only the facts hospitable to opposing views 4. Invite moral outrage by engaging emotion. [...] 5. Replace argument with ridicule and ad hominem 6. Often invite their audiences to see the political world as one unburdened by either ambiguity or common ground across the ideological divide97 They add that: There are consequences at the individual level as well. When one systematically misperceives the positions of those of a supposedly different ideology, one may decide to vote against a candidate with whom, on some issues of importance to both, one actually agrees. A polarized political world is one in which everyone is entitled to his or her own facts, the evidentiary grounds for political discussion are lost, and there is as a result no point in attempting to deliberate across ideological lines. In such a world, each side simply asserts its ideology. Neither is open to any good that may reside in the opposition's point of view. Compromise may become a lost art.98 The second question raised by Akin and Landrum regarding phenomena of selection is the way the information itself is presented by the communicator. Framing, according to Druckman and Lupia, refers to the process of distilling complex information to make it intelligible to lay audiences.99 This is done by emphasizing certain details at the detriment of others.100 Cacciatore et al. explain that the concept of framing can be traced back to two largely unrelated research traditions.101 The first is work in psychology led by Kahneman and Tversky, whose 1981 \"Asian disease\" study examined how people responded to equivalent information depending on whether it was presented (i.e. framed) in terms of gains or losses. The study, which asked participants to choose between alternative options for dealing with a deadly disease, found that people were more risk averse when the outcomes were presented in terms of gains (in this case, lives saved) but risk seeking when the same information was presented in terms of loss (in this case, lives lost). Kahneman and Tversky replicated these 85 results across many different issues, and Cacciatore et al write that the results consistently showed \"that human choice is contingent on the description of choice problems, or how information is contextualized, rather than the expected utility of those options.\"102 Since it relies on \"different but logically equivalent words or phrases to produce the framing effect\", work in the tradition of Kahneman and Tversky has been called \"equivalency framing.\"103 There is also a sociological theory of framing, starting with the work of Goffman (1974), followed by Gamson and colleagues.104 Cacciatore et al summarize it as follows: Driven in part by concerns about the ecological validity of equivalence-based framing work, the sociological tradition views framing as a means of understanding how people construct meaning and make sense of the everyday world (Ferree et al., 2002). Goffman (1974) described framing as a method by which individuals apply interpretive schemas to both classify and interpret the information that they encounter in their day-to- day lives, whereas Gamson and Modigliani (1987) defined frames as ''a central organizing idea or story line that provides meaning to an unfolding strip of events. . . . The frame suggests what the controversy is about, the essence of the issue'' (p. 143). Unlike the equivalence-based definition of framing, this sociologically rooted definition moves framing outside of the presentation of logically equivalent information and into territory where the selection of one set of facts or arguments over another can be deemed a frame. 105 Work on emphasis and issue framing, in a wide variety of disciplines, including psychology, behavioural economics, political science, communication, and sociology, has shown that frames influence audiences' evaluation of the material - another departure from rational choice theory. However, framing refers to many different things. In their article, Cacciatore et al. proceed to disentangle the interrelations between different concepts that have been bundled as \"framing\" as a result of the expanded definition of the concept by sociologists, including notions in communication studies such as priming and agenda-setting.106 Dietram A. Scheufele, a co-author of Cacciatore, published a similar paper in 1999, \"Framing as a Theory of Media Effects,\" in which he writes that, because of vague conceptualizations, \"the term framing has been used repeatedly to label similar but distinctly different approaches.\"107 Whatever the precise conceptualization, it is clear that frames play a role in how communication of science is received by audiences; Akin and Landrum write that \"cues embedded in messages that emphasize scientific uncertainty or political disagreement, whether intentional or unintentional, lead audiences to dismiss credible evidence.\"108 In sum, work in this research tradition contributes to understanding the problem of antivaxxers' resistance to science because it shows that the process of forming perceptions of risks and benefits about vaccines in light of scientific evidence is distorted by cognitive biases and heuristics [Figure 5]. 86 In other words, the scientific evidence that is disseminated to persuade antivaxxers is interpreted through the lens of all of these biases and heuristics. For example, the availability heuristic makes an antivax mother overestimate the likelihood that her child will have an adverse reaction to a vaccine, because she readily remembers the stories, widely disseminated in her anti-vaccination social circle, of the rare children who did. The affect heuristic makes her decide on the basis of her extreme emotions at the thought of her child having a seizure, rather than on the scientific evidence that shows that seizures following vaccination are extremely rare. Confirmation bias makes her seek out more stories of children who had such seizures, and find articles and blog posts on the link between vaccines and seizures, and overestimate the value of what she reads in these articles and blog posts, while neglecting or rejecting evidence that comes her way that suggests that seizures following vaccination are extremely rare. It makes her think that the people who tell her this are biased, that they haven't considered all of the evidence, that they have an interest in rejecting contradictory evidence, while failing to see that this is what she is doing, too. She prefers talking to other mothers who share her concerns, and she joins online groups where she and other mothers can reassure each other, confirm that they are acting in the interests of their children, find a sense of community. She is in an echo chamber. Availability, affect, probability neglect, and confirmation bias are just a few of the biases and heuristics that researchers have provided empirical evidence of; dozens more are also at play in the decision-making process of antivaxxers. There are literally hundreds of published studies linking cognitive biases to anti-vaccination attitudes. For example, a 2015 article by Dubov and Phung in Vaccine reviewed how seven cognitive biases are relevant in the context of decisions about influenza vaccination: omission bias, ambiguity aversion, present bias, availability bias, optimism bias, naturalness bias, and protected values.109 Similarly, a study by Pomares et al. (published in 2020 in Human Vaccines & Immunotherapeutics) investigated how vaccine hesitancy and intent to vaccinate are associated with established cognitive biases. They found that \"the presence of certain cognitive biases - conjunction fallacy and sunk cost bias - was associated with lower vaccine hesitancy\" and that \"[i]nformation avoidance and present bias were positively associated with parental vaccine hesitancy.\"110 Moreover, \"lower intent to vaccinate was associated with information avoidance.\"111 A 2020 review by Mendez Luz, Nadanovsky and Leask summarized studies on Figure 5. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on cognitive biases and heuristics 87 how nine cognitive biases and heuristics are linked to anti-vaccination attitudes: the affect heuristic, the availability heuristic, ambiguity aversion, optimism bias, anticipated regret, omission bias, confirmation bias, framing effects, and the Dunning-Krueger effect.112 Another study by LaCour and Davis, published in 2020 in Vaccine, found that vaccine skeptics tended to be less accurate in mortality-related event frequency estimations. They write that: Many other researchers have converged on the conclusion that emotionally negative information is weighted more heavily in people's judgments and decisions [...] Our results suggest that people high in vaccine skepticism may be particularly sensitive to overweighing such negative information, which leads to lower accuracy in estimation of vital statistics. [...] These results suggest that vaccine skepticism may be related to faster, less deliberative processing when it comes to mortality-related or emotionally negative information. By using less deliberative strategies and considering less information before responding, people higher in vaccine skepticism may produce less accurate estimations.113 These are just a few recent examples; there are many others. It is clear that there is no shortage of empirical evidence on the link between cognitive biases and heuristics and anti-vaccination attitudes. Overcoming resistance to science will thus require educating people about the biases and heuristics that hinder their thinking and presenting information in a way that reduces reliance on heuristic reasoning. 88 Key Messages : The psychological approach Human reasoning is far from the flawless, almost robotic enterprise described in rational choice theory. Work across disciplines (notably in behavioral economics) has provided empirical evidence of the numerous cognitive biases and heuristics that lead individuals to make systematic errors in judgment. These phenomena of reasoning include: the availability heuristic, which is the estimation of the frequency or probability of an event based on the ease with which instances of that event come to mind; the affect heuristic, which refers to the effect of positive and negative affective feelings in guiding decision-making and judgment; confirmation bias, i.e. the tendency to selectively gather and give undue weight to evidence that support already held beliefs and to neglect to gather or discount evidence that contradicts these already held beliefs; and bias blind spot, that is, the tendency of individuals to recognize the existence and operation of systematic biases in other people's thinking but not their own. These cognitive biases may be exacerbated by the characteristics of the information sources and contents. A lot has been written on selective exposure, including on \"echo chambers\" which insulates like-minded individuals into a bounded media space where they reinforce each other's beliefs while systematically excluding all outside beliefs. A lot has also been written on framing effects. Antivaxxers interpret the scientific evidence that is disseminated to persuade antivaxxers through the lens of all of these biases and heuristics. 89 REFERENCES: THE PSYCHOLOGICAL APPROACH1 Dan M. Kahan, Dietram A. Scheufele, and Kathleen Hall Jamieson, \"Why Science Communication?\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 1-14, 7. 2 Paul Slovic, The perception of risk. Risk, Society, and Policy Series. (London; Sterling, VA: Earthscan, 2000). 3 Maya J. Goldenberg, Vaccine Hesitancy: Public Trust, Expertise, and the War on Science (Pittsburgh: University of Pittsburgh Press, 2021), 42. 4 Dan M. Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" in Handbook of Risk Theory, eds. S. Roeser, R. Hillerbrand, P. Sandin, and M. Peterson (Dordrecht, Netherlands: Springer Netherlands, 2012). 5 Richard H. Thaler, Misbehaving (New York: W.W. Norton, 2015), 7. 6 Thaler, Misbehaving, 23. 7 Herbert A. Simon, \"A Behavioral Model of Rational Choice,\" The Quarterly Journal of Economics 69, 1 (1955): 99-118, 99. 8 Herbert A. Simon, Administrative Behavior (New York: Macmillan, 1947), 79. 9 Miller, Susan J., David J. Hickson, and David C. Wilson, \"Decision-Making in Organizations,\" in Handbook of Organization Studies, eds. Stewart Clegg, Cynthia Hardy, and Thomas Lawrence (London: Sage, 1996): 294-295. 10 Simon, \"A Behavioral Model of Rational Choice,\" 101. 11 Simon, \"A Behavioral Model of Rational Choice,\" 101. 12 Michael Lewis, The Undoing Project (New York: W.W. Norton, 2016), 103. 13 Lewis, The Undoing Project, 146-147. 14 Lewis, The Undoing Project, 150-151. 15 Lewis, The Undoing Project, 284. 16 Lewis, The Undoing Project, 160. 17 Lewis, The Undoing Project, 341. 18 Lewis, The Undoing Project, 319. 19 Daniel Kahneman, Thinking, Fast and Slow. (New York: Farrar, Straus and Giroux, 2011), 9-10. 20 Kahneman, Thinking, Fast and Slow, 8. 21 Thomas Kuhn, The Structure of Scientific Revolutions. (Chicago: University of Chicago Press, 1962). 22 Kahneman, Thinking, Fast and Slow, 35. 23 Kahneman, Thinking, Fast and Slow, 20-21. 24 Cass R. Sunstein, \"Probability Neglect: Emotions, Worst Cases, and Law,\" The Yale Law Journal 112, 1 (2002): 61-107, 85. 25 Kahneman, Thinking, Fast and Slow, 25. 26 Kahneman, Thinking, Fast and Slow, 28. 27 Kate Kenski, \"Overcoming Confirmation and Blind Spot Biases When Communicating Science\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 369-376, 370. 28 Kahneman, Thinking, Fast and Slow, 25. 29 Kenski, \"Overcoming Confirmation and Blind Spot Biases When Communicating Science,\" 370. 30 Kenski, \"Overcoming Confirmation and Blind Spot Biases When Communicating Science,\" 370. 31 Heather Akin and Asheley R. Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges to Communicating Science\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, and Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges to Science,\" 455. 33 Akin and Landrum, \"A Recap: Heuristics, Biases, Values, and Science,\" 456. 34 Sunstein, \"Probability Neglect: Emotions, Worst Cases, and Law,\" 63-64. 35 Kahneman, Thinking, Fast and Slow, 142. 36 Amos Tversky and Daniel Kahneman, \"Availability: A Heuristic for Judging Frequency and Probability,\" Cognitive Psychology 5 (1973): 207-232, 208. 37 Akin and Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges to Science,\" 457. 38 Tversky and Kahneman, \"Availability: A Heuristic for Judging Frequency and Probability,\" 208-209. 39 Kahneman, Thinking, Fast and Slow, 8. 40 Kahneman, Thinking, Fast and Slow, 142. 41 Akin and Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges to Communicating Science,\" 457. 42 Kahneman, Thinking, Fast and Slow, 138-139. 43 Paul Slovic, Melissa L. Finucane, Ellen Peters, and Donald G. MacGregor, \"The affect heuristic,\" European Journal of Operational Research 177 1333-1352, 1333. Slovic, heuristic,\" 1336. 45 Kahneman, Thinking, Fast and Slow, 139. 46 Kahneman, Thinking, Fast and Slow, 144. 47 Sunstein, \"Probability Neglect: Emotions, Worst Cases, and Law,\" 84. 90 48 Sunstein, \"Probability Neglect: Emotions, Worst Cases, and Law,\" 63. 49 Sunstein, \"Probability Neglect: Emotions, Worst Cases, and Law,\" 63. 50 Bruce W. Hardy and Kathleen Hall Jamieson, \"Overcoming Biases in Processing of Time Series Data About Climate\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 399-408, 404. 51 Ellen Peters, \"Overcoming Innumeracy and the Use of Heuristics When Communicating Science\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) Emotions, Worst Cases, 53 Oswald and Stefan Grosjean, \"Confirmation Bias\" in Cognitive Illusions: A Handbook on Fallacies and Biases in Thinking, Judgment and Memory, ed. R.F. Pohl (Hove, England; New York: Psychology Press, 2004), 79-96, 79. 54 Kenski, \"Overcoming Confirmation and Blind Spot Biases When Communicating Science,\" 371. 55 Akin and Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges to Communicating Science,\" 457. 56 Oswald and Grosjean, \"Confirmation Bias,\" 80. 57 Raymond S. Nickerson, \"Confirmation Bias: A Ubiquitous Phenomenon in Many Guises,\" Review of General Psychology 2, 2 (1998): 175-220, 175. 58 Oswald and Grosjean, \"Confirmation Bias,\" Nickerson, \"Confirmation Bias: Many Guises,\" 175. 61 Nickerson, \"Confirmation Bias: A Ubiquitous Phenomenon in Many Guises,\" 175. 62 Nickerson, \"Confirmation Bias: A Ubiquitous Phenomenon in Many Guises,\" 197. 63 Nickerson, \"Confirmation Bias: A Ubiquitous Phenomenon in Many Guises,\" 197. 64 Natalie Jomini Stroud, \"Understanding and Overcoming Selective Exposure and Judgment When Communicating About Science\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) Kunda, \"The Case for Bulletin 108, 3 (1990): 480-498. 66 Kenski, \"Overcoming Confirmation and Blind Spot Biases When Communicating Science,\" 369. 67 Kenski, \"Overcoming Confirmation and Blind Spot Biases When Communicating Science,\" 371. 68 Kahneman, Thinking, Fast and Slow, 87-88. 69 Kahneman, Thinking, Fast and Slow, 87-88. 70 Kenski, \"Overcoming Confirmation and Blind Spot Biases When Communicating Science,\" 372. 71 Brendan Nyhan and Jason Reifler, \"Does correcting myths about the flu vaccine work? An experimental evaluation of the effects of corrective information,\" Vaccine 33 (2015): 459-464. 72 Emily Pronin, Daniel Y. Lin, and Lee Ross, \"The Bias Blind Spot: Perceptions of Bias in Self Versus Others,\" Personality and Social Psychology Bulletin 28, 3 (2002): 369-381. 73 Kenski, \"Overcoming Confirmation and Blind Spot Biases When Communicating Science,\" 371. 74 Pronin, Lin, and Ross, \"The Bias Blind Spot: Perceptions of Bias in Self Versus Others,\" 369-370. 75 Pronin, Lin, and Ross, \"The Bias Blind Spot: Perceptions of Bias in Self Versus Others,\" 378. 76 Kenski, \"Overcoming Confirmation and Blind Spot Biases When Communicating Science,\" 372. 77 Pronin, Lin, and Ross, \"The Bias Blind Spot: Perceptions of Bias in Self Versus Others,\" 379. 78 Akin and Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges to Communicating Science,\" 455. 79 Stroud, \"Understanding and Overcoming Selective Exposure and Judgment When Communicating About Science,\" 377. 80 Akin and Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges 456. 81 Akin and Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges to Science,\" 456. 82 Cass R. Sunstein, Republic.com (Princeton, NJ: Princeton University Press, 2001); Cass R. Sunstein, Going to Extremes: How Like Minds Unite and Divide (Oxford: Oxford University Press, 2009); Republic.com 2.0. (Princeton, NJ: Princeton University, 2009). 83 Kathleen Hall Jamieson and Joseph N. Cappella. Echo Chamber: Rush Limbaugh and the Conservative Media Establishment (New York: Oxford University Press, 2008). 84 C. Thi Nguyen, \"Echo Chambers and Epistemic Bubbles,\" Episteme 17, 2 (2020): 141-161. 85 Elo Pariser, The Filter Bubble: How the New Personalized Web is Changing What We Read and How We Think (New York: Penguin, 2011). 86 Nguyen, \"Echo Chambers and Epistemic Bubbles.\" 87 Jamieson and Cappella, Echo Chamber, 76. 88 Nguyen, \"Echo Chambers and Epistemic Bubbles,\" 143. 89 Nguyen, \"Echo Chambers 90 Nguyen, \"Echo Chambers and Epistemic Bubbles,\" 149. 91 Jamieson and Cappella, Echo Chamber, 178. 92 Jamieson and Cappella, Echo Chamber, 82. 91 93 Jamieson and Cappella, Echo Chamber, 83. 94 Jamieson and Cappella, Echo Chamber, 237. 95 Jamieson and Cappella, Echo Chamber, 83. 96 Jamieson and Cappella, Echo Chamber, 247. 97 Jamieson and Cappella, Echo Chamber, 245-246. 98 Jamieson and Cappella, Echo Chamber, 246. 99 Akin and Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges 456. 100 Akin and Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges to Science,\" 456. 101 Michael A. Cacciatore, Dietram A. Scheufele, and Shanto Iyengar, \"The End of Framing as we Know it... and the Future of Media Effects,\" Mass Communication and Society 19, 1 (2016): 7-23, 10. 102 Cacciatore, Scheufele, and Iyengar, \"The End of Framing as we Know it... and the Future of Media Effects,\" 10. 103 Cacciatore, Scheufele, and Iyengar, \"The End of Framing as we Know it... and the Future of Media Effects,\" 10. 104 Cacciatore, Scheufele, and Iyengar, \"The End of Framing as we Know it... and the Future of Media Effects,\" 10. 105 Cacciatore, Scheufele, and Iyengar, \"The End of Framing as we Know it... and the Future of Media Effects,\" 10. 106 Cacciatore, Scheufele, and Iyengar, \"The End of Framing as we Know it... and the Future of Media Effects,\" 11. 107 Dietram A. Scheufele, \"Framing as a Theory of Media Effects\" Journal of Communication 49, 1 (1999): 103-122, 103. 108 Akin and Landrum, \"A Recap: Heuristics, Biases, Values, and Other Challenges to Communicating Science,\" 457. 109 Alex Dubov and Connie Phung, \"Nudges or mandates? The ethics of mandatory flu vaccination,\" Vaccine 33(2015): 2530-2535, 2533. 110 Tiffany D. Pomares, Alison M. Buttenheim, Avnika B. Amin, Caroline M. Joyce, Rachael M. Porter, Robert A. Bednarczyk, and Saad B. Omer, \"Association of cognitive biases with human papillomavirus vaccine hesitancy: a cross-sectional study,\" Human Vaccines & Immunotherapeutics 5 (2020): 1018-1023, 1021. 111 Pomares et al, \"Association of cognitive with human papillomavirus vaccine hesitancy: a cross-sectional study,\" 1021. and and Tyler Davis, \"Vaccine skepticism reflects basic cognitive differences in mortality-related event frequency estimation,\" Vaccine 38 (2020) : 3790-3799, 3797. 92 4.3. The Cultural Theory of Risk and Cultural Cognition The knowledge deficit model and the psychological approach, while different, both stress individual, cognitive influences to explain resistance to science. The cultural theory of risk, meanwhile, stresses sociocultural influences. Cultural theory was first articulated by anthropologist Mary Douglas in her book Natural Symbols, in 1970; she further developed and clarified the theory with political scientist Aaron Wildavsky in their 1982 seminal book Risk and Culture, which Tansey and O'Riordan describe as the \"key text for understanding the origins of cultural theory.\"1 Douglas and Wildavsky were critical of the two other prominent approaches I have presented.2 The knowledge deficit model, which is grounded in rational choice theory, sees resistance to science as the result of an individual's implicit risk/benefit analysis (the problem being chiefly that the analysis is done in a situation of lack of information). According to Douglas and Wildavsky, this approach is problematic because it is oblivious to how \"cultural ways of life\" influence what situations individuals are willing to take risks to attain: \"To ask which is the correct description of rational behavior (that is, to ask what the real risks are) leads to an answer which finds irrational bias and misperceptions of real interest in the viewpoint of anyone who disagrees. Instead, cultural analysis shows how a given cluster of values and beliefs makes sense out of the various positions people take...\"3 Douglas and Wildavsky also criticized the psychological approach, according to which resistance to science can be attributed to the warping of the risk/benefit analysis by biases and heuristics. They argued that the way this approach \"depoliticizes\" risk perception is naive: \"Acceptability is always a political issue... Since there is no single correct conception of risk, there is no way to get everyone else to accept 'it'.\"4 The psychological approach fails to recognize that these cognitive biases and heuristics are reflections of commitments to competing cultural ways of life. In sum: \"Cultural theory does not question the validity of technical procedures for hazard identification [...] What cultural theory does do is to criticize the apparent depoliticization of risk issues - the subtle process of taking for granted the link between hazard identification and the normative choices that follow.\"5 Cultural theory is thus one of multiple ways to interpret how and why individuals make certain judgments about risks.6 It seeks to explain why some issues about risks are politicized and others not by proposing a framework that elucidates how these issues are constructed and selected.7 Tansey and O'Riordan explain that \"[t]he point of the theory is to show that such judgments are not formed independently of social contexts.\"8 Douglas and Wildavsky's thesis could not be clearer when they state that \"the perception of risk is a social process,\"9 and, later in their book, that \"public perception of risk and 93 its acceptable levels are collective constructs, a bit like language and a bit like aesthetic judgment.\"10 Douglas and Wildavsky write that: This book is about how particular kinds of danger come to be selected for attention. [...] Our book is about why, at this time, pollution has been singled out for special concern. Our answer will be that the choice of risks to worry about depends on the social forms selected. The choice of risks and the choice of how to live are taken together. Each form of social life has its own typical risk portfolio. Common values lead to common fears (and, by implication, to a common agreement not to fear other things). There is no gap between perception and reality and no correct description of the right behavior, at least not in advance. The real dangers are not known until afterward (there always being alternative hypotheses). In the meantime, acting in the present to ward off future dangers, each social arrangement elevates some risks to a high peak and depresses other below sight. This cultural bias is integral to social organization. Risk taking and risk aversion, shared confidence and shared fears, are part of the dialogue on how best to organize social relations.11 The theory is the following: through social interactions, people develop solidarities in terms of outlooks. Culture, then, is a shared outlook or interpretive framework; it is the common way in which a community imposes an order on reality and makes sense of the world.12 Social structures, which Douglas and Wildavsky call \"ways of life,\" produce attitudes about the world (\"cultural biases\") that support and sustain this way of life. In Risk and Culture, Douglas and Wildavsky explain that ways of life vary along two cross-cutting dimensions or axes, \"grid\" and \"group\" [Figure 6]. Group refers to \"the extent to which an individual is incorporated into bounded units\" or, to put it another way, the degree of solidarity among members of the society: \"[t]he greater the incorporation, the more individual choice is subject to group determination.\"13 A \"strong group\" way of life implies a high degree of collective control: \"people interact frequently in a wide range of activities\" and \"depend on one another\" to achieve their ends.14 In a \"weak group\" way of life, independence and self-sufficiency matter more; it \"inclines people toward an individualistic worldview, highly competitive in nature, in which people are expected to fend for themselves without collective assistance or interference.\"15 Grid refers to \"the degree to which an individual's life is circumscribed by externally imposed prescriptions\" (i.e. their position in society).16 A \"high grid\" way of life is defined by evident and durable social stratification, with some strata possessing more power and authority: \"Goods and offices, duties and entitlements, are all 'distributed on the basis of explicit public social classifications' [...] It thus conduces to a 'hierarchic' worldview that disposes people to 'devote a great deal of attention to maintaining' the rank-based 'constraints' that underwrite 'their own position and interests.'\"17 A \"low grid\" way of life is defined by egalitarianism; it is \"an egalitarian state of affairs in which no one is prevented from participation in any social role.\"18 This group-grid scheme delineates four main ways of life, each in its quadrant of the matrix: individualist (low grid, weak group), egalitarian (low grid, strong group), hierarchist (high grid, strong group), and fatalist (high grid, weak group). A fifth, asocial \"autonomous\" way of life is sometimes added to the grid. This typology is perhaps the best known element of Douglas and Wildavsky's theory.19 94 Cultural theory hypothesizes that individuals will most likely form risk perceptions that reflect and strengthen their way of life [Figure 7].20 The theory makes two main assertions about the link between ways of life and perceptions of risk: first, that \"discrete constellations of perceived risk tend to cohere better with one or another way of life\";21 second, that \"individuals gravitate toward perceptions of risk that advance the way of life to which they are committed.\"22 Douglas and Wildavsky write that: \"Once the idea is accepted that people select their awareness of certain dangers to conform with a specific way of life, it follows that people who adhere to different forms of social organization are disposed to take (and avoid) different kinds of risk. To alter risk selection and risk perception, then, would depend on changing the social organization.\"23 Each way of life has its risk portfolio, and conflicts over risks are essentially part of an \"ongoing debate about the ideal society.\"24 Figure 6. - Douglas and Wildavsky's group-grid scheme Source: Dan M. Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk\" (2012) 95 As an approach to understand why dissemination of scientific evidence fails to change the behaviour of antivaxxers, cultural theory is thus a stark departure from the individual, cognition-based approaches that I have summarized so far. As Kahan notes: One prominent position asserts that individuals (in aggregate, and over time) process information in a manner consistent with expected utility (Viscusi 1983). An opposing view holds that individuals systematically mis-process risk information as a result of cognitive limits and biases (Sunstein 2005). These theories generate different predictions about the influences that determine risk perception, but neither predicts that cultural worldviews will be one of them.25 In recent years, Dan Kahan and his colleagues, including Donald Braman, Geoffrey Cohen, John Gastil, and Paul Slovic (who pioneered work on cognitive biases and heuristics),26 advanced a new theory that bridges the gap between the psychological approach (or \"psychometric paradigm\") and cultural theory. \"Cultural cognition\" - which Kahan calls \"the descendent\" of these two approaches27 - posits that the biases and heuristics of the psychological approach are the mechanisms through which culture (i.e. group-grid worldviews) shapes risk perception [Figure 8]. As Kahan explains in multiple articles,28 cultural cognition improves both approaches by combining them: Cultural cognition attempts to fuse the cultural theory of risk and the psychometric paradigm in ways that permit each to answer questions posed by but not satisfactorily addressed by the other. The psychometric paradigm [...] furnishes an account of the individual-level mechanisms through which cultural values shape risk perceptions [...] For its part, cultural theory remedies the psychometric paradigm with a much-needed theory of individual differences: the interaction of values with the psychological mechanisms featured in the psychometric position explain how one and the same dynamic - whether affect, availability, biased assimilation, source credibility, or others - can nevertheless produce diametrically opposed risk perceptions in different people and indeed intense forms of polarization across groups of persons.29 Figure 7. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on the cultural theory of risk Figure 8. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on cultural cognition 96 Since the publication of Risk and Culture nearly forty years ago, a lot of empirical research has tested the relationship between ways of life and risk perception.30 But this stream of literature is plagued by a tough methodological issue: measuring cultural worldviews.31 Indeed, as Kahan explains in \"Cultural Cognition as a Conception of the Cultural Theory of Risk\" (2012), the first to publish empirical studies of cultural theory and develop a measure of cultural worldviews was a student of Wildavsky's, Karl Dake.32 Dake used items from public opinion surveys to create scales to measure the worldviews of the grid-group matrix: at first the \"Egalitarianism\" worldviews, and then \"Fatalism\" as well.33 As Kahan observes, there are two problems with this scale. The first problem is reliability: Dake did not provide measures for it, and subsequent research found that it fails on scale reliability tests like Cronbach's alpha.34 The second problem is a conceptual one about the validity of the scale: When one uses separate scales to measure each group-grid worldview, it becomes theoretically possible for a single individual to exhibit multiple, competing orientations - for example, to be simultaneously both a hierarchist and an egalitarian. Indeed, most likely because the items associated with discrete scales do not reflect a high degree of coherence or international consistency; it's not uncommon for subjects to have high scores on competing scales...35 The first thing that cultural cognition theory does is to fix these measuring problems. While some researchers, including Jenkins-Smith, have refined Dake's measures significantly, cultural cognition proposes an altogether different strategy to measure cultural worldviews that avoids these psychometric and conceptual measuring problems.36 The cultural cognition strategy relies on two continuous attitudinal scales: \"hierarchy-egalitarianism\" measures an individual's orientation toward high or low grid, while \"individualism-communitarianism\" measures an individual's orientation toward strong or weak group.37 Multiple studies by Kahan and others have shown that these scales are highly reliable.38 Moreover: They also avoid the logical indeterminacy problem associated with variants of Dake's original measures. When one uses a single scale for group and a single scale for grid, each individual respondent's worldview is identified with a unique point or coordinate in the \"culture space\" demarcated by the intersection of group and grid.39 Because the scales are continuous, they make it possible to simultaneously and precisely map the position of an individual on both axes, instead of classifying them in broad categories [Figure 9]. This measure of cultural worldviews is thus more powerful and sophisticated. 97 To designate ways of life, cultural cognition offers new labels in accordance with the the scales are continuous, some have argued that the cultural cognition approach implies \"an infinite number of ways of life formed by congregations of persons around any coordinate in the group-grid map.\"40 However, Kahan writes: A certain measure of heterogeneity among individuals is perfectly consistent with there being aggregations of persons who exert a dominant influence on social structures and affiliated worldviews (Braman et al. 2005). Under either of these conditions, we would expect individuals to form packages of risk perceptions characteristic of their groups in proportion to the strength or degree of attachment to the cultural groups with whom they are most closely affiliated [...] My collaborators and I take a pragmatic attitude: we are more interested in finding a scheme for measuring cultural worldviews that is internally valid and that has explanatory utility than in finding one that fits a profile dictated by axiomatic, abstract theorizing.41 From a methodological standpoint, two other things must be said about cultural cognition. The first is that cultural cognition sees cultural worldviews as \"latent predispositions\" of individuals, not of institutions as others - namely, Rayner and Thompson - have argued.42 Cultural worldviews are not directly observable, but they can be assessed indirectly through the proxy of measurable, professed attitudes.43 The second is that the measures were developed to study variation in risk perception in Americans. Critics of cultural cognition, including Douglas (who suggested that the group-grid matrix was universal) have deplored the decidedly \"American feel\" of the scale items.44 Kahan recognizes that the measures are adapted to US population samples, but rejects the argument that this is problematic. Even if one admits that the constructs of cultural theory's goup-grid matrix apply across place and time, argues Kahan, \"[i]t is Figure 9. - Cultural cognition map Source: Dan M. Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk\" (2012) 98 another matter entirely to say that the indicators of the latent dispositions associated with these worldviews must be the same everywhere and forever.\"45 He concludes: \"the validity - and value - of a theory that predicts that individuals of opposing predispositions will mobilize themselves into opposing factions over risk doesn't depend on it being able to say, in a manner oblivious to the historical circumstances of such people, what the dispute will be about...\"46 Overall, then, cultural cognition, while it uses cultural theory's basic grid-group scheme, proposes an improved methodology to measure the cultural worldviews that the scheme represents. The second thing is that cultural cognition goes beyond methodology. Kahan's theory of cultural cognition brings together the work on cognitive biases and heuristics and the work of culture theorists by suggesting that heuristics interact with cultural values.47 Douglas and Wildavsky's theory was functionalist: they argued that individuals form beliefs about risk in accordance with their way of life because having these beliefs is in accordance with (and promotes) their way of life. Kahan notes that this type of reasoning is typical of classical sociological theories of ideology but has aged badly because contemporary social scientists see it as \"implausibly attributing agency to collective entities.\"48 Cultural cognition seeks a more profound answer to why individuals tend to form perceptions of risk that are congenial to their way of life. The thesis of cultural cognition is that the set of cognitive biases and heuristics identified by the psychological approach are the mechanisms through which cultural worldviews shape perceptions of risk. In Kahan's words: The mechanisms hypothesis is that worldviews yield risk perceptions through a set of social and psychological processes. These processes are well-established; they are the heart of the \"psychometric paradigm\" [...] What hasn't been fully recognized until now, our research suggests, is how these social and psychological processes interact with cultural ways of life, generating individual differences in risk perception between people who subscribe to competing worldviews [...] [T]his is not a functionalist account because the social and psychological processes associated with the psychometric paradigm, although different from the ones stressed by rational choice economics, don't treat the needs of collective entities as the causes of individual behavior but instead derive collective behavior from the interaction of individuals self-consciously pursuing fulfillment of their own ends...49 To explain it differently, the impact of cognitive biases and heuristics on perceptions of risk will vary according to worldviews. Cultural worldviews shape perceptions of risk because cognitive biases and heuristics enable them to. Five particular mechanisms of cultural cognition have been the object of thorough study: identity-protective cognition, biased assimilation and group polarization, cultural credibility, cultural availability, and cultural identity affirmation. Cultural identity-protective cognition (IPC) is defined as the propensity of individuals to match their views to those of other individuals with whom they share a self-identifying, cultural commitment. Being part of a group provides not only material but also nonmaterial benefits such as status and self- 99 esteem. In order to protect their ties to their group and retain this \"social capital,\" individual conform their beliefs to those of others in their group: Challenges to commonly held group beliefs can undermine a person's well-being either by threatening to drive a wedge between that person and other group members, by interfering with important practices within the group, or by impugning the social competence (and thus the esteem-conferring capacity) of a group generally. Accordingly, as a means of identity self-defense, individuals appraise information in a manner that buttresses beliefs associated with belonging to particular groups.50 Kahan calls this an \"individually rational strategy of belief formation,\"51 when one considers the costs associated with conforming versus not conforming. Indeed, holding factually incorrect beliefs on most matters often does not have very negative consequences for individuals concerning the risks they face or those risks increasing or diminishing. But, \"given what beliefs on these subjects (correct or incorrect) have come to signify about the kind of person one is - about whose side one is on, in what has become a struggle for status among competing cultural groups - the personal cost of forming the wrong ones in relation to one's own cultural identity could be punishingly high.\"52 Kahan has conducted multiple studies on cultural IPC, including in 2007 when he looked into the \"white male effect,\" a well-documented pattern according to which \"white men fear various risks less than women and minorities.\"53 Kahan's statistical analyses, which were based on a survey answered by a nationally-representative sample of 1800 respondents, showed that the white male effect \"could be explained as a form of motivated cognition aimed at protecting identities individuals form through their commitment to cultural norms.\"54 When controlling for cultural orientations, other attributes such as gender and race were no longer significantly associated with particular risk perceptions: Each type of risk perception had the hypothesized relationship with cultural worldview. [...] These effects were all large, moreover, relative to that of other individual characteristics that might be thought to bear on risk perception, including other group affiliations (such as political party affiliation and religion) that might be expected to produce identity-protective cognition. Demographic variance in risk perceptions, we found, grew out of cultural variance. Gender affects risk perception only in conjunction with particular worldviews. [...] Racial disparities were also highly dependent on culture.55 Kahan concludes: \"our data suggest the need for expressively sophisticated modes of risk communication, ones that avoid identity-protective resistance to public acceptance of empirically sound risk information.\"56 Biased assimilation and group polarization is an information processing dynamic where individuals have an unconscious motivation to persist in their beliefs and, as such, they selectively seek out and accept evidence that reinforces their beliefs, while dismissing as non-credible evidence that is contrary to these beliefs.57 The result of this biased assimilation is that individuals \"tend to harden in their views when exposed to a portfolio of arguments that variously support and challenge their views.\"58 Also, \"[b]y the same token, when groups of individuals who are motivated to persist in opposing beliefs are exposed to balanced information, they don't converge in their views [...] they polarize.\"59 Their divide widens when 100 exposed to balanced information.60 It also widens in the presence of cues that suggest that a certain issue is at the center of a conflict between groups.61 Kahan's 2009 study on biased assimilation and group polarization revealed something else. Conventional literature about biased assimilation, such as the literature that I presented earlier on confirmation bias, posits that individuals assimilate information biasedly to confirm their prior held beliefs. But in Kahan's study, which focused on nanotechnology, most respondents knew next to nothing about nanotechnology. Biased assimilation did not support prior held beliefs, because they had no prior held beliefs; it supported a certain predisposition toward risk. Moreover, public opinion surveys have repeatedly found that those who knew more about nanotechnology had a more positive view of it. This has led some to argue, as many have done regarding scientific literacy in general, that disseminating more information about nanotechnology would lead to people developing more positive attitudes towards it. The results of Kahan's study do not support this hypothesis. Those who claimed to know more about nanotechnology indeed had a more positive attitude than those who did not, but when exposed to information, those who started out not knowing about nanotechnology did not all react positively; their attitude depended on their cultural worldview. In addition, Kahan found that those who reported knowing more about nanotechnology, on average, rated most risks as low. Kahan explains that: This is the signature of spurious correlation: information about nanotechnology is not causing individuals to see guns, the Internet, genetically modified foods, nuclear power, and so forth, as safe; some third influence is causing people both to form the view that these risks are low and to become interested enough in nanotechnology to learn about it before others do.62 This apparent causal connection between information about nanotechnology and risk perception is caused by a third, confounding factor that makes individuals seek out information about nanotechnology as well as consider it as presenting little risk: cultural worldview.63 To put it another way, individuals' cultural predispositions \"both affect the likelihood of information exposure and moderate how information affects risk-benefit perceptions.\" [Figure 10 and Figure 11]64 Kahan concludes: \"Our study reinforces the conclusions of other researchers who have cautioned against assuming that enlightened public opinion will spontaneously emerge from accumulating scientific information on the risks and benefits of nanotechnology.\"65 Source: Dan M. Kahan, Donald Braman, Paul Slovic, John Gastil and Geoffrey Cohen, \"Cultural cognition of the risks and benefits of nanotechnology\" (2009) Figure 10. - Relationships between cultural predisposition, information exposure and risk-benefit perception 101 In sum, Kahan summarizes his findings about biased assimilation and polarization like this: Individuals bear cultural predisposition toward risk - a tendency (founded on identity-protective cognition) to view some risk claims more congenial than others on the basis of latent characteristics indicated by values they share with others. This predisposition not only endows culturally diverse individuals with opposing \"prior\" beliefs about risk. It also decisively regulates their experience with information about the truth or falsity of those beliefs. People with opposing predispositions seek out support for their competing views through opposingly biased forms of information search. What's more, they construe or assimilate information, whatever its provenance, in opposing ways that reinforce the risk perceptions they are predisposed to form. As a result, individuals end up in a state of cultural conflict - not over values, but over facts - that mere accumulation of empirical data cannot be expected readily to dispel.66 Identity-protective cognition is exacerbated in the context of the attention economy, which is based on algorithms that are inherently creators of online echo chambers. Clearly, even without social media, individuals interact much more with other individuals who share important cultural commitments with them than with those who don't. But social media algorithms entrench this pattern and make it nearly impossible for individuals to be exposed online to information that contradicts their beliefs. In this context, as Kahan observes, deliberate misinformation by third parties is not necessary.67 If biased assimilation is cultural cognition theory's take on confirmation bias, cultural availability is its take on Kahneman and Tversky's availability effect. The basic idea is the same: \"If instances of some fact or contingency relevant to the risk are highly salient, individuals are more likely to notice, assign significance to, and remember them. When they are required to consider the incidence of such a contingency thereafter, the ease with which those instances can be recalled will induce individuals to overestimate their occurrence.\"68 However, as with confirmation bias, cultural cognition theory offers a more complex explanation of the mechanisms behind the effect. In this case, there was an obvious gap in the classic literature on availability, which cultural cognition could fill: why do some things have sufficient saliency to trigger the availability effect, and others not?69 Kahneman, Tversky, and Sunstein provided an answer to this question when they talked about availability cascades. According to this view, disproportionate media coverage is to blame for how \"available\" negligible risks are in people's minds. But, as Kahan notes, this explanation is unsatisfying, Figure 11. - The KAP or knowledge deficit model of diffusion of scientific evidence, adapted in accordance with the stream of literature on cultural cognition 102 because media coverage is \"a market-driven reflection of the public demand\" for news of the risk in question, not the cause of that demand.70 Kahan points out that individuals can agree on the horror of some media images while still disagreeing about the risk issue represented by the images; for example, most people find images of a school massacre or a terrorist attack horrific, but many of these people still disagree on the risk these events represent, and consequently on the solutions to implement.71 Cultural cognition suggests that culture is what makes people \"attach differential significance to salient, readily available instances of some contingency\":72 If people are more likely to notice risk-related contingencies congenial to their cultural predispositions, to assign them significance consistent with their cultural predispositions, and recall instances of them when doing so is supportive of their cultural predispositions, then the availability effect will generate systematic individual differences among culturally diverse individuals.73 The article where Kahan and his colleagues developed their theory of cultural availability focused on conflict over scientific consensus,74 which is highly relevant to the case of antivaxxers since the literature on the safety and efficacy of vaccines is a textbook example of scientific consensus. Their hypothesis was the following: Scientific opinion fails to quiet societal dispute on such issues not because members of the public are unwilling to defer to experts but because culturally diverse persons tend to form opposing perceptions of what experts believe. Individuals systematically overestimate the degree of scientific support for positions they are culturally predisposed to accept as a result of a cultural availability effect that influences how readily they can recall instances of expert endorsement of those positions.75 Their results suggest that when individuals have to weigh the views of experts about a topic - which we have to do when it comes to myriad scientific issues that are too complex and on which we must trust experts - they are likely to overestimate the number of experts whose views are consistent with their cultural predisposition.76 Cultural credibility is intricately linked to cultural availability. It refers to \"the hypothesized tendency of individuals to impute the sorts of qualities that make an expert credible - including knowledge, honesty, and shared interest - to the people whom they perceive as sharing their values.\"77 The public cannot be expected to comprehend all decision-relevant science. And while, as advocates of scientific literacy stress, critical reasoning skills matter, how laypeople really acquire the insights of decision-relevant science is by recognizing valid sources of science. The problem, then, is not so much one of scientific literacy, but one of valid expertise recognition: \"disagreement about what evidence counts as valid and what it implies is precisely what accounts for the persistent contestation associated with the science communication problem.\"78 If cultural availability is about what evidence and how many experts come to an individual's mind about a certain topic, cultural credibility is about which individuals are deemed credible experts. Kahan states that: 103 ...no group understands itself to be 'rejecting' the weight of scientific opinion on any of the issues featured in the science communication problem. That these groups are forming such unreliable judgments on what scientists' consensus is, however, suggests that something is disabling their members from correctly assessing information about what genuine experts believe on these matters.79 What is impeding these groups' ability to recognize valid expertise, Kahan argues, is cultural cognition. Individuals evaluate the strength of an expert's arguments based on how credible they deem that individual to be, and \"cultural affinity and cultural difference supply the relevant in-group/out-groups references that in turn determine whom people see as knowledgeable, honest, and unbiased, and thus worthy of being credited in debates about risk.\"80 In sum, cultural cognition influences perceptions of credibility, with individuals being more willing to trust experts they perceive as sharing their worldviews. Thus, \"scientific consensus cannot be expected to counteract the polarizing effects of cultural cognition because apprehension of it will necessarily occur through the same social psychological mechanisms that shape individuals' perceptions\" of everything else.81 The fifth mechanism of cultural cognition is cultural identity affirmation. Cultural identity affirmation is, in a way, the flip side of the coin of identity-protective cognition. IPC makes individuals match their beliefs to those of their group and dismiss information which threatens that membership and sense of identity. Cultural identity affirmation, meanwhile, is based on self-affirmation. It refers to a situation where: ...individuals experience a stimulus [...] that makes a worthy trait of theirs salient to them. This affirming experience creates a boost in a person's self-worth and self-esteem that essentially buffers the sense of threat he or she would otherwise experience while confronted with information that challenges beliefs dominant within an important reference group. As a result, individuals react in a more open-minded way to potentially identity-threatening information, and often experience a durable change in their prior beliefs.82 For the purposes of this review, one last thing might said about cultural cognition and about the differences between cultural cognition and cultural theory. Work on cultural cognition goes beyond the diagnosis of a problematic resistance to scientific evidence: it looks into ways to overcome it, including cultural identity affirmation. Cultural theory was decidedly pessimistic; according to Douglas and Wildavsky, conflict over risk is unavoidable: \"Because there is no culture-free perspective, it is not possible for individuals to 'overcome' reliance on their worldviews in apprehending risks.\"83 But, as Kahan explains, overcoming conflicts over risk doesn't depend on overcoming cultural commitments: Nothing in [cultural cognition's] account of the mechanisms that connect culture to risk perceptions implies that those dynamics are exclusive to others that might inform individual apprehension of risk. Nor does anything in that account entail that the contribution that alternative cultural worldviews make to risk perception are static and relentlessly oppositional.84 The Cultural Cognition Project, which Kahan leads, conducted a series of nationally-representative surveys and experiments (with around 5000 American respondents), which had two explicit goals: first, to further examine the mechanisms of cultural cognition, i.e. the social and psychological mechanisms through 104 which culture shapes risk perceptions; and second, \"to determine what sorts of techniques for providing information might counteract or neutralize cultural cognition.\"85 This latter goal is as much a central pillar of the Cultural Cognition Project as the former. Two potential strategies stand out in cultural cognition literature. The first is framing the information in a way that makes it \"bear a plurality of meanings\" that different, opposing cultural groups can all endorse.86 Kahan underscores that \"communicators must attend to the cultural meaning as well as the scientific content of information.\"87 The second strategy \"suggests the value of structuring democratic deliberation in ways that effectively lessen participants' reliance on culture.\"88 Reliance on cultural cues as heuristics can be \"disabled\" or \"blunted\": [W]hen people's cultural identities are affirmed, they don't experience the threatening affective response, or are less influenced by it, as they consider information that challenges beliefs that predominate in their group; when they can't discern a consistent connection between the cultural identity of advocates and positions on some risk issue, they can't simply adopt the position of the advocate whom they perceive as having values most like theirs. [...] [I]ndividuals will be forced to process information in a different way, maybe in a more considered way, or maybe in a way that reflects other cues that are reliable but not culturally valenced. In the resulting deliberative environment, individuals might not immediately converge on one set of factual beliefs about risks and risk mitigation. But they won't spontaneously split into opposing cultural factions on those matters.89 Overall, then, Kahan and his colleagues' theory of cultural cognition is a more empirical, evidence-based, pragmatic and optimistic conception of Douglas and Wildavsky's cultural theory of risk. Kahan summarizes his approach in this way: There are three features of cultural cognition, I submit, that are distinctive among the various conceptions of cultural theory. One is the way in which cultural cognition measures cultural worldviews, which are the primary explanatory variable in the Douglas-Wildavsky account of risk perceptions. Another is the attention that cultural cognition gives to the mechanisms - social and psychological - that explain how cultural shapes individuals' beliefs about risk. And the third is the practical objective of cultural cognition to promote collective management of public perceptions of risk and the effect of policies for mitigating them.90 Work on cultural cognition thus offers a complex and rigorous diagnosis of the problem of ineffective dissemination of sound scientific evidence while also setting out a blueprint for further research on treating it. Multiple researchers have studied anti-vaccination attitudes specifically from the perspective of cultural theory and cultural cognition. For example, Kahan's 2010 study on the HPV vaccine found that hierarchists (vs. egalitarians) and individualists (vs. communitarians) tended to perceive mandatory vaccination of girls against HPV as a less beneficial and riskier policy; moreover, Kahan found that the hierarchy-egalitarianism dimension more strongly predicted opposition to the policy than the individualism-communitarianism dimension.91 Similarly, a study by Nan and Madden also focusing on HPV found while there was no significant difference in risk perceptions between individualists and communitarians, hierarchy-egalitarianism was \"a robust predictor of risk perception.\"92 In a study 105 examining how \"cultural worldview, a core value centered in an individual's belief system, impinges upon his or her comprehension of th[e] benefits and risks related with vaccines,\"93 Song found that: ...as grid-group cultural theory of risk perception claims, [...] cultural predispositions also significantly influence individuals' perceptions pertaining to vaccine benefits and risks. Those with a strong hierarch orientation tend to envision greater benefits and lesser risk and conceive of a relatively high ratio of benefit to risk when compared to other cultural types. By contrast, those with a fatalist tendency are inclined to emphasize risks and downplay benefits while conceiving of a low vaccination benefit-risk ratio. Situated between hierarchs and fatalists, strong egalitarians are prone to perceive greater benefits, smaller risks, and a higher positive benefit-risk ratio than strong individualists. [...] the vaccine controversy is not solely derived from disagreements on, or the disproportionate distribution of, vaccine-related scientific knowledge and information within the general public, but from disparities in perceptions, or vaccine benefits and risks rooted in individuals' values and beliefs (notably, as this research suggests, in the form of cultural orientations).94 In a study examining the link between cultural worldviews and vaccine policy preferences, Song, Silva, and Jenkins-Smith also found that cultural worldview had an important impact on vaccine policy preferences. Hierarchs and egalitarians are more likely to be pro-vaccination, while individualists and (especially) fatalists tend to oppose this view. Hierarchs advocate mandatory vaccination; disapprove of religious and philosophical exemptions; and believe that government, not parents, should preside over childhood immunizations. By contrast, fatalists are inclined to negate mandatory vaccination policy and uphold religious and philosophical exemptions and the role of parents in determining vaccination of their children. Egalitarians' pro-vaccination inclination is relatively weaker and less consistent than hierarchs', while individualists' anti-vaccination leanings are overall less robust than those of fatalists.95 They add: Many government health authorities and experts believe that people oppose vaccinations because of their own inability to access quality vaccine-related knowledge or due to dissemination of false information. In response, health advocates have tried to enlighten the general public and thereby increase compliance with mandatory vaccination policy, thereby improving public health. Of course, proliferation of quality knowledge and sound information provided by the scientific community is essential. However, the results of this study show that preferences for vaccine-related policies are significantly influenced by individual values and beliefs regarding desirable social relationships, notably in the form of cultural predispositions. Furthermore, from a cultural cognition perspective, individuals' cultural biases work as a set of heuristics in the processing of the information and in the course of reasoning. [...] That is, when individuals with a particular cultural bias encounter new information, they will reinterpret that information through the filters of their own cultural bias and use the results in their reasoning and policy evaluation.96 And while cultural worldview and political ideology are correlated (cultural worldview being a strong predictor of political ideology), cultural worldview better predicts vaccine attitudes than political ideology.97 In these studies, cultural theory and cultural cognition prove to be powerful frameworks to explain different views on vaccination and vaccine mandates. In the words of Kahan, Jenkins-Smith and Braman: \"because the source of the enfeebled power of scientific opinion is different from what is normally thought, the treatment must be something other than what is normally prescribed.\"98 In sum, dissemination of sound scientific evidence, while important, clearly does not suffice. 106 Key Messages : The cultural theory of risk and cultural cognition A third approach to understand why diffusion of scientific evidence fails to persuade antivaxxers is the cultural theory of risk, which posits that individuals likely form risk perceptions that reflect and strengthen their \"way of life\" or \"cultural worldview.\" Cultural theory's best-known feature is perhaps its grid-group matrix, in which each quadrant represents a cultural \"way of life.\" Empirical research has found a correlation between these ways of life (or cultural worldviews) and vaccine attitudes and policy preferences. A more recent theory, cultural cognition, combines cultural theory and the psychological approach by hypothesizing that cognitive biases and heuristics are the mechanisms through which cultural worldviews shape risk perceptions. In other words, worldviews yield risk perceptions through cognitive biases and heuristics. The impact of these biases and heuristics will thus vary according to worldviews. The mechanisms identified by cultural cognition scholars are: cultural identity-protective cognition; biased assimilation and group polarization; cultural availability; cultural credibility; and cultural identity affirmation. Cultural theory and cultural cognition seem to be powerful frameworks to explain different views on vaccination and vaccine mandates, predicting anti-vaccination attitudes better than other variables such as political idelogy. Dissemination of sound scientific evidence, while important, clearly does not suffice. 107 REFERENCES: THE CULTURAL THEORY OF RISK AND CULTURAL COGNITION1 James Tansey and Tim O'Riordan, \"Cultural theory and review,\" Risk (1999): and O'Riordan, \"Cultural theory and risk: a review,\" 72. 3 Mary Douglas and Aaron Wildavsky, Risk and Culture: an essay on the selection of technical and environmental dangers (Berkeley: University of California Press, 1982): 9. 4 Douglas and Wildavsky, Risk and Culture, 4. 5 Tansey and O'Riordan, \"Cultural theory and risk: a \"Cultural \"Cultural O'Riordan, \"Cultural theory and risk: a review,\" 71. 9 Douglas and Wildavsky, Risk and Culture, 6. 10 Douglas and Wildavsky, Risk and Culture, 186. 11 Douglas and Wildavsky, Risk and Culture, 8. 12 Tansey and O'Riordan, \"Cultural theory and risk: a O'Riordan, \"Cultural risk: a review,\" 78. 14 S. Rayner, \"Cultural theory and risk analysis,\" in Social Theories of Risk, eds. S. Krimsky & D. Golding (Westport: Praeger, 1992): 83-115, 87. 15 Dan M. Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" in Handbook of Risk Theory, eds. S. Roeser, R. Hillerbrand, P. Sandin, M. Peterson (Dordrecht, Netherlands: review,\" 78. theory and risk analysis,\" 87. 18 Rayner, \"Cultural and risk analysis,\" 87. Tansey and O'Riordan, \"Cultural theory and risk: a review,\" 77. 20 Dan M. Kahan, Hank Jenkins-Smith, and Donald Braman, \"Cultural cognition of scientific consensus,\" Journal of Risk (February 2011): 147-174, 148. 21 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 728. 22 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 728. 23 Douglas and Wildavsky, Risk and Culture, 9. 24 Douglas and Wildavsky, Risk and Culture, 36. 25 Dan M. Kahan, Donald Braman, John Gastil, Paul Slovic, the White-Male Effect in Risk Perception,\" Journal of Empirical Legal Studies 4:3 (November 2007): 465-505, 473. 26 Dan M. scientific consensus,\" 148. 28 Dan M. Kahan, \"On the Sources of Ordinary Science Knowledge and Extraordinary Science Ignorance,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford \"Culture Identity-Protective Cognition: Explaining the White-Male Effect and 148-149. 30 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 728. 31 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 729. 32 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 729. 33 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 729. 34 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 730. 35 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 730. 36 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 730. 37 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 730. 38 Kahan et al., \"Culture and Identity-Protective Cognition: Explaining the White-Male Effect in Risk Perception\"; Dan M. Kahan, Donald Braman, Paul Slovic, John Gastil, and Geoffrey Cohen, \"Cultural cognition of the risks and benefits of nanotechnology,\" Nature Nanotechnology 4 (2009): 87-90. 39 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 730. 40 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 734. 41 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 734. 42 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 736. 43 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 736. 44 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 737. 45 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 738. 46 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 738. 108 47 Dan M. Kahan, Donald Braman, Geoffrey L. Cohen, John Gastil, and Paul Slovic, \"Who Fears the HPV Vaccine, Who Doesn't, and Why? An Experimental Study of the Mechanisms of Cultural Cognition,\" Law and Human Behavior 34 (2010): 501-516, 503. 48 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 739. 49 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 739. 50 Kahan et al., \"Culture and Identity-Protective Cognition: Explaining the White-Male Effect in Risk Perception,\" 470. 51 Dan M. Kahan, \"Why We are Poles Apart on Climate Change,\" Nature 488 (2012): 255. 52 Kahan, \"On the Sources of Ordinary Science Knowledge and Extraordinary Science Ignorance,\" 46. 53 Kahan et al., \"Culture and Identity-Protective Cognition: Explaining the White-Male Effect in Risk Perception,\" 491. 54 Kahan et al., \"Culture and Identity-Protective Cognition: Explaining the White-Male Effect in Risk Perception,\" 491. 55 Kahan et al., \"Culture and Identity-Protective Cognition: Explaining the White-Male Effect in Risk 492. 56 Kahan et al., \"Culture and Identity-Protective Cognition: Explaining the White-Male Effect in Risk Perception,\" 498. 57 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 742. 58 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 742. 59 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 742. 60 Kahan et al., \"Cultural cognition of the risks and benefits of nanotechnology,\" 88. 61 Dan M. Kahan, \"A Risky Science Communication Environment for Vaccines,\" Science 342, 4 (October 2013): 53-54, 53. 62 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 745. 63 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 746. 64 Kahan et al., \"Cultural cognition of the risks and benefits of nanotechnology,\" 89. 65 Kahan et al., \"Cultural cognition of the risks and benefits of nanotechnology,\" 89. 66 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 746. 67 Kahan, \"On the Sources of Ordinary Science Knowledge and Extraordinary Science Ignorance,\" 45. 68 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 747. 69 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 747. 70 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 747. 71 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 747. 72 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 747. 73 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 747. 74 Kahan, Jenkins-Smith, and Braman, \"Cultural cognition of scientific consensus,\" 168. 77 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 750. 78 Kahan, \"On the Sources of Ordinary Science Knowledge and Extraordinary Science Ignorance,\" 43. 79 Kahan, \"On the Sources of Ordinary Science Knowledge and Extraordinary Science Ignorance,\" 43. 80 Kahan et al., \"Who Fears the HPV Vaccine, Who Doesn't, and Why? An Experimental Study of the Mechanisms of Cultural Cognition,\" 504. 81 Kahan, Jenkins-Smith, and Braman, \"Cultural cognition of scientific consensus,\" 150. 82 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 753. 83 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 755. 84 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 755. 85 Dan M. Kahan, Donald Braman, Paul Slovic, John Gastil, and Geoffrey Cohen, \"The Second National Risk and Culture Study: Making Sense of - and Making Progress In - the American Culture War of Fact,\" (2007): 3. Working paper found through the website of the Culture Cognition Project: < http://www.culturalcognition.net/ >. 86 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 755. 87 Kahan, Jenkins-Smith, and Braman, \"Cultural cognition of scientific consensus,\" 169. 88 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 756. 89 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 756. 90 Kahan, \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" 726. 91 Kahan, Braman, Cohen, Gastil, Paul Slovic, \"Who Fears the HPV Vaccine, Who Doesn't, and Why? An Experimental Study of the Mechanisms of Cultural Cognition.\" 92 Xiaoli Nan and Kelly Madden, \"The Role of Cultural Worldviews and Message Framing in Shaping Public Opinions Toward the Human Papillomavirus Vaccination Mandate,\" Human Communication Research 40 (2014): 30-53, 44. 93 Geoboo Song, \"Understanding Public Perceptions of Benefits and Risks of Childhood Vaccinations in the United States,\" Risk Analysis 34, 3 (2014): 541-555, 544. 94 Song, \"Understanding Public Perceptions of Benefits and Risks of Childhood Vaccinations in the United States,\" 549. 95 Geoboo Song, Carol L. Silva, and Hank C. Jenkins-Smith, \"Cultural Worldview and Preference for Childhood Vaccination Policy,\" The Policy Studies Journal 42, 4 (2014): 528-554, 542. 96 Song, Silva, and Jenkins-Smith, \"Cultural Worldview and Preference for Childhood Vaccination Policy,\" 542-543. 97 Nan and Madden, \"The Role of Cultural Worldviews and Message Framing in Shaping Public Opinions Toward the Human Papillomavirus Vaccination Mandate,\" 33. 98 Kahan, Jenkins-Smith, and Braman, \"Cultural cognition of scientific consensus,\" 169. 109 Chapter 5 - Discussion Most Americans are not concerned about vaccines. However, a small but vocal minority is, and a growing number of parents are receiving vaccine mandate exemptions for their children on the basis of religion or \"personal belief.\" Vaccine refusal can have disastrous consequences: in some communities, childhood vaccination coverage has dived well below the threshold required for \"herd immunity,\" allowing diseases like measles to stage a forceful comeback. 2019 saw the most cases of measles among American children since 1992; the disease, which kills at least 150,000 people in the developing world each year, was declared \"eliminated\" in the U.S. in 2000. Vaccination is a victim of its own success: the more invisible the diseases it prevents become, the more vaccine mandates seem unnecessary. In the case of vaccination, complacency is deadly. The drivers of vaccine hesitancy and refusal have been thoroughly studied in different disciplines. The clear conclusion that emerges from a review of this literature is that antivaxxers, while a heterogeneous crowd, often share common concerns: about the toxicity of vaccines, respect of \"nature,\" acknowledgment of parental rights, authority, and agency, the evils of Big Pharma, etc. Most public health interventions that aim to promote vaccination rely on disseminating trustworthy scientific knowledge. If antivaxxers knew how safe, effective, and necessary vaccines are, the theory goes, they would vaccinate more. This is commonly known as the KAP (knowledge, attitudes, practice) model, and it could be summarized by the following steps: evidence will be disseminated (diffusion) and reach the target population (coverage), who will understand it (understanding), adapt their evaluation of the risks and benefits of vaccination (perceptions), consequently develop certain attitudes about vaccination (attitudes), and - rationally -, have the intent to undergo vaccination (intent), which they will (behaviour). Unfortunately, empirical work evaluating the effectiveness of interventions based on dissemination of scientific evidence suggests that they often fail. Why? I attempted to answer this question by probing the cognitive and social mechanisms that interact with elements of the KAP intervention model. Where does this causal chain fail, and why? Inspired by Edgar Morin's principles of transdisciplinarity, Thomas Kuhn's theory of scientific revolutions, and Trisha Greenhalgh's meta-narrative review methodology, I examined the publications of different seminal authors across disciplines that directly or indirectly provide an answer to my question. I distinguished three main approaches. These constitute \"narratives\" about why antivaxxers are unpersuaded by scientific evidence on vaccines; in other words, they present alternative explanations of why interventions based on simple 110 dissemination of scientific evidence fail. These approaches have different views of where the KAP model fails, and because of which variables. I first looked at literature on the concept of scientific literacy. This approach hypothesizes that resistance to science can be explained by a lack of information and a lack of understanding; the key to overcoming the resistance to science evidence of antivaxxers thus lies in increasing their scientific literacy and giving them more sound evidence on which to base their decisions. What \"scientific literacy\" implies is unclear, but it generally refers to a set of core competencies and knowledge of facts that enables individuals to engage with science in their daily life. While a minimum level of scientific literacy is certainly necessary for the \"understanding\" element of the KAP model, and while dissemination of sound scientific evidence is important, the case of antivaxxers is the perfect example of where the link between knowledge and attitudes is shoddy. What I learned from the literature in this research tradition is that while there is evidence that increased scientific literacy is correlated with more positive attitudes towards science generally, there is no evidence that increased scientific literacy predicts positive attitudes towards specific science issues such as vaccination. In fact, studies focusing specifically on vaccination have found that antivaxxers are generally educated and scientifically literate, and that they have often already been exposed to the scientific evidence about vaccination that we are trying to persuade them with. Moreover, there is evidence of a \"backfire effect\": exposure to corrective information on vaccine myths might decrease the intent to vaccinate of the most concerned antivaxxers. I then looked at literature on cognitive biases and heuristics. According to this research tradition, resistance to scientific evidence can be explained by the numerous cognitive biases and \"rules of thumb\" that lead individuals to make systematic errors in judgment and thus deviate from the rational choice theory decision-making ideal. In other words, antivaxxers interpret the the scientific evidence that is disseminated to persuade them through the lens of these biases and heuristics, which include availability, affect, confirmation bias, and bias blind spot. The risk perception phase of the KAP model is disturbed. From this perspective, persuading antivaxxers will require making them aware of the biases and heuristics that hinder their thinking and presenting the scientific evidence that is disseminated in a way that reduces reliance on heuristic thinking. Finally, I looked at the literature on the cultural theory of risk and its descendant, cultural cognition theory. This approach differs from the two others in that it stresses sociocultural influences (rather than individual, cognitive influences) to explain resistance to science. According to the cultural theory of risk, culture, which cultural theorists define as a shared outlook or interpretive framework, produces attitudes about the world that support and sustain this way of life. Perceptions of risks are thus collective constructs, a social process: individuals will most likely form risk perceptions that reflect and strengthen their \"way of life\" or cultural worldview. Cultural theory hypothesizes that there are four main ways of life. Multiple 111 studies have already applied cultural theory to the case of anti-vaccination by examining which ways of life are correlated with anti-vaccination attitudes. Other researchers have built on the foundations of cultural theory to offer a more complex explanation of resistance to science. Cultural cognition combines the psychological approach and cultural theory by positing that cognitive biases and heuristics are the mechanisms through which culture influences risk perceptions. Cultural worldviews shape perceptions of risk because biases and heuristics enable them to. Researchers in this paradigm have identified several specific mechanisms of cultural cognition, including: cultural identity-protective cognition; biased assimilation and group polarization; cultural availability; cultural credibility; and cultural identity affirmation. According to this approach, we could potentially overcome antivaxxers' resistance to scientific evidence with two strategies: first, by framing the disseminated information in a way that makes it bear different meanings that different cultural groups can all endorse; and second, structuring deliberation in an identity-affirming way that reduces reliance on cultural cues. Figure 12 presents a cross-disciplinary synthesis of the modifier variables identified in these approaches that complexify the KAP intervention model. These variables intervene at various points in the KAP model and may explain why dissemination of scientific evidence fails to persuade antivaxxers. This integrated model shows that the intervention can go wrong at many stages. The three approaches I summarized suggest that scientific illiteracy may be an obstacle in the process that leads from exposure to the information (coverage) to understanding that information. Moreover, biases and heuristics may frustrate the analysis that leads to certain perceptions about the risks and benefits of vaccines. Finally, cultural way of life (or cultural worldview) seems to have an impact on multiple steps of the KAP model. From the traditional cultural theory perspective, it determines attitudes directly. But from the cultural cognition perspective, cultural predispositions both impact information coverage - the probability that an individual will be exposed to the information - and moderate how information impacts perceptions of risk, through biases and heuristics. In sum, the variables of scientific illiteracy, biases and heuristics, and cultural way of life complicate the KAP model; at multiple points, the model can easily fail. Figure 12. - A more complex KAP model 112 It is interesting to note that the three approaches I looked into all focus on the steps of the KAP model from coverage to attitudes. Looking into other research traditions could inform us on other modifier variables that intervene elsewhere in the model [Figure 13]. What other variables are at play? Certainly, characteristics of the disseminated evidence itself can affect how successful the intervention is. I did not look into how different subtypes of communication or education interventions may yield different effects. Literature on social networks and how information spreads within them could also tell us more about the coverage step of the model. How can we ensure that we reach antivaxxers, especially in the age of online echo chambers? How can we ensure antivaxxers distinguish the signal from the noise? It also seems plausible that there is a link between scientific illiteracy and biases and heuristics. Although everyone is subject to cognitive biases and heuristics, we could expect a scientifically illiterate person to rely more on heuristic thinking and processing to make sense of complicated scientific information. Furthermore, it would be interesting to better distinguish risk perceptions and attitudes. The relationship between the two concepts was glossed over in the literature I looked at. For example, it was unclear in the work of Douglas and Wildavsky if cultural ways of life really impact attitudes directly, or if they impact risk perceptions which, in turn, determine attitudes. How do perceptions become attitudes? Do perceptions necessarily produce attitudes, or can it be the other way around? And do other variables affect attitudes directly, such as religion and personal life experience? Literature on access to health care and characteristics of care in the American context could also tell us more about why an intent to undergo vaccination may not translate into vaccination behaviour. In addition to children who are unvaccinated, meaning that they have received no vaccines on the basis of \"personal belief\", religious or medical exemptions, there are many children who are undervaccinated: children who, for different reasons, have received some but not all of their vaccines, or whose vaccinations are delayed. This may happen, for example, in areas where access to regular follow-ups in primary or pediatric care is difficult, including for financial reasons. In the US, this issue disproportionately affects underprivileged - and often minority - communities. Figure 13. - Other questions about the KAP model 113 Moreover, while I often referred to \"antivaxxers\" (plural), I saw them as a collection of individuals, not as an organized, sociopolitical interest group. This also would have been an interesting angle of analysis. Indeed, antivaxxers and other organized anti-science groups have been very active and vocal in recent years, for example when some states legislated to remove personal belief exemptions. Similarly, I did not study anti-vaccination group dynamics and their impact on individual resistance to scientific evidence. All of these additional questions merit investigation, and the variables that emerge could easily be integrated into the conceptual framework I used to guide my analysis of three approaches. The strength of such a framework is that it structures discussions on the effectiveness of scientific dissemination interventions from any disciplinary point of view and about many other science issues such as climate change. Finally, while I was in the very last stages of writing, I was informed of a book which was yet to be published at the time, written by the philosopher of science Maya J. Goldenberg: Vaccine Hesitancy: Public Trust, Expertise, and the War on Science. Goldenberg presents the same three dominant \"narratives\" about vaccine hesitancy as I did, but proposes a persuasive alternative explanation: vaccine hesitancy, she argues, turns on epistemic trust rather than on understanding of the scientific evidence. Goldenberg delves deeply into how we invest science with epistemic trust and how that trust might be breached. She convincingly shows the link between trust and vaccine hesitancy. To pick just one excerpt of her argument: The scientific consensus is designed to direct public opinion and action; yet, tied into the consensus is a claim to the epistemic and moral legitimacy of its authors and their institutions. While most of the publics accept the legitimacy of scientific pronouncements, vaccine hesitators and more strident vaccine refusers reject those claims of legitimacy. They do not trust the source.1 While I brought up trust as a driver of vaccine hesitancy a few times (including in paragraphs on Kahan's cultural cognition theory and Nguyen's work on epistemic bubbles), and saw it mentioned here and there as a bullet point among others to explain vaccine attitudes, I did not fully consider how central this variable might be. Goldenberg writes that \"...this compartmentalizing of the problem of trust, rather than centralizing it in characterizing vaccine hesitancy, stems from underappreciation of how trust pervades science, its institutions, and relations of expertise both within scientific communities and in relation to the publics.\"2 In future work on resistance to science, I would like to further explore the variable of epistemic trust. Recognition of the important role that all of the different variables I have presented play in increasing or reducing vaccine confidence and acceptance should contribute to a reorientation of the public health interventions that aim to persuade antivaxxers. Improving the effectiveness of these interventions matters. Colossal resources are spent on interventions to persuade antivaxxers that are unsuccessful because they fail to take into account the different variables that are actually at play when we disseminate scientific evidence to change behaviours. The problem is urgent, because when it comes to health, consequences can be dire. Children dying of measles today is absolutely unnecessary and heartbreaking. 114 Just like the behaviours they promote, these interventions should be evidence-based. It is time for science communicators to stop holding on to the myth that simply giving people more facts, without consideration of social and cognitive hindrances, will suffice. Moreover, effective science communication safeguards science's cultural authority. Science holds a privileged cultural status, an exceptional rhetorical power that allows it to ground debates; this is put in peril when science communication interventions fail. Vaccine hesitancy and refusal are about much more than scientific evidence on vaccines. Science communication should be too. 115 REFERENCES: DISCUSSION 1 Maya J. Goldenberg, Vaccine Hesitancy : Public Trust, Expertise, and the War on Science (Pittsburgh: Pittsburgh University Press, 2021), 169. 2 Goldenberg, Vaccine Hesitancy, 113. 116 Index A affect ..... 24, 33, 44, 51, 68, 76, 77, 78, 79, 80, 89, 95, 100, 124, 128 Africa ......................................................................8 Akin, Heather ....48, 50, 52, 78, 83, 84, 85, 89, 90, 91, 122, 127 alternative medicine .............................................. 26 Asia .......................................................... 8, 52, 124 Australia ................................................. 29, 52, 124 autism .................................................. 20, 31, 32, 44 availability ................ 43, 78, 79, 80, 95, 98, 101, 102 B Bayesian statistics ................................................. 76 Beinart, Peter ........ 12, 13, 20, 34, 37, 38, 40, 41, 119 Benecke et al. ........ 23, 28, 33, 35, 38, 39, 40, 41, 119 Betsch et al. ............................................. 22, 39, 120 bias blind spot ................................................. 78, 82 biased assimilation ..................... 95, 98, 99, 100, 101 biases .................................................................... 77 Big Pharma ..................................................... 13, 22 Biss, Eula 8, 11, 14, 16, 25, 26, 32, 34, 35, 36, 37, 38, 39, 40, 41, 120 Braman, Donald ....................... 95, 97, 107, 108, 129 Briss et al. .................................. 43, 51, 73, 122, 125 Britain ................................................ 61, 65, 73, 125 C Cacciatore et al. .................................. 84, 85, 91, 127 Canada ........................................... 9, 42, 46, 52, 123 Cappella, Joseph N. ...................... 83, 84, 90, 91, 127 Centers for Disease Control and Prevention .... 12, 14, 19, 30, 46 Chapman et al. ..................... 39, 42, 43, 51, 120, 122 cognitive biases and heuristics ... ii, 33, 56, 57, 75, 76, 77, 78, 79, 80, 83, 89, 90, 91, 92, 95, 98, 104, 127, 128 Cohen, Geoffrey ............................. 95, 107, 108, 129 Cold War .............................................................. 11 Colgrove, James ......................................................8 confirmation bias ............. 33, 78, 81, 82, 83, 100, 101 Conis, Elena ........................... 13, 20, 36, 37, 38, 120 conspiracy thinking ...................... 4, 9, 23, 29, 30, 56 cultural cognition ii, 27, 95, 96, 97, 98, 101, 102, 103, 104, 107, 108, 129 Cultural Cognition Project ................................... 103 cultural credibility ......................................... 98, 102 cultural identity affirmation ........................... 98, 103 Cultural identity-protective cognition .................... 98 cultural theory of risk .. 92, 94, 95, 103, 104, 107, 129 Cutter laboratory ................................................... 12 D Dake, Karl ............................................................ 96 Democratic ..................................................... 22, 53 diffusion ............................... 4, 5, 42, 49, 56, 59, 124 Disneyland............................................................ 19 dissemination .. 1, 2, 42, 43, 48, 49, 51, 53, 56, 57, 95, 104, 105, 106, 122 Douglas, Mary .. 72, 92, 93, 94, 97, 98, 103, 104, 107, 126, 129 Druckman and Lupia ............................................. 84 dual process theory .................................... 77, 78, 80 Durbach, Nadja ....................................................... 9 E echo chambers ................................... 56, 83, 84, 101 education .... 27, 28, 34, 37, 43, 44, 45, 56, 61, 62, 65, 66, 72, 82, 122, 126 Edwards, Ward ..................................................... 76 England .................................... 9, 10, 11, 31, 90, 128 epistemic bubbles.................................................. 83 Europe ................................................. 8, 60, 72, 125 exemptions, personal belief .. 4, 13, 16, 17, 18, 20, 22, 23, 27 exemptions, religious ............................................ 13 exemptions, vaccine ..... 10, 13, 16, 17, 18, 20, 36, 37, 120, 121 F fake news................................................... 23, 32, 56 filter bubbles ......................................................... 83 flu 25, 44, 51, 73, 74, 82, 90, 124, 126, 128 Food and Drug Administration .............................. 12 Four C Model ....................................................... 22 framing .................................................... 84, 85, 104 G Gastil, John .................................... 95, 107, 108, 129 germ theory ...................................................... 9, 26 Goffman, Erving ................................................... 85 Google ............................................................ 33, 34 Graham et al. .............................. 42, 51, 52, 123, 124 Greenhalgh, Trisha.................. 54, 55, 56, 57, 59, 124 grid (cultural theory) ...................... 93, 95, 96, 97, 98 Grimshaw, Jeremy M. ........................................... 43 group (cultural theory) ............ 93, 95, 96, 97, 98, 103 117 H H1N1 .................................................................... 29 Hamblin, James ............................ 13, 14, 37, 38, 120 Harrison and Wu ............................................. 35, 41 Harvey et al. .................. 44, 51, 73, 74, 123, 125, 127 heuristics ............................................................... 77 Hurd, Paul ............................................... 61, 72, 126 I identity-protective cognition ................................ 101 ideology ................................... 22, 23, 30, 69, 84, 98 implementation................................................ 42, 60 Industrial Revolution ............................................. 26 J Jamieson, Kathleen Hall19, 30, 38, 40, 45, 46, 51, 52, 72, 80, 83, 84, 89, 90, 91, 107, 120, 121, 122, 123, 125, 127, 128, 129 Jenner, Edward .............................................. 8, 9, 29 Johnson, Lyndon B. ............................................... 12 K Kahan, Dan . 18, 19, 30, 38, 40, 45, 51, 52, 67, 69, 72, 89, 90, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 107, 108, 120, 121, 122, 123, 125, 127, 128, 129 Kahneman, Daniel .. 48, 52, 76, 77, 78, 79, 80, 82, 84, 85, 89, 90, 101, 123, 127 KAP model ........................................ 2, 5, 47, 48, 57 Kenski, Kate........................... 78, 81, 82, 89, 90, 127 knowledge deficit model ............................ 47, 48, 92 knowledge exchange ............................................. 42 knowledge transfer ...................................... 4, 42, 56 knowledge translation ......... ii, 2, 4, 42, 43, 45, 48, 56 knowledge-to-action gap (KTA) ............................ 42 Kuhn, Thomas ................. 54, 56, 127 R. ... 78, 83, 84, 85, 89, 90, 91, 127 Larson, Heidi . 7, 17, 21, 33, 36, 38, 41, 119, 121, 122 Laugksch, R\u00fcdiger C. ........ 61, 62, 63, 64, 72, 73, 126 Lewenstein, Bruce V. .............................. 61, 72, 126 Lewis, Michael ......................... 4, 7, 76, 89, 119, 127 M measles ... 4, 10, 12, 14, 16, 18, 19, 20, 22, 24, 27, 31, 33, 37, 38, 44, 68, 119, 120, 121 meta-narrative review ............. 54, 55, 56, 57, 59, 124 methodology ........................................ 53, 54, 57, 98 Miller, Hickson and Wilson ................................... 60 MMR vaccine................................. 17, 20, 31, 32, 44 Morin, Edgar .......................... 53, 54, 55, 56, 59, 124 motivated reasoning ........................................ 69, 82 N nanotechnology .............................100, 107, 108, 129 National Childhood Vaccination Injury Act ........... 14 National Science Board .................34, 64, 65, 73, 126 nature, as an antivaccination argument 12, 23, 24, 25, 26, 27, 28, 30, 39, 40, 50, 55, 56, 60, 62, 63, 64, 77, 78, 93, 121 Nguyen, C. Thi ........................................ 83, 90, 128 Nyhan, Brendan . 44, 51, 73, 74, 82, 90, 124, 126, 128 O Offit, Paul ............................................................. 32 Oswald and Grosjean ............................... 81, 90, 78, 82 ........................................................... 10 Paracelsus ............................................................. 25 paradigm, scientific .............................. 54, 55, 95, 98 pertussis................................................................ 17 Pew (Research Center, survey) . 64, 65, 66, 67, 68, 73, 126 polarization 22, 53, 56, 69, 78, 83, 84, 95, 98, 99, 101, 103 polio ............................................................... 11, 22 Pollyanna principle ............................................... 81 Poltorak et al. ........................................................ 28 Popova, Maria....................................................... 32 positive test strategy .............................................. 81 probability neglect .......................................... 78, 80 Pronin et al. ............................................. 82, 90, 128 pseudoscience ................................................. 23, 31 psychometric or psychological approach..... 92, 95, 98 public health ...... 11, 18, 34, 35, 42, 44, 45, 46, 48, 70 public understanding of science ..... 60, 61, 62, 67, 72, 126 R rational choice theory ................................. 60, 85, 92 rationality ........................... 26, 30, 75, 76, 77, 78, 80 Reagan, Ronald ..................................................... 12 Reich, Jennifer .... 7, 14, 21, 24, 28, 34, 36, 37, 38, 39, 40, 69, 74, 119, 121, 126 religion .................... 10, 12, 13, 16, 18, 22, 23, 30, 69 Republican...................................................... 22, 53 research utilization ............................................ 4, 42 resistance .... 11, 12, 13, 19, 23, 28, 49, 53, 57, 60, 92, 99, 103 Rousseau, Jean-Jacques ......................................... 24 S Sabin vaccine ........................................................ 12 118 Salvadori, Fran\u00e7oise, and Laurent-Henri Vignaud ...7, 11, 13, 22, 25, 26, 30, 31, 36, 37, 39, 41, 74, 119, 121, 126 Scheufele, Dietram A. .. 30, 38, 40, 45, 48, 50, 51, 52, 72, 85, 89, 90, 91, 107, 120, 121, 122, 123, 125, 127, 128, 129 Schumacher............................................. 53, 59, 124 science communication .... ii, 4, 18, 19, 45, 46, 48, 50, 56, 102, 103 science knowledge.......................... 65, 66, 67, 68, 69 scientific literacy ii, 48, 56, 60, 61, 62, 63, 64, 65, 66, 67, 72, 100, 102, 125, 126 selective attention .................................................. 83 selective exposure ................................................. 83 side effects of vaccines ............. 13, 14, 35, 44, 70, 82 Simon, Herbert A. ..... 60, 72, 75, 76, 78, 89, 126, 128 Slovic, Paul ........... 79, 80, 89, 95, 107, 108, 128, 129 smallpox ................................ 8, 9, 10, 11, 12, 13, 23 Smith, Adam ......... 72, 73, 75, 96, 107, 108, 125, 129 Sobo, Elisa ........................ 27, 28, 29, 39, 40, 41, 122 Specter, Michael ..................... 10, 19, 36, 37, 38, 122 Stroud, Natalie Jomini ..................................... 81, 90 Sunstein, Cass ................... 78, 79, 80, 89, 90, 95, 101 Supreme Court of the United States ....................... 11 T third-person effect ................................................. 82 Thomas, Lewis ........................................................4 toxins ........................................................ 24, 25, 26 transdisciplinarity ................................ 49, 53, 54, 56 Tversky, Amos ..... 48, 52, 76, 77, 78, 84, 85, 89, 101, 123 Twitter .................................................................. 33 U United States..... 4, 5, 9, 10, 11, 14, 16, 17, 18, 19, 21, 22, 23, 26, 29, 31, 38, 39, 40, 41, 44, 46, 61, 64, 72, 119, 121, 122, 126 V Vaccine Injury Compensation Program ................. 14 variolation ........................................................ 8, 11 Vietnam ................................................................ 12 W Wakefield, Andrew .................................... 20, 31, 32 Waldorf schools ...................... 27, 28, 39, 40, 41, 122 Watergate ............................................................. 12 Wildavsky, Aaron ... 92, 93, 94, 96, 98, 103, 104, 107, 129 Willis et al. ........................................................... 44 World Health Organization ............................. 11, 29 World Heath Organization ......................... 12, 26, 29 World War II ..................................... 11, 12, 72, 126 Y YouTube......................................................... 33, 34 119 Bibliography INTRODUCTION Baillargeon, Normand. Liliane est au de France, 2003. Sebastian. Total Bullshit! Au Coeur de la post-v\u00e9rit\u00e9. Paris: Presses Universitaires de France, 2018. Frankfurt, Harry G. On Bullshit. Princeton: Princeton University Press, 2005. Kakutani, Michiko. The Death of Truth. New York : Penguin Random House, 2018. Kitta, Andrea. Vaccinations and Public Concern in History. New York: Routledge, 2012. Larson, Heidi. Stuck: How Vaccines Rumors Start - and Why They Don't Go Away. Oxford: Oxford University Press, 2020. Nichols, Tom. The Death of Expertise. Oxford: Oxford University Press, 2017. Otto, Shawn. The War on Science: Who is Waging It, Why It Matters, What We Can Do About It. Minneapolis: Milkweed Editions, 2016. Pinker, Steven. Enlightenment Now: The Case for Reason, Science, Humanism and Progress. New York: Penguin Random House/Viking, 2018. Reich, Jennifer A. Calling the Shots: Why Parents Reject Vaccines. New York: NYU Press, 2016. Rosling, Hans. Factfulness. New York: Flatiron Books, 2018. Sagan, Carl. The Demon-Haunted World. New York: Penguin Random House, 1995. 2019. Thomas, Lewis. The Lives of a Cell: Notes of a Biology Watcher. Toronto: Bantam Books, 1974. CONTEXT Beinart, Peter. \"What the Measles Epidemic Really Says About America, \" The Atlantic. August 2019. https://www.theatlantic.com/magazine/archive/2019/08/measles-as-metaphor/592756/ (accessed 2020). Benecke, Olivia and Sarah Elizabeth DeYoung. \"Anti-Vaccine Decision-Making and Measles Resurgence in the United Health 6 (2019): 1-5. 120 Betsch, Cornelia, Robert B\u00f6hm, and Gretchen B. Chapman. \"Using Behavioral Insights to Increase Vaccination Policy Effectiveness,\" Policy Insights from the Behavioral and Brain Sciences 2, 1 (2015): 61-73. Biss, Conscientious Objectors?\" 29, (accessed 2020). Biss, Eula. \"The Illusion of 'Natural',\" The Atlantic, September 30, 2014. https://www.theatlantic.com/health/archive/2014/09/the-illusion-of-natural/380836/ (accessed 2020). Caulfied, Timothy. The Vaccination Picture. Toronto : Viking, 2017. Centers for Disease Control and Prevention. \"Measles Cases and Outbreaks,\" August 19, 2020. https://www.cdc.gov/measles/cases-outbreaks.html (accessed 2020). Centers for Disease Control and Prevention, \"Required Vaccines for Child Care and School,\" May 17, 2019. https://www.cdc.gov/vaccines/parents/records/schools.html (accessed 2020). Conis, Elena. \"The History of the Personal Belief Exemption,\" Pediatrics 146, 4 (2020): e20192551. Dixon, Graham, and Christopher Clarke. \"The effect of falsely balanced reporting of the autism-vaccine controversy on vaccine safety perceptions and behavioral intentions\" Health Education Research 28, 2 (2012). Earl, Elizabeth. \"The Victorian Anti-Vaccination Movement,\" The Atlantic. July 15, 2015. https://www.theatlantic.com/health/archive/2015/07/victorian-anti-vaccinators-personal-belief-exemption/398321/ (accessed 2020). Green, Emma. \"Anti-Vaxers Aren't Stupid,\" The Atlantic, February 16, 2016. https://www.theatlantic.com/health/archive/2016/02/anti-vaxers-arent-stupid/462864/ (accessed 2020). Goldenberg, Maya J. Vaccine Hesitancy : Public Trust, Expertise, and the War on Science. Pittsburgh: Pittsburgh University Press, 2021. Hamblin, James. \"Why The Government Pays Billions to People Who Claim Injury by Vaccines,\" The Atlantic, May 14, 2019. https://www.theatlantic.com/health/archive/2019/05/vaccine-safety-program/589354/ (accessed 2020). Harrison, Emily A., and Julia W. Wu. \"Vaccine confidence in the time of COVID-19,\" European Journal of Epidemiology, 35 (2020): 325-330, 325. Jamieson, Kathleen Hall. \"The Need for a Science of Science Communication: Communicating Science's Values and Norms,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, 2017: 15-25. Kahan, Dan M., Dietram A. Scheufele, and Kathleen Hall Jamieson, \"Why Science Communication?\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, 2017: 1-14. 121 Kahan, Dan M. \"Protecting or Polluting the Science Communication Environment?: The Case of Childhood Vaccines\", in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, 2017: 421-432. Kahan, Dan M. \"A Risky Science Communication environment for Vaccines,\" Science 342, October 4 (2013), 53-54. Kempe, Allison, et al. \"Parental Hesitancy About Routine Childhood and Influenza Vaccinations: A National Survey,\" Pediatrics 146, 1 (2020). Khazan, Olga. \"The Baffling Rise of Goop,\" The Atlantic, September 12, 2017. https://www.theatlantic.com/health/archive/2017/09/goop-popularity/539064/ (accessed 2020) Khazan, Olga. \"The Shadow Network of Anti-Vax Doctors,\" The Atlantic, January 18, 2017. https://www.theatlantic.com/health/archive/2017/01/when-the-doctor-is-a-vaccine-skeptic/513383/ (accessed 2020) Larson, Heidi. Stuck: How Vaccines Rumors Start - and Why They Don't Go Away. Oxford: Oxford University Press, 2020. Larson, Heidi. \"The state of vaccine confidence,\" The Lancet 392, 10161 (2018), 2244-2246. National Conference of State Legislatures. \"States With Religious and Philosophical Exemptions from School Immunization Requirements,\" June 26, 2020. https://www.ncsl.org/research/health/school-immunization-exemption-state-laws.aspx (accessed 2020) Nelson, Roxanne. \"US measles outbreak concentrated among unvaccinated children,\" The Lancet 19 (2019): 248. Olive, Jacqueline K., Peter J. Hotez, Ashish Damania, and Melissa S. Nolan, \"Correction: The state of the antivaccine movement in the United States: A focused examination of nonmedical exemptions in states and counties,\" PLoS Med 15,7 (2018). Omer, Saad B., et al., \"Nonmedical Exemptions to School Immunization Requirements,\" The Journal of the American Medical Association 296, 14 (2006): 1757-1763. Reich, Jennifer A. \"'We are fierce, independent thinkers and intelligent': Social capital and stigma management among mothers who refuse vaccines,\" Social Science & Medicine 257 (2020): 112015. Reich, Jennifer A. Calling the Shots: Why Parents Reject Vaccines. New York: NYU Press, 2016. Reich, Jennifer A. \"Of natural bodies and antibodies: Parents' vaccine refusal and the dichotomies of natural and artificial,\" Social Science & Ranee et al., \"Vaccination Coverage with Selected Vaccines and Exemption Rates Among Children in Kindergarten - United States, 2018-19 School Year,\" MMWR Morb Mortal 905-912. Sobo, Elisa J. \"Social Cultivation of Vaccine Refusal and Delay among Waldorf (Steiner) School Parents,\" Medical Anthropology Quarterly 29, 3 (2015): 381-399. Specter, Michael. \"Resistant,\" The New Yorker. May 23, 2011. https://www.newyorker.com/magazine/2011/05/30/resistant (accessed 2020). Urist, Jacoba. \"How Schools Are Dealing With Anti-Vaccine Parents,\" The Atlantic, February 5, 2015. https://www.theatlantic.com/education/archive/2015/02/schools-may-solve-the-anti-vaccine-parenting-deadlock/385208/ (accessed 2020). Widdus, Roy, and Heidi Larson. \"Vaccine mandates, public trust, and vaccine confidence: understanding perceptions is important,\" J Public Health Pol 39 (2018): 170-172. CONCEPTUAL MODEL AND RESEARCH QUESTION Akin, Heather, and Dietram A. Scheufele, \"Overview of the Science of Science Communication,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele (Oxford: Oxford University Press, 2017) 25-34. American Academy of Family Physicians. News story now unavailable, previously accessed in 2020 at: https://www.aafp.org/news/family-medicine-americas-health/20160812hip-immunizations.html American Academy of Pediatrics, \"Immunization Campaigns: National Immunization Awareness Month.\" https://www.aap.org/en-us/about-the-aap/aap-press-room/campaigns/Pages/NIIW.aspx (accessed 2020) Breckon, Jonathan, and Jane Dodson, \"Using Evidence: What Works?\", Alliance for Useful Evidence (2016). Briss, Peter A., et al., \"Reviews of Evidence Regarding Interventions to Improve Vaccination Coverage in Children, Adolescents, and Adults,\" American Journal of Preventive Medicine 18, 1S (2000): 97-140. The Canadian Press, \"Toronto Public Health launches advertising campaign aimed at promoting vaccination,\" Global News, October 7, 2019. https://globalnews.ca/news/6002457/toronto-public-health-vaccination-advertisement/ (accessed 2020) Caulfied, Timothy. The Vaccination Picture. Toronto : Viking, 2017. Centers for Disease Control, \"National Immunization Awareness Month,\" July 13, 2020. https://www.cdc.gov/vaccines/events/niam/index.html (accessed 2020) Chapman, Evelina, et al., \"Knowledge translation strategies for dissemination with a focus on healthcare recipients: an overview of systematic reviews,\" Implementation Science 15:14 (2020). Cutlip, Scott M., Allen H. Center, and Glen M. Broom. Effective public relations (6th ed.) (Englewood Cliffs, NJ: Prentice-Hall, 1985). 123 Dempsey, Amanda F., Gregory D. Zimet, Robert L. Davis, and Laura Koutsky. \"Factors That Are Associated With Parental Acceptance of Human Papillomavirus Vaccines: A Randomized Intervention Study of Written Information About HPV,\" Pediatrics 117, 5 (May 2006): 1486-1493. Dub\u00e9, Eve, Dominique Gagnon, Noni E. MacDonald and the SAGE Working Group on Vaccine Hestiancy, \"Strategies intended to address vaccine hesitancy: Review of published reviews,\" Vaccine 33 (2015): 4191-4203. Graham, Ian D., et al., \"Lost in Knowledge Translation: Time for a Map?\" The Journal of Continuing Education in the Health Professions, 26 (2006): 13-24. Harvey, Hannah, Nadja Reissland, and James Mason, \"Parental reminder, recall and educational interventions to improve early childhood immunisation uptake: A systematic review and meta-analysis,\" Heracleous, Loizos Th. 16-23. Canada: Term of Reference,\" 2017. https://immunize.ca/sites/default/files/Resource%20and%20Product%20Uploads%20(PDFs)/Immunize%20Canada/Terms%20of%20Reference/2017/Immunize%20Canada%20ToR%20June%202017.pdf (accessed 2020) Jamieson, Kathleen Hall. \"The Need for a Science of Science Communication: Communicating Science's Values and Norms,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, 2017: 15-25. Kahan, Dan M., \"A Risky Science Communication environment for Vaccines,\" Science 342, October 4 (2013): 53-54. Kahan, Dan M. \"Protecting or Polluting the Science Communication Environment?: The Case of Childhood Vaccines,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, 2017: 421-432. Kahan, Dan M., Dietram A. Scheufele, and Kathleen Hall Jamieson, \"Why Science Communication?\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University \"Prospect Theory: An 1979): 263-292. Langer, Laurenz, and David Gough, The Science of Using Science: Researching the Use of Research Evidence in Decision-Making (London: EPPI-Centre, Social Science Research Unit, UCL Institute of Education, University College London, 2016). Lavis, John N., et al., \"Developing and refining the methods for a 'one-stop shop' for research evidence about health systems,\" Health Research Policy and Systems 13, 10 (2015). Lindenmann, Walter K. \"An 'Effectiveness Yardstick' to measure public relations success,\" PR Quarterly 38, 1 (1993): 7-9. 124 Macnamara, Jim. \"Evaluation: The Achilles Heel of the public relations profession.\" International Public Relations Review 15, 4 (1992): 19. Macnamara, Jim. \"Research in public relations: A review of the use of evaluation and formative research.\" Asia Pacific Public Relations Journal 1, 2 (1999): 107-133. Macnamara, Jim. \"Research and evaluation.\" in C. Tymson & P. Lazar, The New Australian and New Zealand Public Relations Manual. Sydney: Tymson Communications, 2002: 100-134. Mendel-Van Alstyne, Judith A., Glen J. Nowak, Ann L. Aikin, \"What is 'confidence' and what could affect it?: A qualitative study of mothers who are hesitant about vaccines,\" Vaccine 36 (2018): 6464-6472. Nyhan, Brendan and Jason Reifler, \"Does correcting myths about the flu vaccine work? An experimental evaluation of the effects of corrective information,\" Vaccine 33 (2015): 459-464. Pluviano, Sara, Caroline Watt, and Sergio Della Sala. lingers in memory: Failure of strategies,\" 12, 7 e0181640. Reardon, Lavis, and Jane Gibson, \"From Research to Practice: A Knowledge Transfer Planning Guide,\" Institute for Work & Health (2006). Sarkies, Mitchell N., Kelly-Ann Bowles, Elizabeth H. Skinner, Romi Haas, Haylee Lane, and Terry P. Haines, \"The effectiveness of research implementation strategies for promoting evidence-informed policy and management decisions in healthcare: a systematic review,\" Implementation Science 12, 132 (2017). Straus, Sharon E., Jacqueline Tetroe, Ian D. Graham, and Eman Leung, \"Section 1.1 Knowledge to action: what it is and what it isn't,\" Canadian Institutes of Health Research, August 8, 2010. https://cihr-irsc.gc.ca/e/41928.html (accessed 2020). Willis, Natalie et al., \"\"Communicate to vaccinate\": the development of a taxonomy of communication interventions to improve routine childhood vaccination,\" BMC International Health and Human Rights 13:23 (2013). Wyer, Robert S. Jr., and Thomas K. Srull. \"The processing of social stimulus information: A conceptual integration,\" in Person memory: The cognitive basis of social R. Hastie, Srull. \"Human Cognition in Its Social Context,\" Psychological Review 93, 3 (1986): 322-359. METHOD Greenhalgh, Trisha, Glenn Robert, Fraser Macfarlane, Paul Bate, Olympia Kyriakidou, and Richard Peacock. \"Storylines of research in diffusion of innovation: a meta-narrative approach to systematic review,\" Social Science & Medicine 61 (2005): 417-430. Kuhn, Thomas. The Structure of Scientific Revolution. Chicago: Chicago University Press, 1962. Morin, Edgar. Introduction \u00e0 la pens\u00e9e complexe. Prague: \u00c9ditions Od\u00e9on, 1974. Schumacher, E.F. 1977. A Guide for the Perplexed. New York: Harper Perennial, 1977. 125 RESULTS: RATIONAL CHOICE THEORY, THE KNOWLEDGE DEFICIT MODEL AND SCIENTIFIC LITERACY Allum, Nick, Patrick Sturgis, Dimitra Tabourazi, and Ian Brunton-Smith. \"Science knowledge and attitudes across cultures: a meta-analysis,\" of Science Branscomb, Anne W. \"Knowing how to know, Science, Technology, & Human Values 6, 36 (1981): 5-9. Brickhouse, N.W., D. Ebert-May, and B.A. Wier. \"Scientific literacy: Perspectives of schools administrators, teachers, students, and scientists from an urban mid-Atlantic community,\" in This year in school science. Scientific literacy, eds. A.B. Champagne, A., et al. \"Reviews of Evidence Regarding Interventions to Improve Vaccination Coverage in Children, Adolescents, and Adults,\" American Journal of Preventive Medicine 18, 1S (2000): 97-140. Dempsey, Amanda F., Gregory D. Zimet, Robert L. Davis, and Laura Koutsky. \"Factors That Are Associated With Parental Acceptance of Human Papillomavirus Vaccines: A Randomized Intervention Study of Written Information About HPV,\" Pediatrics 117, 5 (May 2006): 1486-1493. Dub\u00e9, Eve. Dominique Gagnon, Noni E. MacDonald and the SAGE Working Group on Vaccine Hesitancy. \"Strategies intended to address vaccine hesitancy: Review of published reviews,\" Vaccine 33 (2015): 4191-4203. Durant, John R. \"What is scientific literacy?\" in Science and culture in Europe, eds. J.R. Durant and J. Gregory. London: Science Museum, 1993: 129-137. Evans, Geoffrey, and John R. Durant, \"The Relationship between Knowledge and Attitudes in the Public Understanding of Science in Britain,\" Public Understanding of Science 4, 1 (1995): 57-74. Gauchat, Gordon. \"The cultural authority of science: Public trust and acceptance of organized science,\" Public Understanding of Science 20, 6 (2011): 751-770. Goldenberg, Maya J. Vaccine Hesitancy : Public Trust, Expertise, and the War on Science. Pittsburgh: Pittsburgh University Press, 2021. Hallman, William K. \"What the Public Thinks and Knows About Science - and Why It Matters,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, 2017: 61-72. Harvey, Hannah, Nadja Reissland, and James Mason. \"Parental reminder, recall and educational interventions to improve early childhood immunisation uptake: A systematic review and meta-analysis,\" Vaccine 33 (2015): 2862-2880. Hazen, Robert M., and James Trefil, Science matters: Achieving scientific literacy. New York: Anchor Books Doubleday, 1991. 126 Hurd, Paul. \"Science literacy: Its meaning for American schools.\" Education Leadership, 16 (1958): 13-16. Jenkins, Edgar. \"Scientific literacy,\" in The international encyclopedia of education, eds. T. Husen and T.N. Postlethwait, W.M. \"A basis for better understanding of science,\" in Communicating science to the public, eds. D. Evered & M. 71-94. Bruce V. \"The meaning of 'public understanding of science' in the United States after World War II,\" Public Understanding of Science 1, 1 (1992): 45-68. Miller, Susan J., David J. Hickson, and David C. Wilson, \"Decision-Making in Organizations,\" in Handbook of Organization Studies, eds. Stewart Clegg, Cynthia Hardy, and Thomas Lawrence. London: Sage, 1996. National Science Board. \"Science & Engineering Indicators 2020: Science and Technology: Public Attitudes, Knowledge, and Interest,\" (May 15, 2020). Nyhan, Brendan and Jason Reifler, \"Does correcting myths about the flu vaccine work? An experimental evaluation of the effects of corrective information,\" Vaccine 33 (2015): 459-464. Pella, Milton O., George T. O'hearn, and Calvin W. Gale. \"Referents to scientific literacy,\" Journal of Research in Science Teaching 4 (1966): 199-208. Pew Research Center. \"What Americans Know About Science,\" (2019). Reich, Jennifer A. \"'We are fierce, independent thinkers and intelligent': Social capital and stigma management among mothers who refuse vaccines,\" Social Science & Medicine 257 (2020): 112015. Roberts, Douglas A. \"Scientific literacy. Towards a balance for setting goals for school science programs.\" (Ottawa: Minister of Supply and Services, 1983). 2019. Shamos, Morris Herbert. The myth of scientific literacy. New Brunswick, NJ: Rutgers University Press, 1995. Shen, Benjamin S.P. \"Scientific literacy and the public understanding of science,\" in Communication of scientific information, ed. S.B. Day (Basel: Karger, 1975): 44-52 Shen, Showalter, V.M. \"What is united science education? Part 5. Program objectives and scientific literacy\" Prism II (1974). Simon, Herbert A. \"A Behavioral Model of Rational Choice,\" The Quarterly Journal of Economics 69, 1 (1955): 99-118. 127 Willis, Nathalie, et al. \"\"Communicate to vaccinate\": the development of a taxonomy of communication interventions to improve routine childhood vaccination,\" BMC International Health and Human Rights 13:23 (2013). RESULTS: THE PSYCHOLOGICAL APPROACH Akin, Heather and Asheley R. Landrum. \"A Recap: Heuristics, Biases, Values, and Other Challenges to Communicating Science\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, Scheufele, and Shanto Iyengar. \"The End of Framing as we Know it... and the Future of Media Effects,\" Mass Communication and Society 19, 1 (2016): 7-23. Dubov, Alex, and Connie Phung. \"Nudges or of mandatory flu vaccination,\" Vaccine 33(2015): 2530-2535. Goldenberg, Maya J. Vaccine Hesitancy : Public Trust, Expertise, and the War on Science. Pittsburgh: Pittsburgh University Press, 2021. Hardy, Bruce W., and Kathleen Hall Jamieson. \"Overcoming Biases in Processing of Time Series Data About Climate\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, 2017: 399-408. Harvey, Hannah, Nadja Reissland, and James Mason, \"Parental reminder, recall and educational interventions to improve early childhood immunisation uptake: A systematic review and meta-analysis,\" Vaccine 33 (2015): 2862-2880. Jamieson, Kathleen Hall, and Joseph N. Cappella. Echo Chamber: Rush Limbaugh and the Conservative Media Establishment. New York: Oxford University Press, 2008. Kahan, Dan M., Dietram A. Scheufele, and Kathleen Hall Jamieson. \"Why Science Communication?\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, 2017: 1-14. Slow. Straus and Giroux, 2011. Kenski, Kate. \"Overcoming Confirmation and Blind Spot Biases When Communicating Science\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele, Oxford: Oxford University Press, 2017: 369-376. Kuhn, Thomas. The Structure of Scientific Revolutions. Chicago: University of Chicago Press, 1962. Kunda, Ziva. \"The Case for Motivated Reasoning.\" Psychological Bulletin (1990): 480-498. LaCour, Mark, and Tyler Davis. \"Vaccine skepticism reflects basic cognitive differences in mortality-related event frequency estimation,\" Vaccine 38 (2020) : 3790-3799. Lewis, Michael. The Undoing Project. New York: W.W. Norton, 2016. 128 Mendes Luz, Paula, Paulo Nadanovsky, and Julie Leask. \"How Sa\u00fade P\u00fablica 36 (2020): e00136620. Miller, Susan J., David J. Hickson, and David C. Wilson, \"Decision-Making in Organizations,\" in Handbook of Organization Studies, eds. Stewart Clegg, Cynthia Hardy, and Thomas Lawrence (London: Sage, 1996). Nguyen, C. Thi. \"Echo Chambers and Epistemic Bias: A Ubiquitous Phenomenon in Many Guises,\" Review of General Psychology 2, 2 (1998): 175-220. Nyhan, Brendan and Jason Reifler. \"Does correcting myths about the flu vaccine work? An experimental evaluation of the effects of corrective information,\" Vaccine 33 (2015): 459-464. Oswald, M.E. Illusions: A Handbook on Fallacies and Biases in Thinking, Judgment and Memory, ed. R.F. Hove, England; New Elo. The Filter Bubble: How the New Personalized Web is Changing What We Read and How We Think. New York: Penguin, 2011. Peters, Ellen. \"Overcoming Innumeracy and the Use of Heuristics When Communicating Science\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, 2017: 389-398. Pomares, Tiffany D., Alison M. Buttenheim, Avnika B. Amin, Caroline M. Joyce, Rachael M. Porter, Robert A. Bednarczyk, and Saad B. Omer. \"Association of cognitive biases with human papillomavirus vaccine hesitancy: a cross-sectional study,\" Human Vaccines & Immunotherapeutics 16, 5 (2020): 1018-1023. Pronin, Emily, Daniel Y. Lin, and Lee Ross. \"The Bias Blind Spot: Perceptions of Bias in Self Versus Others,\" Personality and Social Psychology Bulletin 28, 3 (2002): 369-381. Scheufele, Dietram A. \"Framing as a Theory of Media Effects\" Journal of Communication 49, 1 (1999): 103-122. Simon, Herbert A. Administrative Behavior. New York: Macmillan, 1947. Simon, Herbert A. \"A Behavioral Model of Rational Choice,\" The Quarterly Journal of Economics 69, 1 (1955): 99-118. Slovic, Paul. The perception of risk. Risk, Society, and Policy Series. London; Sterling, VA: Earthscan, 2000. Slovic, Paul, Melissa L. Finucane, Ellen Peters, and Donald G. MacGregor. \"The affect heuristic,\" European Journal of Operational Research 177 (2007): 1333-1352, 1333. RESULTS: THE CULTURAL THEORY OF RISK AND CULTURAL COGNITION 129 Douglas, Mary, and Aaron Wildavsky. Risk and Culture: an essay on the selection of technical and environmental dangers. Berkeley: University of California Press, 1982. Kahan, Dan M., Donald Braman, John Gastil, Paul Slovic, the White-Male Effect in Risk Perception,\" Journal of Empirical Legal Studies 4:3 (November 2007): 465-505. Kahan, Dan M., Donald Braman, Paul Slovic, John Gastil, and Geoffrey Cohen. \"The Second National Risk and Culture Study: Making Sense of - and Making Progress In - the American Culture War of Fact,\" (2007): 3. Working paper found on the website of the Culture Cognition Project: < http://www.culturalcognition.net/ >. Kahan, Dan M., Donald Braman, Paul Slovic, John Gastil, and Geoffrey Cohen. \"Cultural cognition of the risks and benefits of nanotechnology,\" Nature Nanotechnology 4 (2009): 87-90. Kahan, communications Nature 463 (2010): 296-297. Kahan, Dan M., Donald Braman, Geoffrey L. Cohen, John Gastil, and Paul Slovic. \"Who Fears the HPV Vaccine, Who Doesn't, and Why? An Experimental Study of the Mechanisms of Cultural Cognition,\" Law and Human Behavior 34 (2010): 501-516. Kahan, Dan M., Hank Jenkins-Smith, and Donald Braman. \"Cultural cognition of scientific consensus,\" Journal of Risk (February 2011): 147-174. Kahan, Dan M. \"Cultural Cognition as a Conception of the Cultural Theory of Risk,\" in Handbook of Risk Theory, eds. S. Roeser, R. Hillerbrand, P. Sandin, M. Peterson. Dordrecht, Netherlands: Springer Netherlands, 2012: 725-759. Kahan, Dan M. \"A Risky Science Communication Environment for Vaccines,\" Science 342, 4 (October 2013): 53-54. Kahan, Dan M. \"On the Sources of Ordinary Science Knowledge and Extraordinary Science Ignorance,\" in The Oxford Handbook of the Science of Science Communication, eds. Kathleen Hall Jamieson, Dan M. Kahan, and Dietram Scheufele. Oxford: Oxford University Press, 2017: 35-50. Nan, Xiaoli, and Kelly Madden. \"The Role of Cultural Worldviews and Message Framing in Shaping Public Opinions Toward the Human Papillomavirus Vaccination Mandate,\" Human Communication Research 40 (2014): 30-53. Rayner, S. \"Cultural theory and risk analysis,\" in Social Theories of Risk, eds. S. Krimsky Golding. Westport: Praeger, 1992: 83-115. Song, Geoboo. Public Perceptions of Benefits and Risks of Childhood Vaccinations in the United States,\" Risk Analysis 34, 3 (2014): 541-555. Song, Geoboo, Carol L. Silva, and Hank C. Jenkins-Smith, \"Cultural Worldview and Preference for Childhood Vaccination Policy,\" The Policy Studies Journal 42, 4 (2014): 528-554. Tansey, James, and Tim O'Riordan. \"Cultural theory review,\" Health, Risk & Society 1:1 (1999): 71-90. 130 DISCUSSION Goldenberg, Maya J. Vaccine Hesitancy : Public Trust, Expertise, and the War on Science. Pittsburgh: Pittsburgh "}