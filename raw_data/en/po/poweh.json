{"title": "PDF", "author": "PDF", "url": "https://ipilab.usc.edu/files/2018/04/IPILab_AnnualReport_2011-1e0aetk.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "Image Processing and Informatics Laboratory (IPI) Annual Progress Report February 2011 Image Processing and Informatics Lab Biomedical Engineering Department Viterbi School of Engineering University of Southern California Suite KER 302, Los Ange les, California 90089-7725 213-743-1720 Office, 213-743-2962 Fax www.ipilab.org BIOMED SCHOOL OF EN GINEERING UNIVERSITY OF SOUTHE RN CALIFORNIA 2011 Annual Report Image Processing and Informatics Laboratory 734 West Adams Blvd, Los Angeles, CA 90089. Tel: (213) 743 -2520 Fax: (213) 743 -2962 SUMMARY The Image Processing and Informatics Laboratory (IPI Lab) continues to thrive during these difficult economic times. The biggest news, however, is that our lab has moved to a new location closer to the USC main campus. Our new location is at the Annenberg Research Park located on 734 W. Adams Blvd. in the Kerckhoff Hall adjacent to the University Park Campus. IPILab has continued to maintain its course and provide a bridge of collaboration between the two schools - Viterbi School of Engineering and the Keck School of Medicine - with research support and establishing new collaborations and hosting visitors interested in Imaging Informatics training and research. Some of the accomplishments are detailed: 1. Education and Training IPILab has received a no-cost extension for a sixth year of a T32 Training Grant from the National Institute of Biomedical Imaging and Bioengineering (NIBIB), National Institutes of Health (NIH), DHHS entitled: \"Biomedical Imaging Informatics Training Program\" e ffective September, 1, 2005 - August 31, 2010, totaling about US$1.6 million. Existing trainees continue receiving national recognition as first author in national presentations, proceedings papers and peer-reviewed chapters and papers. Currently, we have six T32 trainees - Three are Postdoctoral Fellows, 1) Jorge Documet, Ph.D., graduating from our own Biomedical Engineering Department, Viterbi Engineering School; 2) James Fernandez, MD who graduated from University of Hawaii John A. Burns School of Medicine, has returned for a second year of training and will enter the USC Radiology Residency program in July, 2011; and 3) Ali Maziad, MD who completed his Orthopedic Surgery Residency at Ain Shams University Medical School, Egypt, and passed USMLE Step 1 and Step 2 for practicing medicine in the US, he will enter a selected surgical residency program in July, 2011. The three Predoctoral Fellows are, 1) Syed Ashrafulla who graduated from University of Texas and is currently a PhD student in the Viterbi School of Engineering, USC; 2) Jerry Loo, who will be complete his MD this coming June in the USC School of Medicine and awaiting a residency match in diagnostic radiology; and 3) Kathleen Garrison, who is a Ph.D. candidate in Neuroscience and graduated from UCLA. We are currently submitting to NIH a T32 Renewal proposal. As usual, summer activities are the height of our academic year for recruiting new and young blood into the IPILab for research collaborations. In addition to the T32 trainees, IPILab welcomed five undergraduate research trainees. The USC Summer Undergraduate Research Program continues to fund our efforts to recruit and foster bright young undergraduate students searching for future academic research directions. The previous summer we were able to recruit four undergraduate students from the BME program three of whom have remained as Student Assistants in IPILab after the summer. One undergraduate student trained at IPILab from Wabash College on a funded fellowship in Electrical Engineering. Finally, we had one MS graduate student, Joohyung (Luke) Suh, from the BME program who participated in summer training activities and has continued through the academic year. 1Other new additions to our lab, include two Provost Fellow PhD students Ruchi Deshpande and Ximing Wang from the BME graduate program. In addition to the milestones mentioned above in the T32 training program, Dr. Anh Le and Dr. Jasper Lee completed their Ph.D. in BME. Dr. Lee was a previous Predoc T32 Fellow. Another Predoc T32 Fellow, Kevin Ma, a BME Ph.D. student, has passed his qualifying Ph.D examinations. Dr. Brent Liu continues in the position as co-Chair for the \"Advanced PACS -based Imaging Informatics and Therapeutic Application\" Conference of the SPIE Medical Imaging Conference. Finally, last but not least, Dr. Bernie Huang has been awarded the distinguished honor of Professor Emeritus of Radiology and Biomedical Engineering, USC and his long- awaited and new book titled \"PACS and Imaging Informatics\" Second Edition, Wi ley & Blackwell Publisher January 2010 continues as the best seller at 2010 RSNA. 2. Research Projects We have continued in our areas of Medical Imaging Informatics research: 1) a DICOM- RT based ePR system with Decision Support for Managing patients treated with Proton Beam Therapy; 2) CAD systems for Multiple Sclerosis detection and small Acute Intracranial Hemorrhage detection on CT; 3) A surgical ePR system for Image-Assisted Minimally Invasive Spinal Surgery (MISS), the system is currently in clinical use; 4) The development of an eFolder System for MS Patients; and 5) A multimedia ePR system for clinical movement analysis in pre- and re-habilitation patients. We enjoyed a successful RSNA conference in November 2010 with a total of ten presentations. Other existing long term research projects such as the Data Grid have continued to progress, and have expanded clinical applications in imaging-based clinical trials, small animal imaging, and Breast Cancer imaging. Some of the research work continues to be supported by extramural finds including NIH, U.S. Army Medical Research and Materiel Command, and the private industry. Since summer 2010 w e have been establishing new collaborations in the area of Rehabilitative Science and Physical Therapy where multi-media data is utilized in the research field in addition to Patient-related imaging informatics data. 3. Industrial Collaborations IPILab has continued R & D collaborations with the private industry including but not limited to: Fujifilm, USA in the development of PACS tools and performer observer studies utilizing workflow tools for Mammogram Screening; Calgary Scientific, Inc. in 3- D thin-client server system with iPhone display technology; and SurgMatix, USA in the development of an ePR System for minimally invasive spinal surgery; and Aurora Imaging Technology in collaborating on a dedicated breast MRI imaging data grid for breast cancer patients. As described in the Table of Contents, this 2011 Annual Report includes materials related to the IPILab, IPILab R & D plans and current results, selected published and in- 2press peer-reviewed papers during the year, as well as preprints to appear in the Proceedings of the International Society for Optical Engineering (SPIE) in Medical Imaging , Orlando, Florida, February 12-17, 2011. Our research has been supported by: NIH/NIBIB Biomedical Imaging Informatics Training Undergraduate Research Award No. 22-2149- 6044 Aurora Technology, USA Fujifilm, USA MI2, USA SurgMatix, USA 3Table of Contents SUMMARY..............................................................................................................................................1 TABLE OF CONTENTS.......................................................................................... ............ .......................4 STAFF AND COLLABORATORS............................................. .................. ..................... ..........................6 IPILAB NEW LOCATION & COLLABORATIONS....................................................................................7 IPILAB WEBSITE.................................................................................................. ....................................8 RSNA 2009 POSTERS AND PAMPHLET.................. .................. .............................................................9 SPIE 2010 PREPRINTS AND PROCEEDINGS PAPERS.................................. ......................................18 2D vs. 3D Mammography: Observer Study James Fernandez, Linda Hovanessian- Larsen, Brent Liu............ .................................................19 Evaluation of a stand-alone computer-aided detection system for acute intra-cranial hemorrhage in emergency environments James Fernandez, RuchiDeshpande, Ximing Wang, Brent Liu, Michael Brazaitis, Fletcher Munter, Margaret Liu..................................................................... .......................... ........................26 Evaluation of an Automatic Multiple Sclerosis Lesion Quantification Tool in an informatics- based MS e-Folder system Kevin Ma, James Fernandez, Lilyana Amezcua, Ale x Lerner, Brent Liu ...................................32 A Solution for Archiving and Retrieving Preclinical Molecular Imaging Data in PACS Using a DICOM Gateway Jasper Lee, Bihui Liu, Bren t Liu......................................................... ............................................. .42 Development of a Data Mining and Imaging Informatics Display Tool for a Multiple Sclerosis e-Folder System Margaret Liu, Jerry Loo, Kevin Ma, Brent Liu................................................ ..................... ..........51 Improvement of MS (Multiple Sclerosis) CAD (Computer Aided Diagnosis) performing using C/C++ and computing engine in the graphical processing unit (GPU) JoohyungSuh, Kevin Ma, A nh Le............................................................... ....................... ................ 61 Viability of Sharing MEG Data using Minimum-Norm Imaging Syed Ashrafulla, DimitriosPantazis, John Mosher, MattiH\u00e4m\u00e4l\u00e4inen, Brent Liu, Richard M. Leahy......................................................................................................... ................................. ......... .66 A Multimedia Electronic Patient Record (ePR) System to Improve Decision Support in Pre- and Rehabilitation through Clinical and Movement Analysis Brent Liu, Jorge Documet, Sarah McNitt-Gray, PhilRequejo, Jill McNitt- Gray................... .....73 4DICOM-based computer-aided of intensity modulated radiation therapy (IMRT) treatment plans Fion W. K. Cheung, Maria Y. Y. Law................................................................................................ 82 Personalized Medicine and Patient-Specific Modelling Health Academy , Band 14, Dresden 2010, 155-164. H. U. Lemke, L. Berliner................................................................................................................... 92 Personalized Medicine and Model-Guided Therapy Health Academy , Band 15, Dresden 2010, 39- 48 H. U. Lemke, L. Berliner................................................................................................................. 102 SELECTED PEER REVIE WED REPRINTS........................................................................ .....................112 Grid-based implementation of XDS-I as part of image-enabled EHR for regional healthcare in Shanghai International Journal of Computer Assisted Radiology and Surgery, Accepted: Published Online First, printed publication pending Jianguo Zhang, Kai Zhang, Yuanyuan Yang, Jianyong Sun, Tonghui Ling, Guangrong Wang, Yun Ling, DerongPeng ....................................................................................................................113 MIDG-Emerging grid technologies for multi-site preclinical molecular imaging research communities International Journal of Computer Assisted Radiology and Surgery, Accepted: Published Online First, printed publication pending Jasper Lee, Jorge Documet, Brent Liu, Ryan Park, Archana Tank, HK Huang.................... ...125 A multimedia Electronic Patient Record (ePR) system for Image-Assisted Minimally Invasive Spinal Surgery International Journal of Computer Assisted Radiology and Surgery, 2010 May ; 5(3): 195 - 209. Jorge Documet, Anh Le, Brent Liu, John Chiu, HK Huang........................................ ................. 137 SELECTED BOOK E XCERPT............................................. .................................................................... 166 Recent Advances in Biomedical Image Processing Analysis Chapter18: PACS-Based Computer-Aided Detection and Diagnosis Springer Verlag, Berlin, Germany, 2011 Huang HK, Liu BJ , Le A, Documet J, , Thomas M Deserno, Ed........................................... ....... 167 5STAFF AND COLLABORATORS Faculty and Administration Edward V. Grant, MD, FACR Professor and Chairman, Department of Radiology Brent J. Liu, PhD Associate Professor of BME Director, IPILab H.K. Huang, DSc, FRCR (Hon.), FAIMBE Professor Emeritus of Radiology & BME James Sayre, PhD Professor of Biostatistics and Radiological Science, UCLA Consultant Cammy Huang, PhD Director of Scientific Outreach, Wallenberg Global Learning Network, Wallenberg Hall Lecturer, Dept of Biology, Stanford University Consultant Angelica Virgen Administrative Manager Norberto M. Grzywacz, PhD, Professor and Chairman, Department of Biomedical Engineering (BME) Ewa Pietka, PhD, DSc Professor, Technical University of Silesia, Poland Visiting Professor of Radiology Jianguo Zhang, PhD Professor, Shanghai Institute of Technical Physics, The Chinese Academy of Science Visiting Professor of Radiology Maria YY Law, MPhil, BRS, PhD Associate Professor, The Hong Kong Polytechnic University Visiting Associate Professor of Radiolog y Heinz U. Lemke, Professor Technical University Berlin Research Professor of Radiology Michael Khoo, PhD. Professor of BME, Co -PI, NIBIB Training Grant Postdoctoral and Visiting Fellows Paymann Moin, MD, Fellow Radiology Tao Chan, MD, PhD Assistant Professor, Hong Kong University Anh Le, PhD Fellow, University of Florida Marco A. Gutierrez, PhD Invited Professor, Heart Institute of University of San Paulo Richard Lee, MD Radiology Resident Research Assistants & PhD Candidates Graduate Student Assistants Jasper Lee, MS Kevin Ma, MS T32 Post Doctoral Fellows Jorge Documet, PhD Lab Manager James Fernandez, MD Ali Maziad, MD T32 Pre Doctoral Fellows Jerry Loo, BS Kathleen Garrison, BS Syed Ashrafulla, BS Ruchi Deshpande, BE Young Woo Park, BS Ximing Wang, BS Luke Suh, BS Undergraduate Research Interns Niloofar Eliyahoo Margaret Liu Sarah McNitt -Gray Ellen Messer Will Liu 6IPILAB NEW LOCATION & COLLABORATIONS 734 West Adams Blvd, Los Angeles, CA 90089 7IPILAB WEBSITE 8 RSNA 2010 POSTERS AN D PAMPHLET 9 10 11 12 13 14 15 16 17 SPIE 2010 PREPRINTS AND PROCEEDINGS PAPERS 182D vs. 3D Mammography: Observer Study James Reza F. Fernandeza, Linda Hovanessian-Larsenb, Brent Liua aImage Processing and Informatics Laboratory, 746 W Adams Blvd, Los Angeles, CA, USA 90039 bUniversity of Southern California, 1441 Eastlake Ave, Los Angeles, CA 90033 ABSTRACT Breast cancer is the most common type of non-skin cancer in women. 2D mammography is a screening tool to aid in the early detection of breast cancer, but has diagnostic limitations of overlapping tissues, especially in dense breasts. 3D mammography has the potential to improve detection outcomes by increasing specificity, and a new 3D screening tool with a 3D display for mammography aims to improve performance and efficiency as compared to 2D mammography. An observer study using a mammography phantom was performed to compare traditional 2D mammography with this ne 3D mammography technique. In comparing 3D and 2D mammography there was no difference in calcification detection, and mass detection was better in 2D as compared to 3D. There was a significant decrease in reading time for masses, calcifications, and normals in 3D compared to 2D, however, as well as more favorable confidence levels in reading normal cases. Given the limitations of the mammography phantom used, however, a clearer picture in comparing 3D and 2D mammography may be better acquired with the incorporation of human studies in the future. Keywords: mammography, 3D, observer study, 2D, phantom 1. INTRODUCTION Breast cancer is the most common type of non-skin cancer in women and the second most common cause of cancer death in women in the United States. Mammography is a screening tool used to aid in the early detection of breast cancer. 2D mammography is the current screening method of choice to detect early breast cancer. 2D digital imaging has the diagnostic limitation of overlapping tissues due to the nature of 2D projections. As the next step, 3D imaging holds promise to overcome the problem of overlapping tissues, especially in dense breasts. The potential of 3D mammography is to improve detection outcomes by increasing specificity thereby reducing recall rates in the screening mammography environment. A new 3D screening tool with 3D display for mammography is being developed which aims to improve performance and efficiency as compared to 2D mammography. The human eyes are separated horizontally by about 65mm. Each eye has a slightly different view of the objects we see and the brain correlates the images giving us the depth perception. The new 3D Mammography is based on this concept, making it very intuitive and natural to see 3D instantly. The observer study presented examines the improvement and efficacy of using this 3DM technique to identify targets in phantoms as compared to 2D mammography. The 3D mammography technique presented here aims to overcome such limitations. An observer study using a mammography phantom was performed to compare traditional 2D mammography with this new 3D mammography technique to evaluate this new technology. This paper will present findings from a receiver operating characteristic (ROC) study comparing traditional 2D Full Field Digital Mammography (FFDM) to 3D mammography with regards to a mammography phantom with masses and calcifications present, particularly on the specificity in detecting lesions. 19 2. MATERIALS AND METHODS 2.1 3D Mammography The 3D mammography (3DM) system comprises of two x-ray images per view (referred to as a stereo pair) of the same breast taken sequentially with a difference of between 4 -10 degrees. The breast remains in position for the image pair per view. The mammograms are displayed on 5 MP 3D stereoscopic monitors. Using special polarized stereo viewing glasses, the viewer's v isual system fuses the two images into a single in-depth 3D image of the breast. Figure 1. Planar 3D Viewing Monitor Setup 2.2 Mammography Phantom The phantom utilized in this study is acustomized CIRS BR3D mammography phantom which consists of a set of 15 slabs made of heterogeneous breast equivalent material that exhibits limited characteristics of real breast tissue and demonstrates how underlying targets can be obscured by varying densities. Each slab contains two tissue equivalent materials mimicking adipose and glandular tissues swirled together in an approximately 50/50 ratio by weight. Five of the slabs include mass targets, five have microcalcifications targets and five have no targets. Each slab measures 100 x 180 x 10 mm2. Figure 2. Phantom calcification and mass targets (left) and acquired image of a no-target phantom (right) Figure 3. Phantoms with a mass (left arrow) and calcifications (right arrow) 202.3 Case Selection Four hundred variations of 3-slab combinations comprised of 320 targets and 80 normal cases were collected via FFDM and 3D mammography, for a total of eight hundred image. Target slabs were composed of only one target, either a mass or calcification (Fig. 2). Calcifications consisted of 6 targets comprised to form a pentagon, and masses were comprised of a single even well-circumscribed round target. Of this sample size, approximately two hundred images were acquired via 2D Full-Field Digital Mammography (FFDM) and two hundred duplicate phantom configurations acquired via 3D mammography. Phantom cases were selected by a radiology resident and fellow to be adequate representations of varying target location and study difficulty. FUJIFILM Amulet System with selenium detector and 50 micron resolution was used for image acquisition. The same imaging conditions were used for 2D and 3D images. The 2D phantom images were acquired with MoRh, 28kV and 71mAs per image and the 3D images were acquired with MoRh 28kV and 36mAs per shot, bringing the sum of the 0-degree and 4-degree images to a total of 72mAs. Table 1. Study Case Types. Note that phantom orientation comprising of the 200 images acquired via 2D mammography is identical to that of the 200 images acquired via 3D mammography 2D acquired 3D acquired # Calcifications 80 80 # Masses 80 80 # Normals 40 40 TOTAL 200 200 2.4 Study Reading The observer study had three radiologists \u2014two dedicated mammographers and one board certified radiologist \u2014at USC Norris Cancer Hospital as readers in two rounds for a total of 400 readings per radiologist using the 3D stereoscopic workstation for both 2D display as well as 3D display. The first round of mammograms utilized the traditional 2D mammography. The second round occurred approximately 3 weeks after completion of the first round, and utilized the new 3D mammography. Each round was grouped into reading sessions of 50 cases. A random number generator was used to separate each group of cases as well as the order of reading sessions. In addition, both 2D and 3D display case groups were randomized to remove bias. Scoring of images was based on the detection of lesions and each study had a reviewer confidence level associated with it. Confidence levels were on a scale from 0 - 4: 0 - absolutely certain no target exists 1 - Less certain a target does not exist 2 - Unsure whether a target exists or not 3 - Less certain a target exists 4 - Absolutely certain a target exists Radiologists were unaware of the number of potential findings in each case. In this study, the reviewer found none, one, or more than one target. The targets or findings per 2D and 3D reading per case were recorded on a target location sheet. Reading of each study was also timed, with the timer starting once the reviewer opened the new study, and ending once a final read was made. 3. METHODS 3.1 ROC Analysis 21 ROC areas under the curves in comparing 2D vs. 3D mammography in the case of masses and calcifications revealed no statistical significance in reader interpretation. Table 2. ROC analysis of 2D vs. 3D for calcifications and normals 2D Area Under Curve 3D Area Under Curve Difference 95% CI Calcifications vs. Normals The final total number of studies consisted of 77 cases with a calcification, 78 cases with a mass, and 38 normals read by three radiologists. P-values comparing 2D and 3D reads for the different categories are as follows: calcifications 0.099, masses 0.003, normals 0.89. Table 3 details regarding how frequently multiple masses were identified in 2D as compared to 3D. Table 3. 2D vs 3D Mass Analysis4 2D 3D # Masses Called 146/237 (61.6%) 114/237 (48.1%) # Masses Called in Multiple Masses from 2 -6 82 0 # masses called correctly 22/82 (9.3%) 114/237(48.1%) # False Positives 60/237 (25%) 0 Table and 3D Overall Lesion Grading Type of Lesion In both 2D and 3D modes, the time it took to read calcifications on average was shorter than what it took to read masses, which was in turn shorter than the average time it took to read a normal study. Differences in reading time among the three subgroups between 2D and 3D were statistically different, with the 3D studies taking less time per read in each situation. Table 5. Average Reading Times Type of Lesion Average Time (seconds) Calcification 2D 22Table 6. Difference in reading time between 2D and 3D for calcifications, masses, and normals Type of Lesion Mean Time (seconds) 95% Confidence Interval of the Difference Significance (2 - tailed) Lower Upper Calcification (2D Time spent - 3D Time spent) 4.269 1.731 6.808 0.001 Mass (2D 5.481 2.299 8.662 0.001 Normal (2D spent) 2.845 2.977 8.744 0.341 3.3 Confidence Levels Confidence levels per read for calcifications were greater than that of masses, which in turn was greater than that of normals for both 2D and 3D. 2D confidence levels were also higher than 3D cases, but were only statistically significant for calcifications. 3D confidence levels were lower than 2D confidence levels for normals, and were statistically significant. In reference to section 2.4 above, the readers were more confident in labeling normals as normals (e.g. lower confidence level) in 3D than in 2D. Table 7. Mean confidence levels per lesion type for 2D and 3D Type of Lesion 0.76610 4. DISCUSSION Overall, the study outcomes were impacted by the nature of the phantoms resulting in statistical differences between sensitivity and confidence levels in 2D and 3D readings. The main statistically significant difference was in specificity and reading time, both of which were more favorable in 3D images. Of note regarding the higher percentage correct of interpreting masses in 2D as compared to 3D was the number of lesions detected by the radiologists, particularly in the case of masses. The 3D readings, by comparison, had 114 masses called from 237 (48.1%), and no multiple masses were called. It is possible that the disparity between 2D and 3D was due to a shotgun approach by the radiologists, as they were more likely to call multiple targets in the 2D images than in the 3D images - thus increasing specificity with the 3D readings. Sensitivity was not affected in a similar fashion likely because sensitivity is related to dose, which is similar in both 3D and 2D mammography. Calcification detection was much higher than mass detection likely because of the nature of the ph antom's calcification targets. Once the radiologists realized that calcifications would appear with a consistent pentagonal orientation, they would start to look for irregularities with such orientation in the phantom images. In addition, noise was not a factor for the statistically insignificant difference in the performance of microcalcification detection in 3D compared to 2D. In addition, the radiologists felt that the phantom used made it difficult to detect targets, particularly due to the nature of the background slabs which sometimes portrayed patterns that, if found in real breast tissue, would lead the radiologist to be more suspicious of certain regions. Mass detection in particular was considered very difficult by all three radiologists. The time spent in reading via the 3D display was on average lower than with the 2D display, and was statistically significant. In addition, the confidence level for reading normal cases in 3D was lower (e.g. readers were more confident labeling normals as being normals) as compared to the 2D cases, and that result was statistically significant. 235. CONCLUSION In the current clinical screening mammography environment, 2D digital projection imaging has a diagnostic limitation of overlapping tissues, especially in dense breasts. Pathology is often obscured by overlying tissue or on the other hand, it can be misleading due to tissue overlap. This gives rise to false negative and false positive reading outcomes. Given the limitations of 2D mammography a new 3DM was evaluated with prior study at Emory University (Reference 5) which resulted in improved detection of microcalcifications and masses due to the depth perception visual separation of overlapped textures. This phantom study showed no improvement in mass detection, however. Although this study revealed no statistically significant changes in reader detection of calcifications and masses in the phantom studies, a few interesting points were brought to light. The amount of time taken by the radiologists in reading via the 3D display was significantly lower than with the 2D display. Also, with the 3D display the radiologists were far less likely to call out multiple lesions, particularly in the case of masses. The radiologists felt that it was easier to rule out potential lesions in 3D as compared to 2D, and subsequently had fewer instances of multiple lesion detection with the 3D studies. The targets in the phantoms were of a fixed pattern and appeared the same on each image. They were representative of pathology; however, in reality they were quite limited in representing true breast pathology and so presented another layer of artificiality which made it easier for the radiologists to identify targets. Calcifications were consistent dot pattern, and masses were spheroidal. Calcifications used in the phantoms also did not behave like they normally would with human breasts, features such as amorphous, indistinct, coarse, linear, pleomorphic or casting type. Mass too were well circumscribed, which is very different from what the radiologists look for in true cancer pathology, features such as spiculated, ill-defined, irregular or lobulated. In conclusion, the limitations of the phantom used in this study may point out the need to perform human studies as it was brought up repeatedly by the radiologists that the phantom did not behave like human breast tissue on imaging. It should be noted that these preliminary observations of 3D readings would translate to more successful outcomes in human subject studies. The ability to visualize tissue stratification and microcalcifications and masses at various tissue depths was confirmed by the participating readers as well as other radiologists who were given a demo on real human breasts. In the mammography screening environment, reading speed especially for true negatives and reduction of false readings are very important for quality patient care. Unofficial feedback indicated that 3D mammography would have improved diagnostic outcomes compared to conventional 2D, thereby having the potential to reduce recall rates. 6. REFERENCES [1] Birdwell RL, Ikeda DM, O'Shaughnessy KF, Sickles EA. Mammographic of 115 missed cancers later detected with screening mammography and the potential utility of computer-aided Receiver operating characteristic rating analysis: generalization to the population of readers and patients with the jackknife method. Invest Radiol1992; 27:723 digital mammography: Improved accuracy of lesion detection in breast cancer screening. Proceedings of the International Workshop on Digital Mammography 2008 , 74-79 247. APPENDIX 25Evaluation detection in Fernandeza, aImage Processing and Informatics Laboratory, 746 W Adams Blvd, Los Angeles, CA, USA 90039; bWalter Reed Army Medical Center, 6900 Georgia Ave NW, Washington, DC 20307 ABSTRACT Acute intra-cranial hemorrhage (AIH) may result from traumatic brain injury (TBI). Successful management of AIH depends heavily on the speed and accuracy of diagnosis. Timely diagnosis in emergency environments in both civilian and military settings is difficult primarily due to severe time restraints and lack of resources. Often, diagnosis is performed by emergency physicians rather than trained radiologists. As a result, added support in the form of computer-aided detection (CAD) would greatly enhance the decision-making process and help in providing faster and more accurate diagnosis of AIH. This paper discusses the implementation of a CAD system in an emergency environment, and its efficacy in aiding in the detection of AIH. Keywords: Acute Intracranial Hemorrhage, computer aided detection, traumatic brain injury 1. INTRODUCTION Acute intracranial hemorrhage (AIH), defined as recent (<72 hours) bleeding within the skull, may be the result of stroke or complication of head injury, such as in traumatic brain injury (TBI). Small AIH (<1 cm) can be difficult to detect in a timely manner without the presence of an experienced radiologist, and may manifest weeks to months later in the form of post traumatic stress disorder (PTSD) or change in cognitive or behavioral function. In military and emergency room environments, evaluation for AIH may be carried out initially by emergency physicians, internists and neurosurgeons. In initial management of a patient with suspected AIH non-contrast CT scans are ordered, but studies have shown that CT interpretation by these acute care physicians may not be optimal. At the Walter Reed Army Medical Center, an AIH computer-aided detection (CAD) was developed to facilitate quick diagnosis of AIH, especially small AIH in the emergency environment. A receiver operating characteristic (ROC) study performed using the CAD system by emergency physicians and radiology residents on 30 AIH studies with AIH smaller than 10 mm and 30 control studies revealed an average area under the ROC (Az) increase from 0.8422 to 0.9294 (p=0.0107) and from 0.9371 to 0.9762 (p=0.0088), respectively (Fig. 1). 26 Figure 1.Receiver operating characteristics of detection of Acute Intracranial Hemorrhage algorithm The CAD detection was developed and tested with MATLAB. System input is a CT head series in DICOM format, and the output is a series of DICOM images, which are secondary captures of the CAD. Resultant images have potential AIH lesions outlined in red as those with high probability of being AIH, and blue for those with low probability of being true AIH. The CAD algorithm detects AIH in a step-wise fashion (Fig. 2): 1. First, skull is removed using global thresholding 2. The brain is realigned into the conventional orientation after automatic localization of mid-sagittal plane 3. Segmentation is based on combined processes of top-hat transformation 4. Candidate AIH lesions are given anatomic context by registration against a previously developed coordinate system 5. Image features and coordinates of the candidates provide inputs for the rule-based classification system 6. Outputs of the algorithm are displayed as images with overlay of red perimeters surrounding genuine AIH 27 Figure 2.Schematic Diagram of the AIH CAD system. The last image shows outlined lesions with high probability of being true AIH in red, and those with low probability of being true AIH in blue. 2.2 CAD Workstation An automated system to facilitate integration of a stand-alone CAD system into the clinical environment was developed around the AIH CAD. The system architecture for the system is shown in figure 2. 28 Figure 2. Architecture and workflow diagram for the AIH CAD system, full capabilities shown The CAD workstation is comprised of a DICOM receiver which listens every 5 minutes on a specific port for incoming DICOM studies and routes them to a pre-specified folder. The pre-processing unit then receives the studies to ensure that they are of the correct type (e.g. brain CT), and the DICOM metadata scanned to ensure that it will be accepted by the algorithm. The data is then stored in a file system, sorted by a control service, and displayed on a graphical user interface (GUI) (Fig. 3). The GUI may be used both for viewing the original and post-processed images, as well as run the CAD manually. The GUI can load images from the database or directly from CD-ROM, and displays the original images adjacent to the CAD-run images. The GUI also allows for the user to annotate reports to be stored with the original and CAD images as a separate text file. A web server is included to allow the viewing of CAD results remotely. 29 Figure 3.AIH CAD graphical user interface. Original image on the left, and CAD-processed image on right, with red lesions being highly suspicious of AIH, and blue being detected lesions with low probability of being true AIH 2.3 AIH, Traumatic Brain Injury and Walter Reed Army Medical Center Military personnel experience more serious and unusual types of traumatic brain injury (TBI), which may result in AIH, than civilians due to exposure to explosions from battlefield bomb blasts. In the battlefield setting, closed brain injury is common and has higher incidence than that seen in other venues. Of all military personnel who experienced injuries because of hostile fire in Iraq and Afghanistan and who were evacuated to WRAMC, 28% had TBI. Due to the difficulty in diagnosing small AIH, many soldiers return home without receiving appropriate therapeutic care, which may result in untreated PTSD or behavioral changes months to years later. The AIH CAD workstation was developed to allow for earlier detection and management of small AIH. 3. WORKSTATION EVALUATION 3.1 Problems Encountered in System Integration Despite having the above mentioned capabilities, given the strict web security requirements of the Walter Reed Army Medical Center, the system was developed to act as a stand-alone system with manual feeding of studies from CD-ROM or DVD. Placing a system online at WRMC requires a certificate of net worthiness, and the approval process for such a certificate may be lengthy. Despite this, proceeding on the application for the certificate of net worthiness is underway, and in the meantime the system was developed to work off-line until it is able to be placed on-line. How the system handles CD-ROMs with images was explained in section 2.2 The CAD workstation can then automatically load, preprocess, and run the images automatically, as well as store the original images, results, and annotations locally. In addition, in testing the workstation with studies from Walter Reed Army Medical Center, 26 AIH cases from WRMC with 26 matched normals were evaluated, with results posted in Table 1. The studies used were acquired 30from military installations throughout the middle east from soldiers with suspected traumatic brain injuries. The studies were of patients with radiologist-diagnosed small (<1cm) AIH . A similar study was performed earlier on cases from the Los Angeles County/University of Southern California (LAC/USC) hospital, which showed a 89.6% lesion detection sensitivity on a per patient basis. 3.2 Results Table 1. Summary of CAD results for WRAMC cases on a per patient basis True Positives 26/26 False Positives 10/26 True Negatives 1/26 False Negatives 9/26 The high number of false negatives in this evaluation was likely due to signal noise from studies acquired from different CT machines. The original CAD algorithm was developed from images acquired from a single modality in Hong Kong. In addition, five out of 26 AIH studies did not make it past the CAD analysis phase, due to DICOM header discrepancies. This is also attributable to the use of different imaging modalities for each study. To accommodate for this, the CAD algorithm itself had to have its knowledge base classification system modified. 3.3 Future Work Improvement of the knowledge classification system used by the algorithm is in need of refinement to account for a wider spectrum of acquisition CT modalities used. In addition, although the workstation can be implemented for off-line use at Walter Reed Army Medical Center, its versatility can be further evaluated by enabling on-line use. Steps are being taken to provide the workstation with a certificate of net-worthiness at the Walter Reed Army Medical Center for such a goal. In addition, work is underway to develop a 3D algorithm to detect AIH, as opposed to the slice- by-slice 2D methodology in use with the current system. Implementing a 3D algorithm in detecting AIH may improve sensitivity of detection, particularly with small (<1cm) AIH. 4. CONCLUSION Detection of AIH in the acute care setting is important facilitating early management. In many parts of the world a trained radiologist's expertise may not be readily available, and implem entation of a CAD system may be a viable alternative. The current AIH CAD system presented here is undergoing refinements in knowledge-based classification, but will be deployed for off-line use at the Walter Reed Army Medical Center. It is pending WRAMC certificate of net worthiness for on-line use. REFERENCES [1] Chan, Tao. Effect of a computer- aided diagnosis system on clinicians' performance in detection of small acute intracranial hemorrhage on computed tomography. Academic Radiology, Volume 15, Issue 3, 290-299. 2008 [2] Chan, Tao. Computer aided detection of small acute intracranial hemorrhage on computer tomography of brain. Computerized Medical Imaging and Graphics 31, 285-298 (2007). [3] Lee, Joon. Evaluation of a computer-aided detection algorithm for timely diagnosis of small acute intracranial hemorrhage on computed tomography in a critical care environment. SPIE [4] Panagos, PD, 2002; 20:631- 655. [5] Broderick, JP, et al. Guidelines for the management of spontaneous intracerebral hemorrhage: a statement for healthcare professionals from a special writing group of the stroke council, American Heart Association. Stroke 1999; 30. 31Evaluation of an Automatic Multiple Sclerosis Lesion Quantification Tool in an Informatics-based MS e-Folder system James Brent Liua aImage Processing and Informatics Laboratory, Dept of Biomedical Engineering, Univ. of Southern California, 734 West Adams Blvd.. Los Angeles, CA 90089 bDept. of Neurology, Univ. of Southern California, 1520 St. Los Angeles, CA 90033 cDept. ofRadiology, Univ. of Southern California, 1520 San Pablo St. Los Angeles, CA 90033 ABSTRACT Multiple sclerosis (MS) is a demyelinating disease of the central nervous system. The chronic nature of MS necessitates multiple MRI studies to track disease progression. We have presented an imaging informatics decision- support system, called MS eFolder, designed to integrate patient clinical data with MR images and a computer-aided detection (CAD) component for automatic white matter lesion quantification. The purpose of the MS eFolder is to comprehensively present MS patient data for clinicians and radiologists, while providing a lesion quantification tool that can be objective and consistent for MS tracking in longitudinal studies. The MS CAD algorithm is based on the K-nearest neighbor (KNN) principles and has been integrated within the eFolder system. Currently, the system has been completed and the CAD algorithm for quantifying MS lesions has undergone the expert evaluation in order to validate system performance and accuracy. The evaluation methodology has been developed and the data has been collected, including over 100 MS MRI cases with various age and ethnic backgrounds. The preliminary results of the evaluation are expected to include sensitivity and specificity of lesion and non-lesion voxels in the white matter, the effectiveness of different probability thresholds for each voxel, and comparison between CAD quantification results and radiologists' manual readings. The results aim to show the effectiveness of a MS lesion CAD system to be used in a clinical setting, as well as a step closer to full clinical implementation of the eFolder system. Keywords: Multiple Sclerosis, CAD, electronic patient record, imaging informatics, algorithm validation 1. INTRODUCTION The goal of this paper is to update on the continuous development of an imaging informatics-based eFolder specifically for multiple sclerosis patients. The system integrates patient data with MR images and an automatic lesion quantification program to aid in disease tracking and management for clinical and research environments. This project focuses on the validation methodology and results of the automatic lesion quantification component. 1.1 Multiple Sclerosis Multiple Sclerosis (MS) is an autoimmune neurological disease that affects approximately 2.5 million people worldwide, and proximately 200 new patients are diagnosed with MS each week in the United States. The body's own immune system attacked the central nervous system, causing damages and scar tissues (called lesions) in brain parenchyma, spinal cord, and optic nerves1. Its symptoms vary greatly and in the most severe cases can be disabling and life-threatening. Currently there is no cure for MS, and treatments for MS include disease management, reducing number and severity of attacks, and improve patients' ability to function in daily lives2,3. Therefore, longitudinal disease tracking of patients become key in MS treatment. Magenetic Resonance Imaging (MRI) is a commonly-used tool in diagnosing and monitoring MS by visually displaying lesions4.Lesions in white matter appearshyperintense in MR sequences T2 and FLAIR, while lesions may appear hypointense in T1 sequences. Figure 1 shows a MS patient's MRI in the three sequences. 32 Figure 1.Three axial brain images of an MS patient. The left-most image is T1-weighted, the middle image is T2-weighted, and the right-most image is FLAIR. White regions in FLAIR image (as pointed by arrows) indicates MS lesions in white matter In longitudinal tracking, existing individual MS lesions need to be identified and quantified for monitoring patients' responses to treatments as well as disease progress. To solve these challenges, an imaging-informatics based eFolder has been designed to store and display MS patient data with MR images and MS lesion quantification results. The benefits of the eFolder include integrated patient data repository, an automatic lesion detection and quantification system to allow disease tracking on MR, and a data mining tool for both clinical and research purposes. 1.2 Design of MS eFolder Figure 2.shows design components of the MS eFolder system. Figure 2.MS eFolder system diagram. The system itself contains three components: eFolder web-based services(red), graphical user interface (green), and CAD component (white). DICOM services (in orange) provide DICOM-based operations needed for eFolder system integration in clinical environments The MS eFolder system has three main design components: database, graphical user interface, and a computer-aided detection (CAD) system that can quantify lesion volume and number of lesions. 331.2.1 Database design The eFolder database stores text data such as patient history, MR image locations, and lesion quantification results. Database schema has beendeveloped in MySQL The database structure is built such that one single patient has a unique data entry regarding demographics and social data, has a list of all MR studies regarding to MS, and a list of all CAD results (in Structured Reporting, or SR, format) available for that patient. The data therefore is patient- centric and allows quick access to a patient's hist orical data. Patient demographic data is collected and designed via physicians' survey forms. The imaging database follows the DICOM structure to store metadata from headers. The CAD results database stores quantified lesion statistics on both study and image level. 1.2.2 Graphical User Interface design A graphical user interface (GUI) is needed to display all the information available in the eFolder, as it ties everything together in a presentable and user-friendly way for navigation of data. The web-based GUIs have the following characteristics: The GUI need to be web-based to allow remote access using thin-client architecture. Computations and visualizations are completed on the server side for a light-weight and fast GUI. The GUI needs to be comprehensive. It needs to display patient clinical data, imaging data, and CAD results on the same interface. It allows physicians and radiologists to access all of the information related to the data query. The system needs to be dynamic and allow display of 3D images and manipulations of images presented. An attractive viewing interface allows for a more clarified presentation The GUI needs to allow flexible and intelligent data mining. With a large number of patients' information stored in the eFolder system, any clinician and researcher should be able to look up MS patients on a variety of different search criteria, ranging from patient demographic data to lesion analytical results. A web-based GUI has been designed and developed for this purpose. A more detailed description of the GUI is presented in Development of a Data Mining and Imaging Informatics Display Tool for a Multiple Sclerosis e - Folder System by M. Liu et al. in SPIE Medical Imaging conference proceedings. 1.2.3 Computer-aided Lesion Detection (CAD) and quantification system The MS CAD algorithm is designed to output lesion volumes, lesion locations, and total lesion load. The detailed algorithm design splits up into three parts: preprocessing, lesion voxel identification by probability is prototyped in MATLAB.The algorithm is designed on 3-D MRI brain images. It uses T1, T2, and FLAIR (Fluid attenuated inversion recovery) axial slices. The algorithm converts the MR into a three-dimensional matrix for 3-D lesion analysis.Lesion voxel classification is K-nearest neighbor(KNN) principle. Methodology of the CAD algorithm is described in more detail in the Method section 1.3 MS CAD Validation In order to ensure CAD results to be accurate and conform to current clinical standards, the results need to undergo validation steps. Currently, there are no methods of quantifying lesion volumes other than manual estimation by radiologists. However, the computer-aided detection results can be validated via comparing lesion contours with radiologist's manual contours. This paper aims to present the methodology of MS CAD clinical validation, to present results of findings, and to list future tasks to be completed for MS CAD algorithm in the eFolder system. 342. METHOD 2.1 Data Collection The focus of this presentation is to compare MS CAD findings with radiologists' findings on MRI. For data collection of this presentation, 20 MRI studies of 17 different MS patients have been collected at University of Southern California Medical Center.The cases are all of 3mm slice thickness with 0mm gap between slices. The images are acquired from Siemens\u00ae Symphony Maestro class 1.5T. 2.2 MS CAD methodology CAD steps: preprocessing, voxel identification, clustering and quantification. 2.3 Preprocessing Goal of preprocessing is to standardize and prepare brain images for KNN classification steps. The result of preprocessing is the segmented brain matter, which then can be used to assess total brain volume and to identify all voxels needed for feature analysis. 2.4 Image preparation and Resolution Standardization The first step in image preprocessing is to read and extract the input images: T1-weighted, T2-weighted, and FLAIR axial slices. The images are loaded into a 3-D matrix in MATLAB\u00ae. Intensity values are normalized to 256 grey- scale. Resolutions of the three series are examined. If T1, T2, and FLAIR images are of different resolution, a resolution standardization process is used to resize all images to a standard resolution, i.e. the lowest resolution is used as the uniform resolution of the three sequences, and intensity values of the images are interpolated bi-linearly. 2.4 Image realignment via Midsagittal Plane After the three sequences are of uniform resolution, the second step is to realign the images such that they are of uniform orientation. The images are realigned according to the midsagittal plane (MSP). The MSP is defined as a plane formed from the interhemispheric fissure line segments h aving the dominant orientation5, and the MSP is identified via localizing the fissure line segments in the 3-D brain data set. From identifying the MSP, the yaw, pitch and roll rotation angles of the brain are calculated. The images are rotated using the rigid body transformation principles on the z-plane. Figure 3 shows an original FLAIR image and the image after realignment. Figure 3 Effects of image rotation via midsaggital line (in red). Left: original MR image. Right: Rotated image with normalized intensity values. 2.5 Brain segmentation 35After image realignment, a segmentation of the human brain is needed to select the region of the head where the MS lesions can occur, which is both white and grey matter of the brain (with emphasis in the white matter region). The brain is segmented based on an automated histogram-based algorithm for T1 and FLAIR images. The algorithm involves three steps: 1) foreground/background thresholding, 2) disconnection of brain from skull via morphological operations, and 3) removal of fragments such as sinus, cerebral spinal fluid, and so on6. Figure 4 shows the segmented brain mask and the subsequent isolated grey and white matter. Figure 4 Left: Realigned FLAIR image. Middle: Brain mask. Right: Segmented brain parenchyma 2.6 Lesion Classification based on KNN After the brain is extracted from the 3-D volume data, each T1-w, T2-w, and FLAIR voxel within the brain mask is examined and the probability of each voxel being a lesion or non-lesion voxel is determined. The voxel identification section is based on the k-nearest neighbor (KNN) algorithm7. KNN uses a set number of features to build a multi-dimensional feature space. Features of a single voxel are extracted and put into the feature space. A number K of closest neighbors of the target voxel are found within the feature space. The classification of the input voxel is determined by the composition of classes of the K nearest neighbors. 2.7 Feature Extraction For the lesion classification algorithm, six features are used to build a three-dimensional feature space: voxel intensity of T1, T2, FLAIR images. 2.8 Training Sets The next step is to populate the feature space with lesion voxel features and non-lesion voxel features. To know which voxels are a part of a MS lesion and which are not, a set of four 3mm-slice training cases, or training sets, have been created to train the feature space. The 4 training sets contains T1, T2, and FLAIR brain MR images with various severity and MS lesions present in their white matter (see red box in Figure 4.9). Two neuroradiologists have participated manually segmenting MS lesions from those 4 training sets, thus identifying all lesion voxels. The training steps only need to be completed once, as all future voxel analyses are based on the constructed feature space. The training set includes voxel features from the 4 cases, with each voxel classified as lesion or non - lesion. The general principle of this algorithm is to determine the probability of a voxel being lesion by finding out the number of lesion nearest neighbors out of k nearest neighbors. 2.9 KNN Algorithm with kd-tree Structure For an input voxel, the features are extracted and put into the trained feature space. The distance between the input point and the trained voxels are calculated one- by-one, and 100 closest neighbors are determined. Since there are numerous points in the trained feature space, the KNN calculation process can be computationally tedious and time consuming. A kd-tree structure is then applied to speed up this calculation. 36The algorithm first constructs a kd-tree, and arbitrarily selects the first parent node, which does not have to be a nearest neighbor. The algorithm then searches through the child nodes to find a nearer neighbor. If the neighbor is nearer than at least one of the 100 closest neighbors already found, it is then saved. The program then continues recursively until the end of the tree structure. After the 100 nearest neighbors are identified, their classification as lesion or non-lesion is determined. The formula for calculating lesion probability is as follows: Probability thresholdingis applied to positively or negatively identify a voxel as a lesion voxel. The threshold is currently set as 70% based on results of KNN algorithm on the 4 training sets, therefore point A is classified as a non-lesion. The lesion detection part is completed here and is the focus of the clinical validation process. Figure 5 shows an example of lesion detection results. Figure 5 MS CAD results: Left upper: FLAIR image with brain matter segmented, Right upper: Lesion probability map of the original image in grey-scale. The whiter the voxel is, the more likely it is a lesion voxel. Left bottom: black-and-white lesion map Right bottom: lesion voxels 2.10 Lesion Quantification Lesion voxels in the binary segmentation are clustered in 3-D with 26-connectivity. All clusters smaller than 10 voxels, or approximately 28.6 mm3 in size, are removed due to possibility of being noise. Subsequently, the lesion load (total lesion volume in the brain) and the number of lesions can be calculated using these clusters. Lesion volume is obtained by multiplying number of voxels in a lesion and the voxel size, which is extracted from DICOM headers of images. Lesions are separated into three subgroups: small (< 1 cm3), medium (between 1 and 5 cm3), and large (> 5 cm3). Lesion load is obtained by summing up all lesion volumes, and lesion locations are identified by the coordinates of their centroids. 372.11 CAD result validation methodology The CAD validation methodology designed to be efficient and easy- to-use for evaluators, or neuroradiologists. The goal of the validation process is to compare lesion detection results with radiologists' manual contours, which is considered the gold standard in MS lesion detection. The evaluation workflow is designed as follows: 1. Original MR imagesare shown on a graphical user interface, in this case an ITK-SNAP\u00ae toolkit8 that has been designed to display 3-D images. 2. Evaluators are able to manually contour onto the MR images using ITK-SNAP toolkit. They are instructed to draw contours on the CAD image while using the original image as their references. 3. Manual contour results are compared with CAD results. Both manual and CAD results are quantified via the quantification steps described in the previous section. The advantages of using the toolkit include 1. It offers a manual contouring function by directing outlining the lesions with mouse pointer, 2. It stores results in standardized format, i.e. DICOM or NIFTI, that can be read by other compliant software, including MATLAB\u00ae, and 3. It allows multiple instances to be open on the same workstation, for radiologists to view multiple windows of the same images side- by-side if they choose. A neuroradiologisthasbeen recruited to read the 20 cases and manually contoured all lesions. The results are quantified using the quantification tool and have been recorded. 3. RESULTS 3.1 MS CAD results Table 1 shows the MS CAD results of the 20 MR cases. The bolded columns show longitudinal studies of 3 patients. Table 1 Preliminary MS CAD results of 20 cases. Bolded rows indicate longitudinal studies Patient Age Brain vol. ( ) Total lesion load ( ) No. of 1219 0 P002 59 976 3.89 8 P003 51 1217.6 0 0 P017 28 1463.2 2.1973 20 Figure 6 shows an example of a FLAIR image with lesion detection results shown in ITK-SNAP software. 38 Figure 6.Top: FLAIR image with 2 lists results from both CAD and radiologists' contours. The bolded columns show longitudinal studies of 3 patients. Table 2. Lesion Quantification results from both CAD P001 0 38.00 0 27 P002 3.89 7.11 39 P003 0 9.11 11 32 P005 32.63 12 36 P007 0.9413 3.52 5 28 P007 0 4.66 5 45 P009 1.3103 7.43 32 77 P012 1.0071 11.6 25 57 P016 0.0801 2.38 2 24 P016 0 1.78 0 16 P017 2.1973 8.78 20 56 Figure 7 shows a sample image of CAD contour versus the radiologist's manual contour. Figure 7. on top of MR image. Right: CAD plus Radiologist's edits on top of same MR image 4. DISCUSSION From initial evaluation, there are significant difference between CAD results and radiologist's evaluations. The CAD algorithm has underestimated lesion volumes and has identified fewer lesions than radiologist's readings. The 40most common characteristic of CAD results, while compared with radiologist's contours, is that CAD is less sensitive on small lesions and does not accurately contour the bigger lesions. This can be attributed to two reasons: 1. the threshold value is too high and needsrefinement and 2. noisethresholding is too high at 10 voxels. It should be noted that most of the lesions missed by CAD are very small and may only appear in one image, instead of multiple images for larger lesions. Many smaller lesions identified by radiologists should also be considered as part of a larger lesion per CAD identification. In the expert's opinion, the CAD algorithm corr ectly identified roughly 60% of MS lesions.On the other hand, out of the 20 cases, only 2 cases contain false positive detections. Based on the evaluation results, the CAD algorithm needs to undergo further revision: Adjusting thresholding and clustering techniques to give a more accurate detection Adding more features (such as location coordinates) in KNN search can increase voxel classification accuracy More training cases and better-selected training cases can improve KNN search as well More radiologists are needed to give a more robust evaluation results 5. CONCLUSION MS CAD algorithm, designed to automatically detect MS lesions in brain MRI and quantify lesion volumes and numbers, has been successfully developed and is now in evaluation and revision stage. Preliminary evaluation results show that the algorithm is underestimating lesion volumes and numbers of lesions compared to a radiologist's readings. The evaluation results will aid future revisions and improvements of the MS CAD program, which has the capability of aiding clinicians and researchers in identifying and tracking MS lesions in MR studies. The completed MS CAD program will be integrated in the MS eFolder, making it a complete and powerful imaging- informatics- based system in MS treatment and research. REFERENCE [1] National Multiple Sclerosis Society http://www.nationalmssociety.org/about-multiple-sclerosis/index.aspx [2] S Ringold, C Lynn, R Glass Multiple Sclerosis JAMA. 2005;293(4):514 [3] D Hafler Multiple [4] KO Lovblad, N Anzalone, A Dorfler, et al. MR Imaging in Multiple Sclerosis: Review and Recommendations for Current Practice Am J Neuroradiol 2010; 31:981 -89 [5] Q Hu, W Nowinski, A rapid algorithm for robust and automatic extraction of the midsagittal plane of the human cerebrum from neuroimages based on local symmetry and outlier removal. NeuroImage, 20(4):2153{2165, Dec 2003. [6] Z Shan, G Yue, J Liu, Automa ted histogram-based brain segmentation in t1-weighted three-dimensional magnetic resonance head images. NeuroImage,17(3):1587{1598, Nov 2002. [7] P Anbeek, K Vincken, M van Osch, et. al. Probabilistic segmentation of white matter lesions in MRimaging. Neuro Image, Mar 2004. [8] Hazlett et al. User -guided 3D active contour segmentation of anatomical structures: Significantly improved efficiency and reliability. Neuroimage 2006 Jul 1;31(3):1116- 28. 41A Solution for Archiving and Retrieving Preclinical Molecular Imaging Data in PACS Using a DICOM Gateway Jasper Lee*a, Bihui Liu a, Brent Liu a a Image Processing & Informatics Laboratory, USC90033, CA ABSTRACT Advances in biology, computer technology and imaging technology have given rise to a scientific specialty referred to as molecular imaging, which is the in vivo imaging of cellular and molecular pathways using contrast-enhancing targeting agents. Increasing amounts of molecular imaging research are being performed at pre-clinical stages, generating diverse datasets that are unstructured and thereby lacking in archiving and distribution solutions. Since PACS in radiology is a mature clinical archiving solution, a method is proposed to convert current imaging files from preclinical molecular imaging studies into DICOM formats for archival and retrieval from PACS systems. A web-based DICOM gateway is presented with an emphasis on metadata mapping in the DICOM header, system connectivity, and overall user workflow. This effort to conform preclinical imaging data to the DICOM standard is necessary to utilize current PACS solutions for preclinical imaging data content archiving and distribution. Keyword : Molecular Imaging, PACS, Preclinical Data, Archiving, DICOM 1. INTRODUCTION With rapid advances in biology, computer technology and imaging technology, molecular imaging has been growing in recent years in the generation of valuable new imaging data. The interest in molecular imaging has especially increased the amount of pre-clinical images data being created, consequently requiring robust archiving solutions at many research institutions.[1] PACS is the de facto archiving solution for clinical radiology, but it has been standardized to the DICOM file format. A method is presented here to receive and convert preclinical molecular images into DICOM formats so that they conform to the interface requirements of most PACS archives. The benefits of utilizing existing PACS solutions for preclinical imaging datasets are its standardized data exchange interface, structured data content search and retrieval functionality, and mature vendor-supported hardware and software solutions. 1.1 Utilizing PACS for Preclinical Research The clinical application of PACS is to receive, archive, display, and distribute digitized medical imaging studies for radiology and any related physicians in medicine. To achieve this over the past decades, PACS has revolutionized the field of medical imaging, calling for information technology standardization, workflow optimization, and extensive industrial vendor support.[3] Although imaging-based preclinical research is focused on animal-model studies as opposed to patient diagnosis, the data management demands and investigative workflow are similar to clinical radiology. The preclinical investigative workflow shown in Figure 1 demonstrates the need for a data archiving and distribution system for steps 7 and 8, respectively. Adopting PACS for preclinical research environments would capitalize on the data management infrastructure already available for medical imaging data content. *jasperle@usc.edu; phone 1 213 743-2520; fax 1 213 743-2962; www.ipilab.org 421. Plan Imaging Studies2. Schedule Imaging3. Prepare Animals4. Staff Technicians Perform Scan5. Staff Performs Post-processing (if required) 7. Data Archiving8. Data Distribution6. Analysis & Reporting9. Investigator Views Images and Results Local Network Storage Device Figure 1. General preclinical investigative workflow at preclinical molecular imaging facilities 1.2 Preclinical Molecular Imaging Data Objects Preclinical investigators are increasing interested in cellular and sub-cellular activity in animals by utilizing novel molecular imaging modalities available at animal imaging facilities. The results are color-enhanced and multi- modality images that simultaneously illustrate anatomical and pathology information to researchers.[5] However, generating and analyzing these datasets create diverse and non-standardized file formats because it requires complex, often proprietary, pre-processing and post-processing techniques. Raw data is represented in various binary file formats, intermediate post-processing files is often proprietary in format, and final viewable images are outputted in a myriad of display formats such as JPEG, TIFF, BMP, and PNG. Furthermore, data context and metadata is usually represented as separate header text files, thereby requiring users to associate header files t o corresponding imaging files. A growing number of preclinical imaging software can export DICOM file formats for their final viewable images, but these typically fail to capture comprehensive study context and metadata in their DICOM header. To avoid incomplete DICOM datasets and non-DICOM image formats in preclinical data archives, a centralized and standardized data storage solution is needed for preclinical imaging environments.[4] Table 1 is an overview of the diverse preclinical molecular imaging data objects from six preclinical imaging modality types that have been identified by the USC Molecular Imaging Center. 43Table 1. Preclinical molecular imaging file formats. Modality Type File Format Description Software (Manufacturer) MicroPET *.lst *.scn.hdr *.img Manager (Siemens) MicroCT *.cat + *.cat.hdr *.img + *.img.hdr Image Acquisition Inveon (Siemens) Cobra (Siemens) PET/CT *.img *.img *.xif PET Input file CT Input file -registered Image Amide (GNU Project) Optical *.tif *.txt *.png Acquisition files Processing Parameters Final Overlayed Image Living Image (Xenogen) Ultrasound *.avi *.ana Image Acquisition file Analysis ROI file OptiQuant (Packard Instrument Co.) 2. METHODOLOGY The design of the DICOM conversion gateway requires a user interface that allows multiple researchers to input textual metadata and attach original preclinical imaging files to be sent to PACS as a normalized DICOM study dataset. This was achieved by implementing the gateway as an Apache web-server with a database and DICOM- handling Java services. The system connectivity, workflow, user interface, and DICOM conversion are presented here. 2.1 System Connectivity and Workflow The web-based DICOM conversion gateway shown in Figure 2 is access by investigators as a secure web-page on their workstations (WS) across a local-area-network. Through the web-page, investigators login with their registered account and password, and then upload new study datasets by filling out fields with relevant preclinical study metadata. After preclinical imaging scans and analysis are completed, the physical data files generated can be transmitted from investigator workstations to the DICOM conversion gateway via network-shared directories on the gateway using the Server Message Block protocol (SMB). Once studies are registered into the user interface and imaging files are copied to the gateway, the investigator can initiate DICOM conversion and archiving into the PACS Server by clicking on a submission button in the final step of the upload process. Once in the PACS Server, the normalized preclinical studies are cataloged and stored to the PACS Archive that typically comes with a PACS implementation as a redundant disk device. Lastly, PACS solutions include sophisticated viewing workstations with visualization features such as window/level adjustments and customizable hanging protocols. However, if investigators require physical retrieval of the preclinical studies from the PACS, the normalized DICOM files can be retrieved directly from the PACS Server to a DICOM device such as the web-based DICOM conversion gateway. 44Preclinical Investigator WS PACS WS DICOMProprietary HTTP/SMB Figure 2. General investigative workflow at preclinical molecular imaging facilities Referring to the preclinical investigative workflow, Figure 3 shows that adding the web-based DICOM conversion gateway requires an additional event into the data archiving process. Once investigators plan and schedule their preclinical imaging study, they can register the new study's metadata into the web -based DICOM conversion gateway. This preliminary event replaces the current methods of logging preclinical study metadata on paper notebooks by imaging technicians and provides a single-entry solution for normalizing all data generated during a study. Step 7 is the physical uploading of created preclinical imaging files to the DICOM conversion gateway. As mentioned earlier, a final submit process is required by investigators to begin the DICOM conversion and archiving in to the preclinical imaging PACS. Investigators can download their DICOM studies in Step 9 by requesting specific studies from the gateway's web -based user interface. The gateway would send a DICOM C-Find and C- Move request to the PACS Server with a unique study identifier. When a requested DICOM study is received at the gateway, it is available for network file transfer in the same way that the original files were uploaded from investigator workstations. 1. Plan Imaging Studies2. Schedule Imaging3. Prepare Animals4. Perform Scan 5. Performs Post-processing (if required) 7. Data Archiving9. Data Distribution6. Analysis & Reporting10. Investigator Views Images and ResultsuploadRegister study New session 8. Web-Based DICOM Conversion Gateway to Preclinical Imaging PACS download Figure 3. Revised preclinical investigative workflow using the web-based DICOM conversion gateway and PACS 2.2 Web-based Graphical User Interface The graphical user interface was created for the DICOM conversion gateway to enable preclinical metadata input and to customize user interactions with the consequent PACS archive. User input is necessary for capturing study- level metadata for the automated DICOM conversion process using DICOM toolkits. Relevant study metadata that was previously scattered across unstructured textual header files can now be centralized and inserted into DICOM images. A customized user interface is needed for advanced search functionality by detailed preclinical imaging parameters, such as animal-model type or IACUC (Institutional Animal Care and Use Committee) number. The user 45interface was created as a web-based display to enable multiple simultaneous user access and to avoid client-side software installation requirements. The main features of this web-based interface are demonstrated in screenshots seen in Figures 4 and 5. Figure 4. User interface for preclinical study metadata registration Figure 4 shows the new study registration form that can be filled out by either primary investigators or preclinical imaging facility staff upon defining the study plan. It requires general preclinical study metadata input such as study date, animal type, IACUC number, and a list of users who have access to download this study's dataset after it has been uploaded. Figure 5 shows the preclinical study download page that allows investigators to download their study datasets, and also to perform advance search for openly shared studies that are available on the preclinical research PACS. 46 Figure 5. User interface for preclinical study download and advanced search 2.3 DICOM Conversion With similarities and differences between molecular imaging research and clinical radiology environments, mapping molecular imaging study metadata to DICOM header tags originally intended for clinical patient studies required some customization. Nonetheless, certain pre-defined DICOM unique identifiers (UID) such as Service-Object Pair (SOP) Class UID and Transfer Syntax UID were kept in conformance to the DICOM standard. Table 2 lists and describes the DICOM tags that are modified by the DICOM conversion gateway. Although not all 38 fields are required for successful storage within PACS, certain metadata are inserted for the benefit of investigators who will download and import these DICOM files on their own computers. Because the preclinical molecular imaging workflow does not require the assignment of patient, study, series, and file instance identifiers, these DICOM tag values were generated by the DICOM conversion gateway and are highlighted in orange text in Table 2. Table 2: List of DICOM tags that are mapped by the DICOM conversion gateway 47DICOM Tag Tag ID VR Description Media Storage SOP Class UID 0002,0002 UI Same as SOP Class UID Transfer Syntax 0002,0010 UID 0008,0018 UI SeriesUID.FileID Study Date 0008,0020 DA Study Date, in the form of yyyymmdd Series Date 0008,0021 DA Session Date, in the form of yyyymmdd Accession Number 0008,0050 SH StudyUID without the periods middle. Modality 0008,0060 CS Modality Type Abbreviations: CT, PT, OPT, US, AR Manufacturer 0008,0070 LO Modality Manufacturer Name Institution 0008,0080 LO Investigator's Institution Referring Physician 0008,0090 PN Investigator's Full Name Study Description 0008,1030 LO Study Description Series Description 0008,103E LO Scan Comments Department 0008,1040 LO Investigator's Department Operators' Name 0008,1070 PN Model PatientName 0010,0010 PN Animal Subject's Name Patient ID 0010,0020 LO Investigator ID Patient Sex 0010,0040 CS Animal Subject's Sex, M or F (has to be uppercase) Patient Age 0010,1010 AS Animal Subject's Age, nnnY Patient Weight 0010,1030 DS Animal Subject's Weight in kg Patient Species Description 0010,2201 LO Animal Type (eg. mouse, rabbit, etc.) Clinical Trial Committee 0012,0081 LO \"Clinical Trial Protocol Ethics Committee Name\" = IACUC Clinical Trial Approval Number 0012,0082 LO \"Clinical Trial Protocol Ethics Committee Approval Number\" Exam Part 0018,0015 CS Animal Imaging ROI, Body Part Contrast Agent 0018,0010 LO Radiopharmaceutical Biomarker (ex. FDG) Study ID as not accounted for) Deviating from the clinical DICOM data model, the Referring Physician' tag (0008,0090) has been allocated for the preclinical investigator's full name, and the investigator's ID to the Patient ID' tag (0010,0020). The investigator's name is placed into the Referring Physician' tag because investigators play a synonymous role in requesting an imaging exam. The investigator's ID was used in the Patient ID' tag instead of an animal ID because molecular imaging studies in research put little emphasis on individual animal-models. In stark contrast with clinical radiology where patients are the focus and owners of imaging studies, investigators are the owners of imaging studies and animals are simply vehicles in a study. Placing the investigator's ID into the Patient ID also enables DICOM - compliant software to sort imaging studies by investigators rather than a multitude of different animal ID's. The 48other patient-related tags such as patient name and patient age, however, remain affiliated with the actual animal subject of the imaging scan. In summary, although the preclinical DICOM conversion gateway has a study-centric workflow to maintain user-access control, the DICOM data model adapted for preclinical imaging studies is a hybridization of investigator and animal subject metadata. 3. RESULTS and DISCUSSION To evaluate the preclinical DICOM conversion gateway, sample datasets from six molecular imaging modalities were collected at the USCMolecularImagingCenter. Each dataset contains sample files from the acquisition, post- processing, and distribution categories, when available. The distribution category represents conclusive files that are typically selected and given to investigators for visualization and documentation. The preclinical molecular imaging file formats that were able to be converted to DICOM and sent into a PACS archive are highlighted in red font in Table 3. Table 3: Preclinical Molecular Imaging File Formats Collected from USC MIC for Evaluation MicroCAT MicroPET Pet-CT Optical Imaging US TIFF XLS PDF PDF AVI 3.1 DICOM Conversion Although DICOM conversion was successful for most distributed file formats, some raw binary files and text files seen in the acquisition and post-processing categories have not yet been converted to DICOM by the preclinical DICOM conversion gateway. This is because the DICOM toolkit, DCM4CHE2[2], that is used does not yet support or was not used for the DICOM conversion of these formats. Further work can be done to manually parse these binary and text files so that they can be encoded into the appropriate DICOM file formats. The other aspect of converting preclinical imaging files to DICOM regards metadata mapping of animal-model experiments to the DICOM standard tags originally developed for human subjects. Because preclinical imaging studies typically belong to primary investigators, investigators are the obvious candidate for the DICOM patient object. That way, PACS workstations will automatically organize multiple studies by investigator identifiers in their worklist. However, the theoretical patient subjects in these preclinical scans are the animal-models being experimented on, leaving no sensible DICOM tag for anim al-related metadata such as animal weight, age and ID, which is critical in longitudinal animal studies. Thus, an alternative solution would be to map animal-related metadata fully to the DICOM patient object and to defer investigator identifies to the referring physician tag, as seen in Table 2. The necessary compromise would be to modify PACS workstations so that studies can be hierarchically categorized by referring physician identifiers, instead of the typical patient tag identifiers. 3.2 Maintaining N on-DICOM Data Authenticity The caveat to standardizing preclinical data formats for storage in PACS is that original data formats are not maintained. Sometimes investigators want to re-visit earlier studies and use a different pre- or post-processing methodology. However, most of today's preclinical imaging software do not support DICOM and require original data formats to be imported. Although reverse operations can probably be implemented into the download dataflow at the DICOM conversion gateway to address this need for authentic data, its development is counter-intuitive and computationally wasteful. A compromise would be to keep a copy of the authentic non-DICOM acquisition and post-processing files on a separate file server attached to the preclinical DICOM conversion gateway, so that users 49are given the option to download DICOM studies from PACS or authentic data format. Additional data management services would need to be implemented to support this design. 4. CONCLUSION With increasing volumes of molecular imaging studies being performed in preclinical research, preclinical imaging facilities are challenged with managing diverse and often proprietary experimental imaging data formats. While PACS is a mature medical image archiving technology that can be utilized as a robust central data repository, a DICOM conversion gateway is needed to convert preclinical molecular imaging formats into DICOM for archival into PACS. An investigator workflow, web-based graphical user interface, and DICOM conversion method were presented to demonstrate the design of the preclinical DICOM conversion gateway. Results show the ability to convert and archive TIFF, JPEG, BMP, PNG, and PDF file formats into PACS. Further work can be done on the PACS-side to facilitate preclinical user workflow and preservation of pre-processed data objects. REFERENCES [1] Anderson N, Lee E, Brockenbrough J, et al (2007) Issues in Biomedical Research Data Management and Analysis: Needs and Barriers. Journal of the American Medical Informatics Association. 14:478-488. Yet?.RadioGraphics. 29(5):247-1251. doi: 10.1148/rg.295095151 [4] Lee J, Documet J, Liu BJ, Park R, Tank A, Huang HK. (2010) MIDG-Emerging Grid Technologies for Multi-Site Preclinical Molecular Imaging Research Communities. International Journal of Computer Assisted Radiology and Surgery. al (2005) Small Animal Imaging Center Design: the Facility at the UCLA Crump Institute for Molecular Imaging. Mol Imaging Bio. 7(6):393-402. doi: 10.1007/s11307- 005-0015-2 50Development of a Data Mining and Imaging Informatics Display Tool for a Multiple Sclerosis e-Folder System Margaret Liu, Jerry Loo,Kevin Ma,Brent Liu Image Processing and Informatics Laboratory, Department of Biomedical Engineering, University of Southern California, Los Angeles, CA 90089 ABSTRACT Multiple sclerosis (MS) is a debilitating autoimmune disease of the central nervous system that damages axonal pathways through inflammation and demyelination. In order to address the need for a centralized application to manage and study MS patients, the MS e-Folder \u2014a web-based, disease-specific electronic medical record system \u2014 was developed. The e-Folder has a PHP and MySQL based graphical user interface (GUI) that can serve as both a tool for clinician decision support and a data mining tool for researchers. This web-based GUI gives the e-Folder a user friendly interface that can be securely accessed through the internet and requires minimal software installation on the client side. The e-Folder GUI displays and queries patient medical records --including demographic data, social history, past medical history, and past MS history. In addition, DICOM format imaging data, and computer aided detection (CAD) results from a lesion load algorithm are also displayed. The GUI interface is dynamic and allows manipulation of the DICOM images, such as zoom, pan, and scrolling, and the ability to rotate 3D images. Given the complexity of clinical management and the need to bolster research in MS, the MS e-Folder system will improve patient care and provide MS researchers with a function-rich patient data hub. Keywords: multiple sclerosis, e-Folder, graphical user interface, web-based, DICOM 1. INTRODUCTION The goal of this paper is to present the development of a data mining and imaging informatics display tool for a multiple sclerosis e-Folder system. The graphical user interface (GUI) would display information stored in the MS e-Folder system and allow patient data lookup and data mining. Its interface aims to simplify workflow for physicians, allowing pertinent information to be displayed in a quick and presentable manner. This comprehensive informatics tool can benefit physicians and radiologists in decision support, treatment assessment, outcome analysis, quantified lesion tracking, and act as a data repository for clinical researchers. 1.1 Multiple Sclerosis Multiple Sclerosis (MS) is an autoimmune neurological disease affecting approximately 2.5 million people worldwide. The body's own immune system attacks the central nervous system, causing damage and scar tissues in the brain, spinal cord, and optic nerves1. MS symptoms vary greatly and, in the most severe cases, can be disabling and life-threatening. MS exhibits itself differently amongst different ethnicities2, such as different prevalent symptoms, differences in disabilities, MS lesion locations, and response to treatments3. Factors in environmental exposures may also result in MS taking different forms and progressions. 1.2 e-Folder concept An MS e-Folder is an imaging informatics-based tool for MS treatment and research. The concept of the e-Folder is derived from electronic patient record (ePR) system. An ePR system is a comprehensive patient record database that includes a patient's demographic information, medical history, disease history, and any other information that is needed in a clinical environment. The advantages of an ePR are 1. It is paperless and easily accessible anywhere with a connection to the database server 2. It is comprehensive and can be designed to hold any information 3. It allows communication between different departments acting as a record-keeping and master database for the enterprise environment. 51The e-Folder differs from the ePR in many ways. First, the e-Folder is specifically designed for patients diagnosed for a specific disease; in this case, MS. Thus, the system is required to store data that are relevant to the disease. An ePR, on the other hand, is designed for patients in a certain geographical environment or a certain facility. Second, the e-Folder is designed for data mining for specific disease characteristics. This allows for a more powerful tool for gathering data in research specifically on the disease. The e-Folder, therefore, has a unique capability of decision support and treatment planning for the disease. The MS e-Folder combines three components into one comprehensive system: patient data database, patient images, and CAD results. The system simplifies workflow for physicians in making follow up evaluations of multiple sclerosis patients, deciding course of treatment for patients, tracking lesion changes over several imaging studies, and making objective comparison studies for patients of different backgrounds and ethnicities.4 1.3 Importance for developing a comprehensive display tool for MS treatment and research The development of a web-based graphical user interface (GUI) tool that properly displays information stored in the Multiple Sclerosis (MS) e-Folder system would allow easy accessibility to physicians and researchers in search of MS-specific information. Its interface aims to simplify workflow for physicians, allowing navigation of pertinent information. Furthermore, with its querying capabilities, the e-Folder GUI is designed to be a powerful data mining tool that will enable MS-related research. 2. METHODS 2.1 Graphical user interface design (GUI) overview The e-Folder system GUI is web-based and written in PHP: Hypertext Preprocessor (PHP) scripting language. The GUI communicates with the e-Folder database and allows the user to view clinical data, perform data mining, input patient records, scroll MR images, and view a 3D lesion model based on CAD results. The GUI layout was coded using HyperText Markup Language(HTML) and Cascading Style Sheets (CSS). Information security is achieved through the use of anonymous patient data that is obscured using patient ID codes, user login page, and various levels of user access. The highest level of a ccess is administrator, and users belonging to this group are able to browse data, query, input, edit, and delete records. Users belonging to the clinician/researcher group will be granted permissions to browse data, query, input and edit records only . Finally, a registered user group is reserved for users to be granted query and data browsing capabilities only. These measures insure the e- Folder system's compliance with the Health Insurance Portability and Accountability Act (HIPAA) and address any other concerns for patient privacy. The e-Folder GUI is completely web-based, allowing for remote access from anywhere in the world where internet access is available. The MS e-Folder is fully supported by the latest iterations of all major web browsers, including Microsoft Internet Explorer, Mozilla Firefox, and Google Chrome. 2.2 GUI Workflow Design With the MS e-Folder system, users can query and input MS patient data. The basic steps for inputting data are as follows: Input Patient Data: GUI Workflow (Figure 1) 1. Users with data inputting privileges can enter patient information via a fillable form (Figure 2) accessed from the Input Record hyperlink available on the GUI main page (Figure 3). A new tab will open in the browser window, allowing users to input data while browsing patient data at the same time. Patient information is currently obtained from paper-based surveys; however, the process can be improved such that patients can fill out the survey forms via the GUI as well. 2. MR images are acquired from a DICOM source (i.e. PACS). Users will be able to query PACS and retrieve the MR images of that patient. The MR images are downloaded and converted into JPEG format, and the DICOM header information is saved into the MS e-Folder database. 3. When the MR images are retrieved, it is simultaneously pushed to MS CAD workstation. After processing, CAD results are stored in the database and are available for viewing via GUI. 52 Figure 1.Workflow diagram of inputting patient data. Figure 2.The Input Record page for entering in data for demographics and MS history. Input Patient Data Enter patient information via GUI form Acquire MR images from a DICOM source MR images downloaded & converted to proper format MR images pushed to CAD workstation for processing CAD results are stored in database 53 Figure 3.Main page as seen by an administrator level user viewing clinical data, MR images, a 3D lesion model, and query options. There are two ways to view patient data. Users may use the Quick Lookup hyperlink on top panel if they know the patient ID or name. Alternatively, they may click the Advanced Query hyperlink to search for patients. Data mining is achieved by using the latter method by selecting query criteria and clicking search. Queries are conducted in the following way: Viewing Patient Data: GUI Workflow (Figure 4) 1) Users can click on the Advanced Query hyperlink to access the advanced query function of the e -Folder from the main GUI page (Figure 3). A new tab will open in the browser window, allowing users to conduct a query while browsing a patient record at the same time. 2) Various criteria can be selected (Figure 5) and patients who meet these parameters will be included in the results when the search button is clicked at the bottom of the page. 3) After clicking search, a list of results will be displayed on the Query Results page (Figure 6). Each patient record listed here can be loaded by clicking on the patient name, which is a hyperlink and will immediately load on the previous tab displaying patient records. 54 Figure 4.Workflow diagram of viewing patient data. Figure 5.An advanced query for relapse-remitting MS patients. View patient data Quick lookup Advanced query By MRN (patient ID) By first name By last name By demographics By MS history By family history By medical history By social history Query results page Individual patient record 55 Figure 6. Query results page that displays 18 patient results after clicking search in Advanced Query. 2.3 Patient clinical data display A patient record in the MS e-Folder is divided into six basic sections: 1) demographic data, 2) MS History, 3) Medical History, 4) Social History, 5) Imaging, 6) 3D Lesions. Figure 3 shows the primary layout of the MS e- Folder as seen by a user with administrator access. At the top of the patient record, demographic data is displayed. This includes date of birth, age, sex, handedness, race, ethnicity, and contact information. The demographic data section is static and is visible to the user at all times, even when viewing different subsections of the e-Folder. Imaging data is dedicated to the right hand side of the GUI, while clinical data is allotted to the left hand side. The e-folder divides clinical data into three tabbed subsections. The MS History tab (Figure 7) includes data on MS Type, age at onset, disability status, MS symptoms, lab results, and family history. Figure 7. MS History tab displaying pertinent clinical information. 56The Medical History tab (Figure 8) contains data on medications, parasites, past medical history, exanthems, and vaccines. Figure 8. Medical History tab showing pertinent clinical information. The Social History tab (Figure 9) includes data on birthplace, occupation, environmental exposures, clinic history, and family background. Figure 9. Social history tab showing pertinent clinical information. A separate section of the GUI is dedicated to MR images, which are fetched based on file locations stored in the database (Figure 10). Below this section, an area is allocated for the display of a 3D lesion model constructed from CAD results (Figure 11). 572.4 MR image viewing The images are stored in both the DICOM format and the converted JPEG images. The DICOM- to-JPEG conversion allows for speedy and responsive viewing in a web browser. JavaScript-based image manipulation tools allow for dynamic viewing of the images, similar to functions in a PACS image viewer. Figure 10.The JPEG image displayed in the GUI of an MR image. 2.5 3D MS lesion quantification result viewing Currently, 3D lesion models are generated using CAD results. The lesion masks generated from CAD processed MR images are stacked into a 3D object and displayed in the e-Folder system as a rotating, pre-animated Graphics Interchange Format (GIF) file (Figure 11). Future versions of the e-Folder system will allow for rotation and zooming of 3D lesion models and select a specific region to view for both brain MRIs and secondary captures of CAD lesion analysis results. Figure 11.A 3D lesion model displayed in the GUI as a pre-animated GIF. Quantitative results displayed include total lesion load, brain volume, number of lesions, size of each lesions, 3D location of each lesions, secondary captures of lesion contours overlaid on top of original images, and 3D rendering of the quantification study (Figure 12). 58 Figure 12.Quantitative CAD results displayed in the GUI. 2.6 Data querying The GUI allows relevant data to be found upon query using the Advanced Query webpage, which opens in a separate browser window or tab (Figure 5). Within the e-Folder database, many fields follow Systematized Nomenclature of Medicine (SNOMED) to standardize names and codes for symptoms, race, country of origin, vaccines, and etc., which allows an easier and universal way of querying data of that nature. The user can query the demographic data, MS History, Medical History and Social History using any number of criteria. Certain variables such as symptoms and family history, which have the possibility of multiple data entries per patient, have an additional AND and OR functionality built in to allow for more complex queries. Results are displayed on a Query Results page (Figure 6). The patient names on the Query Results page are hyperlinks which can be clicked and loaded on a separate browser tab. 2.7 Data Input Patient data can be input by authorized personnel via an Input Record webpage (Figure 2). Inputting new records is an essential component for the e-Folder system as it allows researchers from any remote location to contribute data on MS patients. This webpage provides the user with a blank form that can be filled with data values for the variables mentioned above. Many of the values for fields on this form are easily selectable using drop-down lists allowing for fast and efficient data entry. Using drop-down lists for commonly entered values ensures that the data entered is always validated and eliminates input mistakes that could hinder the data query functions of the e-Folder system. Patient records created from the GUI will be input into the back-end MySQL e-Folder database. 3. RESULTS 3.1 Initial testing results The GUI has been designed and developed as a working prototype. Initial testing of data display and data input has been completed.Initial data mining test looking up patients based on MS history information were performed during the initial testing. As an example, to look for patients with relapse-remitting MS, \"Relapsing Remitting (RR)\" is selected under \"Disease History in the MS History se ction (Figure 5). The query returns 18 results (Figure 6). MS patient data can also be found with a combination of query options. To look for patients of Hispanic race born in the USA, Hispanic is selected under Race in the Demographics section and USA is selected under Birth Place in the Social History section. 593.2 Future work The MS e-Folder GUI has some components that have not yet been incorporated, but are in progress and will continually increase the capabilities of the eFolder system. Future works include developing the ability to search for patient data based on CAD results and image data, such as imaging date and image type, which will further increase the data mining capabilities of the GUI. Currently, MS CAD output is designed to fit the DICOM-SR (structured report) format. The advantages of DICOM-SR include storing CAD results as DICOM objects in DICOM-compliant storage, a standardized structure to store and display results, and allowing queries based on results data. Data mining is thus possible through report content. Thus, the web-based GUI will include the functionality of displaying and querying DICOM-SR contents, further improving its data mining capabilities. Also, as mentioned previously, there will be an interactive display for 3D lesion viewing, allowing for rotation and zooming of 3D lesion models. There will also be performance user tests in order to obtain feedback and improve the features of the GUI. Efficiency and ease of use will be key factors in user feedback and will influence future modifications in design. More cases will be entered into the database, which will allow for true data-mining with the expansion of the database. 4. CONCLUSION This paper describes the design and development of a data mining and imaging informatics display tool for a multiple sclerosis e-Folder system for MS decision support. It is a display tool for the e-Folder system that was previously presented. The system is completely web-based to allow access across the healthcare enterprise and provide user-friendliness to the MS e-Folder. The e-Folder GUI serves as an evaluation tool for conducting MS research, including differences of MS between different racial and ethnic groups. REFERENCES [9] National Multiple Sclerosis Society http://www.nationalmssociety.org/about-multiple-sclerosis/index.aspx [10] Cree B, Khan O, Bourdette D, et al. Clinical characteristics of African Americans vs Caucasian Americans with Multiple Scl erosis Neurology 63:2039 -2045 (2004) [11] Yamasaki K, Kira J, Kawano Y et al. Western versus asian types of multiple sclerosis: Immunogenetically and clinically distinct disorders Annals of Neurology 40:4 569 - 574 (2004) [12] Ma, K., Jacobs, C., Fernandez, J., Amezcua, L. and Liu, B., \"The development of a disease oriented eFolder for multiple sclerosis decision support\", Proc. SPIE 7628, 76280G (2010) 60Improvement of MS (Multiple Sclerosis) CAD (Computer Aided Diagnosis) performing using C/C++ and computing engine in the graphical processing unit (GPU) JoohyungSuh*, Kevin Ma, Anh Le Department of Biomedical Engineering, USC, Los Angeles, CA, USA 90089 ABSTRACT Multiple Sclerosis (MS) is a disease which is caused by damaged myelin around axons of the brain and spinal cord. Currently, MR Imaging is used for diagnosis, but it is very highly variable and time-consuming since the lesion detection and estimation of lesion volume are performed manually. For this reason, we developed a CAD (Computer Aided Diagnosis) system which would assist segmentation of MS to facilitate physician's diagnosis. The MS CAD system utilizes K-NN (k-nearest neighbor) algorithm to detect and segment the lesion volume in an area based on the voxel. The prototype MS CAD system was developed under the MATLAB environment. Currently, the MS CAD system consumes a huge amount of time to process data. In this paper we will present the development of a second version of MS CAD system which has been converted into C/C++ in order to take advantage of the GPU (Graphical Processing Unit) which will provide parallel computation. With the realization of C/C++ and utilizing the GPU, we expect to cut running time drastically. The paper investigates the conversion from MATLAB to C/C++ and the utilization of a high-end GPU for parallel computing of data to improve algorithm performance of MS CAD. Keywords: CAD, Multiple Sclerosis, GPU 1. INTRODUCTION Multiple Sclerosis (MS) is an inflammatory neurological disease which damages the myelin pathway. There are several symptoms such as visual problem, muscle weakness and depression. And the cause of MS still remains unknown [1]. According to the National Multiple Sclerosis Society', approximately 400,000 Americans suffer from MS and every week about 200 people are diagnosed. The MR (Magnetic Resonance) imaging are used to diagnosis. To detect the lesion, MR (Magnetic Resonance) images are used. In this process, the radiologists look for the lesion in the image and then mark a detected lesion manually. They also try to estimate the number and gross size of lesions based on diameter measurements in the patient's brain. The lesion can be detected easily by radiologists, but the quantification of lesions is difficult and extremely-time consuming. For those reasons, an algorithm for a fully automatic Computer Aided Diagnosis system of multiple sclerosis has been developed by IPILab. Currently, the computer aided diagnosis system with the developed algorithm consumes a large amount of time (approximately 3 hours for one MS case) to detect and quantify lesions because the prototype algorithm was developed under the MATLAB environment. This needs to be improved to make it faster by implementation of the algorithm in C/C++ and the utilization of parallel computing technology by the graphical processing unit (GPU) to cut the running time of the system. In this paper, we will show the results of the performance of the system after conversion from MATLAB to C/C++ and discuss how to apply the parallel computing technology into the developed algorithm. Lessons learned and pitfalls will also be discussed to avoid similar mistakes in the future when developing image processing algorithms with heavy computational time demands. The result of this study will show the effectiveness and benefits of this second version of MS CAD on MS diagnosis. 2. MS CAD (MULTIPLE SCLEROSIS COMPUTER AIDED DIAGNOSIS) SYST EM 612.1 Overview As shown in Figure 1, the MS CAD system consists of three parts: 1) Pre-Processing, 2) Searching Lesion and 3) Post Processing. In this system, the T1-weighted, T2-weighted and Fluid Attenuated Inversion Recovery (FLAIR) images are used as input. The output is the number and volume of detected lesions. Figure 1.Overview of the MS CAD system. 2.2 Pre-Processing Component In the Pre -Processing part', the system reads the data, MR images and extracts the brain mask, brain segmentation. There are two parts in the Pre -Processing' part: I. Alignment' and II. Extracting the brain mask'. The system uses 62three different kinds of MR images which required alignment. So in the Alignment' part, each tilt angle of data is calculated by an algorithm designed by Hu et al. [2]. Then the system rotates the images for alignment. The next step is the brain segmentation. This process is based on the paper of Shan et al. [3]. 2.3 Searching Lesion Component After obtaining the brain mask, the system finds lesions on the brain mask. In this process, the system uses the K- Nearest Neighbor classification. This process is based on the paper by Anbeek et al. [4]. In the paper, the authors presented a method to use K-Nearest Neighbor (KNN) classification to develop an automatic segmentation algorithm to detect lesions in the white matter. The system uses k-dimensional tree (KD-tree) [5] instead of the brute force KNN classification which is the straightforward method but consumes a large amount of time. KD-tree is a space-partitioning data structure for storing a finite set of points. By splitting the data, we can decrease the number of computations and make the KNN algorithm faster than the brute force KNN. However, the KD-tree is a challenge to take advantage of parallel computing and we will discuss it more detail in discussion section. 2.4 Post-Processing Component In this process, the system calculates the number and volume of lesions based on the detected lesion by the KNN algorithm. There are three kinds of volumes in the system, smaller than 1 cm3, between 1 and 5 cm3 and larger than 5 cm3.These volumes are calculated by multiplication the number of voxels which contains lesions by the voxel size from the DICOM-headers. 3. MATERIALS AND MET HOD 3.1 Patient data The MR images used in this paper were collected from the University of Southern California (USC) Healthcare Consultation Center 2 (HCC2) in Los Angeles. The MRI studies were acquired on a Siemens 1.5-T system. The scans were performed with a 3mm slice thickness. Each data set (T1-weighted, T2-weighted and FLAIR) has 50 slices with 0.98mm X 0.98mm resolution. In the experiment we used total 19 studies. One of them is used as training set for KNN classification and the other for target set. 3.2 Hardware and software In this project we used a Lenovo ThinkStation D20 (dual Intel\u00ae Xeon X5560 CPU at 2.8 GHz , 16.0 GB installed memory, Windows 7 64-bit operating system, and a NVIDIA\u00ae Tesla\u00ae C1060(GPU)).The prototype was developed by MATLAB 2009b. The developed algorithm in C/C++ was performed in Visual Studio 2008. For the GPU experiment, the CUDA was used. The CUDA is NVIDIA's parallel compu ting architecture that enables dramatic increases in computing performance by harnessing the power of the GPU (graphics processing unit) [6]. 3.3 Method In this paper, we evaluated three kinds of systems, MS CAD performed with MATLAB, by C/C++ with CPU and CUDA with GPU. For performance evaluations, we measured a running time of each case (18 cases) and obtained the average of elapsed time. First, the elapsed time in MS CAD system with MATLAB was approximately 3 hours for the whole processes. The searching lesion process took the bulk of the measured time. So we designed the experiment as shown in Figure 2. Each system has the same Pre -Processing' and Po st-Processing' part, but different Searching lesion' part. The different searching process means different implementation of the same algorithm. 63 Figure 2.Method of evaluations for systems. 4. RESULT AND DISCUSSION 4.1 Result System MATLAB C/C++ with CPU CUDA with GPU Average Time Approximately 3 hours 26.98 minutes N/A Table 1.The result of performance evaluation As shown in Table 1, the measured times of each system are around 3 hours in the MATLAB and 26.98 minutes in C/C++. The conversion from MATLAB to C/C++ decreases the running time of MS CAD system by almost 75 %. However, we could not evaluate the performance of the system with the GPU because it was unable to apply the parallel computing technology into the developed algorithm. The issue is discussed in more detail in the discussion section. 644.2 Discussion We obtained the result in the system with C/C++ as we expected. However when we began to implement the developed algorithm for GPU, we found that it is impossible to apply parallel technology into the existing algorithm because of the usage of KD-tree. As mentioned above, we use the KNN-based algorithm and KD-tree to reduce the amount of computations in KNN search. KNN algorithm is to find K (the number of points) of points which are similar or close to the target point. If the search of the nearest point is performed to every point in the target set, the amount of computation would be huge. The KD-tree structure is to then implemented to reduce computations by repeatedly split the training set into subsets. The algorithm then calculates the difference between the target point and the point from the subset which the KD-tree provides. After the first computing of KNN, the KD-tree compares one value of the target point to the median value of a subset. The next subset is then determined by this comparison. Here lies the inherent complication that makes it unable to apply the parallel computing into the developed algorithm. In the parallel computation, the several calculations are performed simultaneously. However, the developed algorithm relies in results from previous calculation to perform the next set of computations. In order to overcome this issue, a change of KNN search methodology is needed to implement MS CAD algorithm in a parallel computing environment. 5. CONCLUSION We performed the evaluation of three systems in this paper. The system implemented in C/C++ with CPU works well, but the system with GPU does not because of KD-tree. The average of measured times of the system with C/C++ was around 27 minutes. This time is suitable for medical environment because the diagnosis of multiple sclerosis does not require an emergency read. From this research, we found that the application of parallel computing into the developed algorithm is impossible without modification of the algorithm. 6. FUTURE WORK The system we developed is to help radiologists to diagnose the multiple sclerosis. This system should be fitted well to medical environment in order for it to be clinically useful. Future work should be the integration of the system into PACS. For this integration, the Pre -processing' and Post -processing' component should be modified and connected to PACS. Other future work is to apply a new computing method, cloud computing. From this experiment, we found limitation of parallel computation and its application to specific types of image processing algorithms. In addition, the system could be integrated into PACS which could include the application of cloud computing into the system to improve its performance. REFERENCES [13] Alonso A. and Hernn. M.A. Temporal trends in the incidence of multiple sclerosis: a systematic review. Neurology, 71(2): 129-135 (2008). and Wieslaw L. Nowinski. A rapid algorithm for robust and automatic extraction of the midsagittal plane of the human cerebrum from neuroimages based on local symmetry and outlier removal. NeuroImage, 20(4): 2153-2165, Dec 2003. [15] Zu Y. Shan, Guang H. Yue and Jing Z. Liu. Automated histogram -based brain segmentation in T1-weighted three-dimenstional magnetic resonance and Jeroen van der Grond. Probabilistic matter lesions in MR imaging NeuroImage, 21(3): 1037 -1044, Mar 2004 [17] Andrew W. Moore. An Introductory tutorial on kd -trees PhD thesis, Carnegie Mellon University, 1991 [18] http://www.nvidia.com/object/what_is_cuda_new.html Sharing M. Leahya aSignal and Image Processing Institute, University of Southern California, Los Angeles, CA, USA bMassachusetts Institute of Technology, Cambridge, MA, USA cEpilepsy Center, Cleveland Clinic Foundation, Cleveland, Ohio, USA dMartinos Center for Biomedical Imaging, Massachusetts General Hospital, Charlestown, MA, USA eImage Processing and Informatics Lab, University of Southern California, Los Angeles, CA, USA ABSTRACT Cortical activation maps estimated from MEG data fall prey to variability across subjects, trials, runs and potentially MEG centers. To combine MEG results across sites, we must demonstrate that inter-site variability in activation maps is not considerably higher than other sources of variability. By demonstrating relatively low inter-site variability with respect to inter-run variability, we establish a statistical foundation for sharing MEG data across sites for more powerful group studies or clinical trials of pathology. In this work, we analyze whether pooling MEG data across sites is more variable than aggregating MEG data across runs when estimating significant cortical activity. We use data from left median nerve stimulation experiments on four subjects at each of three sites on two runs, occurring on consecutive days for each site. We estimate cortical current densities via minimum-norm imaging. Then, we compare maps across machines and across runs using two metrics: the Simpson coefficient, which admits equality if one map is equal in location to the other, and the Dice coefficient, which admits equality if one map is equal in location and size to the other. We find that sharing MEG data across sites does not noticeably affect group localization accuracy unless one set of data has abnormally low signal power. Keywords: Magnetoencephalography, Data Pooling, Multicenter, Minimum Norm 1. INTRODUCTION Magnetoencephalography1 (MEG) group studies rely on data from many subjects;however, clinics with MEG equipment may not have a sufficient number of subjects2. To work around this limitation when studying pathological conditions, clinicians can pool data recorded at multiple sites. We show that such aggregation of MEG data across centers does not increase localization error. Specifically, we show that the concordance in significant activity between two sites is statistically equal to the concordance in significant activity between two runs at the same site. Thus, we will be ableto create a data model that is conducive to large subject studies recorded atmultiple MEG centers. Analysis of inter-site variability in biomedical imaging includes MRI and PET as well as MEG. For PET, calibration immensely affects multicenter consistency3. For anatomical MRI, phantom scans showed low inter-site variability4 but patient scans showed incongruent segmentation5 that needed correction6. For MEG, preliminary analysis showed low inter-site variation in localization of activity7. In addition, variation in amplitude and time of peak activity is mainly due to subject variability, not site variability8. We expand upon this previous work on MEG data by testing whether regions of significant activity, estimated from real data by minimum-norm estimation, show only as much variation between machines as those regions do between runs at one machine. We use median nerve stimulation recordings with focal regions of activity9at the primary somatosensory cortex (SI). By using real data, we include all possible variations not covered by simulation. By using a real stimulus we emulate multicenter clinical studies. 66We start by finding regions of significant activity estimated from pre-whitened channel data by minimum- norm imaging. Then we define metrics to compare those regions across sites and runs. We apply statistical tests to establish the difference in these metrics inter-site versus inter-run. Our workflow, diagrammed in Figure 2 , will test whether the mean overlap of significant activity across sites is equivalent to the mean overlap in significant activity across runs at one site. 2. MATERIALS AND METHODS 2.1 Experimental Setup Data from ten subjects were recorded7 on three different machines: a 306-channel VectorView system fromElekta- NeuromagOy (Helsinki, Finland) at (Charlestown, MA, a 248-channel Magnes 3600 WH system from 4D Neuroimaging (San Diego, CA, USA) at the University of Minnesota Brain Sciences Center (Minneapolis, MN, USA), and a 275-channel Omega system from VSM MedTech (Coquitlam, B.C., Canada) at The MIND Institute (Albuquerque, NM, USA). Henceforth, we label the data from the VectorView, Magnes, and Ome ga systems with Neuromag, 4D, and CTF, respectively. Presentation software(Neurobehavioral Systems) was used to deliver the triggers to a S88 dual-channel stimulator with PSISU7 optical constant-current stimulus isolation units manufactured by Grass Instruments (West Warwick, RI, USA), which produced the left median nerve stimuli at intervals ranging from 1.5s to 2s. We recorded each subject on two consecutive days at each of the three sites. We removed stimulus artifacts by zeroing a 10ms window around the trigger. We then applied a lowpass filter with cutoff of 100 Hz anddecimated the data to a sampling rate of 500 Hz. Each trial is \u00b1600 ms around each trigger to obtain a set of 150 trials.We were unable to compile data from at least 1 site for each of six subjects, so we have four subjects for group analysis. We acquired anatomical MRI data fromeach subject on a Siemens Avanto 1.5T scanner at Massachusetts General Hospital using a T1-weighted sagittal MPRAGE protocol. From these data, BrainSuite10 extracted the cortex and scalp. The cortical tessellation has vertices where we estimate the neural activity. 2.2 Minimum-Norm Estimates Let be the evoked response11 for a given subject, machine and run, with noise p re-whitened. We compute the forward model G from cortical signals to channel recordings using the overlapping spheres12 method, without constraining direction of activity. We estimate cortical electrical activity using minimum-norm estimation (MNE), which solves at each time sample the optimization problem13: where has dimension 3(# of sources) to include the x-, y- and z-component of each source. For minimum-norm imaging, the estimated sources in each direction are16: Figure 2: Workflow to test for equivalence of MEG data across sites. 67Then, we compute the power of activity at each as ( ) ( ) ( ) We find whether each cortical vertex i is significantly active at time t via statistical mapping17 and permutation testing18. Let and be the source activity pre- and post-stimulus, respectively. To test for significance, we define the null hypothesis and the test statistic: { } ( ) To estimate the distribution for under the null hypothesis, we employ a permutation test19 between the post-stimulus and pre-stimulus intervals. We control for the family-wise error rate across all vertices using the maximum-statistic approach20.The permutation thresholding procedure results in a set of significantly active vertices for channel recordings . To assist in calculation of similarity of two sets of active vertices, we remove small clusters of activity in . 2.4 Sampling Significant Evoked Activity The above analysis results in a single significant map for each combination of subject, machine and run. However, testing for inter-sitevariability requires multiple such maps , . To do this, we bootstrap21 the original data and then repeat the permutation procedure separately for each bootstrap sample. Bootstrapping22 resamples from the trials with replacement to create surrogate evoked responses for bootstraps. Each evoked response is then subjected to the aforementioned permutation test to calculate the significant map .Each bootstrap has an increased pre-stimulus variance21 due to repeated trials. However, with many bootstraps, the set of surrogate evoked responses { } can estimate the mean and variance of . Consequently, the bootstrapped sets of significant voxels { }estimate in approximation a sampling of the distribution of . 2.5 Consistency of Activity We want to compare whether the overlap in activity between two sites X and Y is equivalent to the overlap in activity between X on run one and X on run two. Let be a bootstrapped set of significant activity for site X on run 1; likewise, and . To calculate the overlap between two sets F and G, we employ the Dice23 and Simpson24 coefficients: | | | | | | | | {| | | |} Both coefficients fall in the range [ ]. The Dice coefficient only when , while the Simpson coefficient when or . Let and range within 2ms of the maximum evoked response for data recorded at machine X on runs one and two respectively. We then determine the overlap, for each bootstrap, within runs on the )for all site pairs { }. 2.6Testing for Equivalence We will use the Dice coefficient as an example in this section; the samemethod applies to the Simpson coefficient. 68We test whether ( ), the measure of multicenter consistency, is equivalent to ( ), the measure ofmulti-run consistency. To do this, we set up an equivalence test25. We want the nullhypothesis to be so that we may reject non-equivalence. However, to allow for negligiblevariation in C and R, we set a tolerance so that thestatistical hypotheses are: | | | | The parameter represents the negligible variation in similarity we will allow in group studies. Since we allow multiple runs at one center to be pooled together, we can take to be the average variance { }in the similarity metric between runs at the same site where is the variance in R for one specific subject and site. We test the above hypothesis with a two-sided two-sample z-test.Let and be the sample mean and varianceof C across all bootstraps. Similarly, let and be the sample mean and variance of R. For false positiverate , we accept the alternative hypothesis of | | only if ( ) ( ) where is the cumulative distribution function of a standard normalrandom variable. This test is administered on each pair of machines for everysubject and run. Majority voting26 decides group equivalenceof C, i.e. localization agreement in pooling across machines, and R, i.e.localization agreement in pooling across runs at the same machine. 2.7Implementation We segmented surfaces via BrainSuite10, a magnetic resonance image analysis tool designed for identifying tissue types and surfaces in MR images of the human head. We used BrainStorm27to import the channel recordings and calculate forward models. Bootstrapping and permutation testing were implemented in MATLAB R2009b, as wasequivalence testing. 2.8 Multicenter Data Sharing The next step will be to develop a data model for any MEG center's data to be catalogued. This data model would enable each center to store recordings with the help of metadata input by the user as in Figure 3 . By consistently storing data in the same model at all sites, large studies can easily tap data from multiple sites under a common framework, increasing efficiency in analysis requiring large subject databases. 3. RESULTS 3.1Regions of Significant Activity Figure 4 shows an overlay of maps of significant activity fora given subject between sites and between runs. For each vertex, the valueplotted is the number of bootstraps that consider the vertex active betweenruns at one site (top row) and between sites (bottom row). We used bootstraps. Figure 3: Data flow model for sharing MEG recordings. 69 Figure 4: Cortical map of the number of bootstrap samples that consider avertex active across runs at one site (top row) or across sites (bottom row). The inter-site overlap is smaller than the inter-run overlap, except inonecase. These discrepancies are largely due to the specific noisecharacteristics of each machine. However,the same main cluster of significantly active vertices is seen in almost allbootstraps across all sites and runs for thisparticular subject. 3.2 Distributions of Overlap Figure 5 shows histograms of the inter-site similarity C and the inter-run similarity R when usingboth the Dice coefficient and the Simpson coefficient.These histograms use samples from all subjects and runs to show thenonparametric group distribution of similarity between machines and betweenruns. We see that the distribution between machines is slightly lessbut very close to the distribution between runs. So, inter-site similarityresembles inter-run similarity in distribution. Figure 5: Group distribution of the Dice and Simpson coefficients between sites and between runs at one site. The between -mach ine similarity plots have an axis corrected for having twice as many samples as the within -machine similarity plots. 703.3Equivalence Test Results We employ the equivalence testing of 2.6 over allsubjects and runs. Some pairs have less subjects and runs due to the tainteddata explained in 2.1. Majority voting in Figure 6 indicates that there is group equivalence between inter-site and intra- sitesimilarity coefficients for \"Neuromag\" and \"CTF\" data. Site discordance insimilarity was due to subjects that had low SNR on a certain run. 4. DISCUSSION In this paper, we have shown that inter-site agreement in MEG source estimationis as high as inter-run agreement in MEG source estimation. We started with acommon method for estimating source activity from recorded MEG data:minimum- norm estimation. This technique is widely used to estimate source activity then one cannot assume activity is focal, i.e. a set ofdipoles. With a non-parametric permutation test, we tested for the null hypothesis of no change in activityfrom pre-stimulus topost-stimulus. InFigure 4that most vertices were either active for almost allbootstraps or not active for almost all bootstraps. Thus, bootstrapping, alongwith permutation testing for significance, does not vary the region of significantactivity with respect to the original recordings. The distributions in Figure 5 showthat inter-site consistency is slightly lower than inter-run similarity, due tothe slightly heavier tail. However, the mean and median of the distributionsare nearly the same.Based on this visualinspection, we can pursue equivalence testing between inter-site consistency andinter-run consistency. We note that 4D data for one subject was not very concordant, which contributedto comparisons involving 4D inter- run similarity being lower than normal. Theresult is that while \"Neuromag\" and \"CTF\" data were equivalent in most cases,comparisons involving 4D data suffered from the issues of a single subject. We also note that in some cases, more subject-run pairs showed equivalence inDice than in Simpson coefficient. We find that this is because the Simpsoncoefficient is so inclusive that for most inter-runcomparisons the coefficient is1. However, in inter-site comparisons, differing noise characteristics prevent the Simpson coefficient from attaining maximum Simpson coefficient of one, even though the value is high. However, over most cases we conclude that \"Neuromag\" and \"CTF\" data areinterchangeable, and that \"Neuromag\" data can replace \"4D\" data in a study withoutloss in spatial localization accuracy. We cannot easily conclude that \"CTF\" and \"4D\" data areinterchangeable due to problematic data sets. 5. CONCLUSION We have developed a framework to determine if estimated source signals arepreserved across machines andapplied it to MEG multi-center data. We findthat with minimum-norm imaging and noise whitening, some multicenter dataagrees in localization of activity. We have also seen that for some subjects,flagging of noisy data is necessary to foster inter-site consistency. We willcontinue our work to show whether other inverse imaging methods admitmulticenter pooling of MEG recordings. In addition, we will work towardsa data model for the storage and sharing of recordings at multiple MEG centers. REFERENCES [1] H\u00e4m\u00e4l\u00e4inen, M., J., and O.V., Magnetoencephalography - theory, instrumentation, and applications to noninvasive studies of the working human brain, Rev. Mod. Phys. 65, 413-497 (Apr 1993). [2] Pataraia, E., Deecke, R., and Munz, D.L., Multicenter comparison of calibration and cross calibration of PET scanners, J NuclMed 43(5), 635-639(2002). Figure 6: Fraction of subject -runs that admit equivalence of inter -site similarity coefficient to inter -run similarity coefficient. 71[4] Styner, M., Prastawa, M., Piven, J., Gerig, G., Assessment of reliability of multi -site neuroimaging via traveling phantom study, \"in [ Medical Image Computing and Computer-Assisted Intervention MICCAI2008 ], Metaxas, D., Axel, L., Fichtinger, G., and Szkely, G., eds., Lecture Notes in Computer Science 5242, 263-270, Springer Berlin / Heidelberg (2008). 10.1007/978-3- 540-85990-1_32. [5] Charles, H.C., Park, of image analysis methods: assessing intra- and intersite variability, in [ Society of Photo-optical Instrumentation Engineers (SPIE) Conference Series ], M. Sonka& J.M. Fitzpatrick, ed., Society of Photo-Optical Instrumentation 4684, 278-286 (May 2002). [6] Jovicich, J., Czanner, S., Greve, D., Haley, E., van der Kouwe, A., Gollub, R., Kennedy, D., Schmitt, F ., Brown, G., MacFall, J., Fischl, B., and Dale, A., Reliability in multi -site structural MRI studies: Effects of gradient non- linearity correction on phantom and data, D., Mosher, J., Georgopoulos, A., H\u00e4m\u00e4l\u00e4inen, M., and Aine, C., Paving the way for cross -site pooling of Magnetoencephalography (MEG) data, International Congress Series 1300, 615-618 (2007). New Frontiers in Biomagnetism: Proceedings of the 15th International Conference on Biomagnetism, Vancouver, BC, Canada, August 21-25, 2006. [8] Ou, W., Golland, P., and H\u00e4m\u00e4l\u00e4inen, M., Sources of variability in MEG,\" in [ Proceedings of the 10th international conference on Medical image computing and computer-assisted intervention ], MICCAI'07 , Forss, N., Vanni, S., and Jousm V., Activation of a distributed somatosensory cortical network in the human brain. A dipole modeling study of magnetic fields evoked by median nerve stimulation. Part i: location and activation timing of SEF sources, Electroencephalography and Clinical Neurophysiology/Evoked Potentials Section 104(4), 281-289 (1997). [10] Shattuck, D. and Leahy, R., BrainSuite: An automated cortical surface identification tool, Medical Image Computing and Computer-Assisted Intervention , 50-61 (2000). MICCAI2000, Elbert, T., Tucker, D., and Rocstroh, B., Statistical control of artifacts in dense array EEG/MEG studies, Psychophysiology 37(04), 523-532 (2000). [12] Huang, and Leahy, R.M., A sensor -weighted overlapping-sphere head model and exhaustive head model comparison for MEG , Physics in Medicine and Biology 44(2), 423 (1999). [13] Wang, J.- Z., Williamson, S., and Kaufman, L., Magnetic source images determined by a lead -field analysis: the unique minimum-norm least- squares estimation, Biomedical Engineering, Transactions on 39(7), 665-675 (1992). [14] Lin, F., Belliveau, J., Dale, A., andH\u00e4m\u00e4l\u00e4inen, M., Distributed current estimates using cortical orientation constraints, Human Brain Mapping 27(1), 1-13 parametric mapping: Combining fMRI and MEG for high- resolution imaging of cortical activity, Neuron 26(1), 55-67 (2000). [16] Pantazis, D. and Leahy, R., Statistical inference in MEG distributed source imaging, in [ MEG: An Introduction to Methods ], Hansen, P., Kringlebach, M., and Salmelin, R., eds., 257-284, Oxford University Press (2010). [17] Pantazis, D., Nichols, T., Baillet, S., and Leahy, R., Spatiotemporal localization of significant activation in MEG using permutation tests, in [ Information Processing in Medical Imaging ], Lecture Notes in Computer Science 2732, 512-523, Springer Berlin / Heidelberg (2003). 10.1007/978-3- 540-45087- 0. [18] Pantazis, D., Nichols, T. E., Baillet, S., and Leahy, R., A compa rison of random field theory and permutation methods for the statistical analysis of MEG data, NeuroImage 25(2), S., Benali, H., Mosher, J., Garnero, L., and Leahy, R., Investigations of dipole localization accuracy in MEG using the bootstrap, R.J., [ An Introduction to the Bootstrap ], Chapman & Hall, New York (1993). [21] Dice, L.R., Measures of the amount of ecologic association between species, Ecology 26(3), pp.297- 302(1945). [22] Simpson, G., \\ Mammals and the nature of continents, American Journal of Science 241(1), 1-31 (1943). [23] Wellek, S., [ Testing Statistical Hypotheses of Equivalence ], Chapman & Hall, Boca Raton (2002). [24] Suen, C., Nada l, C., Legault, R., Mai, T., and Lam, L., Computer recognition of unconstrained hand written numerals, Proceedings of the IEEE 80, 1162-1180 (July 1992). [25] Baillet, S., Masher, J., and Leahy, R., Electromagnetic brain imaging using brainstorm, in [Biomedi cal Imaging: Nano to Macro, 2004. IEEE International Symposium on], 652-655 Vol.1 (2004). 72 A Multimedia Electronic Patient Record (ePR) System to Improve Decision Support in Pre- and Rehabilitation through Clinical and Movement Analysis Brent Liua,Jorge Documeta, Sarah McNitt-Graya, Phil Requejob, Jill McNitt-Grayb aDept. of Biomedical Engineering, University Southern California, LA, CA 90089 bDept. of Kinesiology and Biological Sciences, USC, LA, CA 90089 ABSTRACT Clinical decisions for improving motor function in patients both with disability as well as improving an athlete's performance are made through clinical and movement analysis. Currently, this analysis facilitates identifying abnormalities in a patient's motor function for a large amount of neuro-musculoskeletal pathologies. However definitively identifying the underlying cause or long- term consequences of a specific abnormality in the patient's movement pattern is difficult since this requires information from multiple sources and formats across different times and currently relies on the experience and intuition of the expert clinician. In addition, this data must be persistent for longitudinal outcomes studies. Therefore a multimedia ePR system integrating imaging informatics data could have a significant impact on decision support within this clinical workflow. We present the design and architecture of such an ePR system as well as the data types that need integration in order to develop relevant decision support tools. Specifically, we will present two data model examples: 1) A performance improvement project involving volleyball athletes and 2) Wheelchair propulsion evaluation of patients with disabilities. The end result is a new frontier area of imaging informatics research within rehabilitation engineering and biomechanics. Keywords: Rehabilitation Engineering, Human Performance, Multimedia ePR, Imaging Informatics 1. INTRODUCTION With the emergence of PACS as an imaging informatics tool, research work involving decision support and CAD (Computer-aided diagnosis) applications have greatly benefited the Radiology Department by improving workflow and turnaround times [1]. The experiences and skills gained from the development of such decision support systems within Imaging Informatics can be further leveraged in new frontier areas of research that require multimedia data. One such area is where clinical decisions for improving motor function in patients both with disability as well as improving an athlete's performance are made through clini cal and movement analysis. Currently, this analysis facilitates identifying abnormalities in a patient's motor function for a large amount of neuro-musculoskeletal pathologies. However definitively identifying the underlying cause or long-term consequences of a specific abnormality in the patient's movement pattern is difficult since this requires information from multiple sources and formats across different times and currently relies on the experience and intuition of the expert clinician. During a movement evaluation process, kinematics, kinetics, electromyography, and video data are captured simultaneously but stored separately along with demographic and subjective questionnaires. In addition, this data must be persistent for longitudinal outcomes studies. The purpose of this paper is to present the design and architecture of a multimedia ePR system that integrates imaging informatics data and provides a platform for decision support within this new area of research. A medical imaging informatics infrastructure (MIII) has been developed and used widely in many clinical and research applications to utilize PACS images and related data for large scale horizontal and longitudinal clinical service, research and education [1]. The MIII components and their logical relationship are shown in Figure 1. We have extended this methodology in designing and developing such an electronic patient record (ePR) system to 73standardize and centralize multimedia data and properly distribute data during clinical and movement analysis. This paper will focus on designing and developing components within the bottom three layers and outlined in bold. USER'S APPLICATION SOFTWARE Research Clinical Service Education DATABASE & KNOWLEDGE BASE MANAGEMENT DATA MINING & DATA RETRIEVAL Image Processing/ Analysis Visualization Graphic User Interface Security Communication Networks PACS & MEDICAL IMAGE & RELATED DATABASE Figure 1: MIII components and their logical relationship. [1] The concept of the electronic patient record (ePR) is a patient-based digital folder of clinical information obtained from various information sources. The components of an ePR include an information model, a clinical data repository, a web-based application for users, a security model, and built-in decision support. The inclusion of imaging data and built-in decision support makes the ePR stand out amongst general clinical information systems such as Hospital and Radiology Information Systems (HIS and RIS). The imaging data within the ePR data model has opened new doors to the possibility of improvement in clinical decision outcomes of the future. Currently, compared with others in the field, the United States Department of Veterans Affairs Healthcare Enterprise information system, VistA [2], is probably the most advanced enterprise-level ePR integrated with medical images. The multimedia ePR system designed and developed will integrate related imaging and informatics data acquired during this process and manages the data in a patient-based standard similar to current healthcare paradigms. Multimedia data such as patient waveforms, biometric signs, and video are captured and stored via a master clock in synchronized fashion. In addition, force kinematics acquired in post-processing analysis will be integrated as well. Presentation and documentation is provided through a unique timeline-oriented synchronized Graphical User Interface (GUI). The design and development of both the data model and the GUI will be based specifically on two different clinical applications by utilizing data from two separate study trials: 1) A performance improvement project involving volleyball athletes and 2) Wheelchair propulsion evaluation of patients with disabilities. 2.METHODS The design and implementation of the multimedia ePR consists of three main steps: workflow analysis, data analysis and data schema development, and system architecture design. The following sections will discuss each of these steps in great detail. As mentioned previously, the design and development will be based specifically on two different clinical applications utilizing data from study trials: 1) A performance improvement project involving volleyball athletes and 2) Wheelchair propulsion evaluation of patients with disabilities. Although the two project s differ in application, they cover the broad spectrum of pre- and re-habilitation as well as similar methods of data acquisition, processing, and reviewing of data through clinical movement analysis. This would provide a robust ePR system capable of supporting this new area of imaging informatics-related research. 2.1 Workflow Analysis One of the most important first steps for system integration of clinical image and information systems is to research the workflow model of clinical movement analysis. Figure 2 shows the general workflow steps for a movement analysis. The first step in the current workflow assumes that a trial of movement analysis is being captured and all data acquisition devices are set up to acquire data. For example, for the performance improvement project, the trial could be a specific skill movement such as blocking at the net. For the wheelchair propulsion project, the trial could be a specific movement of a wheelchair user climbing an 8% grade ramp. The next step after performing data collection is to perform a manual search for specific data from various standalone systems which can be quite tedious. Once data is searched and retrieved manually, then the data needs to be synchronized. This is performed by either home-grown developed or off-the-shelf software tools. Once data is synchronized, software tools are used to integrate multiple data types (eg, force kinematic data with video) for evaluation. Similar steps are needed to 74integrate data from previous trials for comparison. This is also a manual step for searching previous data. Once the two integrated data sets are complete, the final analysis or review can be made and a decision based on the comparison of previous trial and current trial data is documented in the final results. Data Collection for Single TrialManual Data Search Synchronize Data Files Manually Integrate Multiple Data Types for Analysis Manual Comparison w/ Multiple TrialsSubject /Patient Manual Tracking & Final AnalysisDocumentation of Final Results Manual Data Search for Previous Trials Figure 2: General Workflow Steps for Movement Analysis. Figure 3 shows how the multimedia ePR system can improve the efficiency of the current workflow for movement analysis. All data acquired for a trial is uploaded and stored in an organized manner within the ePR system based on the data schema. The ePR GUI can then be used to search for specific data from the current trial. Additionally, through the use of decision support tools integrated with the GUI, comparisons can be made with data from the previous trials and the documented results can also be stored within the ePR system for future review. The dashed rectangle represents all the workflow steps that can be performed within the multimedia ePR system increasing workflow efficiency and providing a richer data set for movement analysis. Data Collection for Single TrialSearch ePR System for DataAnalyze Data Utilizing ePR GUI Compare Multiple Trials Utilizing ePR GUI Automatic Subject / Patient Tracking & Final AnalysisMulti -media Documentation of Final Results Web -Based Upload Data to ePR System Multi -Media ePR System Figure 3: Movement Analysis Workflow with the Multimedia ePR system. 2.2 Data Object Analysis and the Data Schema Development The next major step for the development of the multimedia ePR is to perform a survey and data object analysis of the acquired data of a trial session. During a movement evaluation process, kinematics, kinetics, electromyography, and video data are captured simultaneously but stored separately along with demographic and subjective questionnaires. Table 1 shows the data types and some corresponding examples. Specifically, this includes but is not limited to: Patient/Subject demographics Biometric waveform da ta Force data and vectors Video clips Post-processed multimedia data Normalized data parameters from tasks 75Data Types Data Type Examples Patient/Subject Text Demographic Data (eg, Height, Weight, Age, etc) Biometric Waveform Data (eg, Electromyography - EMG, Blood Pressure - BP, Heart Rate - HR, etc) Video Clips (eg, High Speed, MPEG, AVI's, etc) Force Data and Vectors Post-processed multi -media data (eg, Force vectors overlaid on video frames) Table 1: Data Types Acquired During a Clinical Movement Analysis Trial Session and Examples. The goal is to utilize the DICOM model of the real world to design the data model for the ePR system. [3] Since the data objects from a clinical movement analysis in pre- and re-habilitation are not an exact fit within the DICOM data model, the data schema was designed to accommodate these new data objects. Figure 4 shows the entity- relationship diagram. The left side shows the patient-centric data model designed for the ePR system. The data acquired during a trial session falls under performance enhancement, which is shown on the right hand side of Figure 4. By maintaining a patient-centric relationship, DICOM -based imaging studies can easily be integrated at the patient level and only enhance the multi-media ePR system. Based on the entity relationship diagram, a data schema was designed and a sample of this data schema is shown in Figure 5. 76Figure 4: Entity Relationship Diagram for the multi-media ePR system. Figure 5: Sample Data Schema Design for the Multi-Media ePR System. 2.3 Multimedia ePR system developed using a PHP (PHP Hyper Preprocessor) framework at the server side. This framework allows the ability of integrating many applications, such as analysis, visualization and comparison tools, to the ePR. Each tool is a plug-in module to the whole system and can be managed using the administration interface. Figure 6 shows the architecture of the ePR. The input data will be sent to the Data Gateway or through a web-based GUI Uploader into the Database. Knowledge can be extracted from the input data to form a Knowledge Base which can be utilized by future decision support tools that can be developed and integrated with the ePR system. The users via the web interface can browse the knowledge and also contribute to it by uploading new cases. Because the system is web-based, users can access the system throughout the healthcare enterprise and related research labs. Figure 6: The System Architecture of the Multimedia ePR System. 3. RESULTS Based on the workflow and data analysis, an initial multimedia ePR prototype system has been developed. The system was further refined by integrating data from two separate applications that cover the spectrum of clinical movement analysis in pre- and re-habilitation trial sessions. 3.1 Volleyball Skill Development Project The first application is the performance improvement in volleyball athletes. The project goal was to monitor quality of practice over time to provide immediate feedback regarding technique and team play for volleyball athletes. Specific tasks that were analyzed include blocking at the net which involves a shift movement and a jumping motion. During one such trial session, data is acquired with various standalone equipment and the data types were described previously in Section 2. The data acquisition process was observed to identify bottlenecks of current workflow and the GUI design was developed accordingly. Figure 7 is a screenshot of the ePR system that shows the result of data integrated into the ePR system in the form of a patient-based worklist of subjects/patients. Figure 8 is a screenshot of the available data from each of the trial sessions of a particular subject/patient. Figure 9 shows a GUI Mock-up how clinical movement analysis can be greatly enhanced through the multimedia ePRsytem with integrated decision support. Complex imaging informatics related data can be displayed side- by-side for a comparison of longitudinal studies on a per-subject basis. In the future the results can be utilized to improve the technique of the subject and further evaluated which would ultimately lead to the prevention of injury to the volleyball athlete. Current status of this application: 78 Design and study of the movement analysis workflow for volleyball skills development has been completed. Data utilized in the project has been identified and a data model was developed. Data acquisition process for one trial session was observed to understand how best to design and develop the GUI and the ePR system. A total of 15 subjects with 130 trials per subject has been integrated with the ePR system. Initial GUI has been designed and developed. Additional decision support tools are currently being developed and mock-up designs have been completed. Figure 7: Patient-Based ePRWorklist Showing Subjects/Patients Figure 8: Screenshot of the GUI View of Trials and Data Available During Data Acquisition of a Subject. 79 Figure 9: GUI Mock-Up Design for Clinical Movement Analysis Showing Automatic Side- by-Side Comparison of Longitudinal Trials per Subject 3.2 Wheelchair Propulsion Project The second application utilized to design the multimedia ePR system is the wheelchair propulsion project. The overall purpose of the wheelchair propulsion project is to identify predictors of onset of shoulder pain in wheelchair patients. Manual wheelchair propulsion is a highly repetitive motion and weight bearing in nature. Should a patient utilize inefficient and incorrect technique, there is potential for fatigue and risk for upper extremity injuries. Therefore, through clinical movement analysis and the data acquired, the goal is to develop biomechanical guidelines for optimum and less stressful shoulder function. [4,5] Large volumes of data collected include wheelchair ergometer and dynamometer for force data, EMG data for muscle activity, and high-speed video clips. Data captured resides in standalone computer systems and needs integration. Once the data is integrated, decision support tools for movement analysis can be developed as a value-add to the ePR system which can provide a powerful tool in this wheelchair propulsion study. Current status of the second application includes: Design and study of movement analysis workflow for manual wheelchair propulsion has been completed. Data utilized in movement analysis for manual wheelchair propulsion has been identified. A data model is currently being developed. Future work includes: Integrating 223 participants with 3 sessions per patient with the ePR system. Initial GUI to be designed and developed for movement analysis. Previous work to develop the first application will be leveraged. Design and develop decision support tools to be integrated with the GUI. 4. SUMMARY The design and development of a robust multimedia ePR system platform for both disability patients and athletes undergoing movement analysis for rehabilitation or performance improvement was presented. Specifically, we presented two data model examples of a performance improvement project involving volleyball athletes and 80wheelchair propulsion evaluation of patients with disabilities. The two examples show similar overlap and design in the data model of the ePR that can accommodate the entire spectrum of multimedia data from rehabilitation engineering to human performance. The result is an ePR platform to develop decision support tools that can impact a new frontier of imaging informatics research. Future work includes integrating the data acquired from the wheelchair propulsion project and developing the data model as well as further development of the GUI and decision support tools to aid in the evaluation and analysis workflow for both clinical applications. REFERENCES [1] Huang HK. PACS and Imaging Informatics: Principles and Applications. John Wiley & Sons, Hoboken, New Jersey (2004). [2] Dayhoff R., and Siegel E., Digital Imaging Within and Among Medical Facilities, in R Kolodner (ed): Computerized Large Integrated Health Networks - The VA Success. New York: Springer Publishing, pp. 473-490. M, Koontz A, Ren D, Dyson-Hudson T, Cooper R. Shoulder Joint Kinetics and Pathology in Manual Wheelchair Users. Clinical Biomechanics, 21 (2006): pp. 781-789. RA, Towers JD, Koontz AM, Souza AL. Shoulder Magnetic Resonance Imaging Abnormalities, Wheelchair Propulsion and Gender. Archives of Physical Medicine and Rehabilitation 84 (2003): pp. 1615-1620. 81DICOM-based computer-aided evaluation of intensity (IMRT) treatment plans Fion W. K. Cheunga,b, Maria Y. Y. Lawb aThe Queen Elizabeth Hospital, Hong Kong, China; bThe Hong Kong Polytechnic University, Hong Kong, China ABSTRACT Intensity -modulated radiation therapy (IMRT) has gained popularity in the treatment of cancers because of its excellent local control with decreased normal tissue complications. Yet, computer planning for the treatment relies heavily on human inspection of resultant radiation dose distribution within the irradiated region of the body. Even for experienced planners, comparison of IMRT plans is definitely cumbersome and not error-free. To solve this problem, a computer-aided decision-support system was built for automatic evaluation of IMRT plans based on the DICOM standard. A DICOM based IMRT plan with DICOM and DICOM-RT objects including CT images, RT Structure Set, RT Dose and RT Plan were retrieved from the Treatment Planning System for programming. Utilizing the MATLAB program language, the decoding-encoding software applications were developed on the basis of the DICOM information object definitions. After tracing the clinical workflow and understanding the needs and expectations from radiation oncologists, a set of routines were written to parse key data items such as isodose curves, region of interests, dose-volume histogram from the DICOM-RT objects. Then graphical user interfaces (GUIs) were created to allow planners to query for parameters such as overdose or underdose areas. A total of 30 IMRT plans were collected in a Department of Clinical Oncology for systematic testing of the DICOM-based decision- support system. Both structural and functional tests were implemented as a major step on the road to software maturity. With promising test results, this decision-support system could represent a major breakthrough in the routine IMRT planning workflow. Keywords: DICOM, knowledge-based, computer-aided, decision- Intensity-modulated radiation therapy (IMRT) Intensity-modulated radiation therapy (IMRT) is the current popular radiation therapy technology that allows the modulation of radiation dose to shape the desired dose to the tumour target volume. With such a plan, it allows the safe delivery of a high dose to the tumours of irregular shapes with maximal sparing of the surrounding structures. 1,2Improved disease control through such dose escalation along with reduction in dose to the neighbouring structures might give IMRT a clear advantage over other technologies in radiation therapy such as three-dimensional conformal radiotherapy (3DCRT). Renowned for its dose-sculpting ability, IMRT has gained increasing popularity for treating concave-shaped targets and other more complicated dose delivery methods. 1.1.1 IMRT planning process IMRT needs a precise 3D representation of the patient anatomy, which requires extensive use of multimodality imaging. IMRT planning includes delineation of tumour targets, organs at risk (OARs). To provide clear guidelines for IMRT planning, well defined site-specific treatment protocols are often set out by radiation oncologists. Encouraging therapeutic outcomes could only be achieved when the exact location and the tumour extension could be accurately defined with respect to all OARs. Manual slice- by-slice delineation is one of the most tedious and time-consuming tasks in IMRT planning. Continuous efforts have been made to develop automatic segmentation algorithm for delineating different structures. 3,4 82IMRT incorporates two novel features, namely, computer-controlled intensity modulation of treatment beams and inverse treatment planning optimization. With this approach, each radiation field is firstly divided into multiple pencil beams enabling custom-design of optimum dose distributions. Inverse planning starts with the required dose distribution and a set of planning parameters. By taking all dose volume constraints imposed on the targets and OARs into account, the desired intensity pattern is achieved through iterative adjustment of individual beamlets by the dose calculation algorithm for IMRT of the Treatment Planning System (TPS). 1.1.2 IMRT plan evaluation Upon completion of dose calculation, each plan should be evaluated carefully using dose volume histograms (DVHs) and planar dose distributions that show the isodose lines. The determination of the best plan requires a clinical decision based on the balance between adequate target coverage and normal tissue sparing. Dose to critical structures should not exceed their tolerable limits or constraints that are set in the protocols. A resultant IMRT plan that cannot meet the plan acceptance criteria in the protocols is judged to be unqualified. Despite lacking spatial information, DVHs provide a global view of whether the resultant plan meets the set limits. On top of that, a detailed slice- by-slice analysis of isodose distribution is crucial in examining target coverage and identifying the exact location of hot and cold spots. Owing to unconventional nature of IMRT dose distribution, special caution should be paid to the unconstrained normal tissues which may receive unexpected high doses. If the IMRT plan is regarded as unacceptable, either the dose volume constraints or priorities can be adjusted reiterately to re-optimize the intensity distribution. As shown in figure 1, each IMRT plan has two primary concerns -target coverage and normal tissue sparing. A key goal of IMRT is to minimize complications to normal tissues by decreasing the dose to OARs while maximize tumor control by increasing the dose to planning target volume (PTV). The development of a clinically acceptable plan usually takes several iterations of refinement depending on complexity of the case and experience of the planner. To obtain a better plan, the optimization and evaluation loop can continue until no further improvement is required. Figure 1. IMRT plan has two primary concerns - target coverage and normal tissue sparing. With the aim of better planning target volume (PTV) coverage and greater organs at risk (OARs) sparing, an IMRT plan continues to refine through a series of optimization iterations. 1.1.3 Major challenges and pitfalls Currently available IMRT planning systems rely heavily on human inspection of resultant dose distribution. When judging the plan quality, the need to interpret such meticulous statistics has prompted the development of intelligent tool for automated dose-volume data analysis. Even for experienced planners, identification of hot and cold spots from pertinent CT slices is definitely cumbersome and not error-free. 2. PURPOSE To save planners from tedious manual evaluation, a computer-aided decision-support system was built for automatic evaluation of IMRT plans based on the DICOM standard. The system aimed at improving the planners' efficiency and accuracy in evaluating an IMRT plan that met all dose volume constraints and identifying underdose and overdose regions on each CT slice. 833. METHODOLOGY The development of the DICOM-based decision-support system consisted of 3 stages: 1. Programme development, 2.Design of Graphic User Interface (GUI), 3. System testing. 3.1 Programme development Detailed workflow analysis and modeling could provide a roadmap to successful programme development. Workflow models are valuable in understanding current operational process, identifying system requirements, visualizing the benefits after system implementation and defining the desired future situation. Figure 2 shows a comparison of conventional and computer-aided IMRT plan evaluation processes. The example of dosimetric evaluation of the right lens of the eye in IMRT for nasopharyngeal carcinoma (NPC) is used. Figure 2.Comparison of conventional and computer-aided methods for evaluation of IMRT treatment plan. Based on institutional practice and philosophy, diverse plan acceptance criteria could be put into practice. Clear goals for individual IMRT treatment plan should be defined at the outset. Association between the lens dose and radiation-induced cataract was well documented. From the literature, it was reported that the lens tolerance dose was 6 Gy. 1,2,5 Conventional IMRT plan evaluation process required human inspection of violation of treatment protocols. As an initial step, the DVH statistics for the right lens was extracted for evaluation. If the results were unsatisfactory, it was necessary to visually inspect the isodose distributions on every single slice. In order to examine the anatomic location and extent of overdose, the right lens contours and 6 Gyisodose line were chosen for display. The decision support system software was developed using MATLAB (The MathWorks, Inc., Natick, MA, USA) to facilitate evaluation of the plan data based on DVH and slice by slice analysis. To streamline the workflow, the two approaches were combined into one process in the programming. The 2D DVH curve of a given structure was automatically linked to specific CT image slice overlaid with user-defined isodose line and contour of region of interest (ROI). In the main loop of the program, the following tasks were performed: 841. Loading an IMRT plan including planning CT images and pertinent DICOM-RT objects into MATLAB workspace 2. Input of dose-volume criteria as the plan acceptance guide (Figure 3). Each specific set of parameters can be saved as a template for future use. 3. Using the DVH data of the plan to check if the plan met the acceptance criteria, e.g. the lens should not receive more than 6 Gy radiation dose level 4. Displaying evaluation details and checking for violations of criteria 5. If violations detected, the CT slices containing the violations would be searched by the programme without user interactions. The dose level would be constructed and overlaid on corresponding CT images. Figure 3. User-defined dose -volume criteria for right lens. 3.1.1 Hierarchical bottom-up searching design Each patient being treated with IMRT must undergo a planning CT scan of the area of interest consisting of more than 100 slices. To allow efficient query processing over the massive image database, a hierarchical four-layered bottom-up approach was implemented. By breaking the ultimate goal down into more detailed sub goals, the algorithm ran in an upward direction towards the top of pyramid. The starting point for constructing a hierarchy was a comprehensive list of the tasks that make up a job. After identifying hierarchical relationship amongst the tasks, sequential instructions were executed in a bottom-up manner. As shown in the figure 4, the searching of CT images subject to violation was decomposed into four subtasks. The hierarchical analysis started with the complete set of CT images by examining the presence of structure contours. With reference to the ROIContourSequence in RT Structure Set (in the DICOM standard), images containing OARs and PTVs were categorized as CT images with OARs or CT images with PTVs respectively. Pruning technique was then employed to progressively narrow down the search. Depending on whether OAR overdose or PTV underdose was present, a specific subset of images were evaluated and searched for pertinent CT slices subject to violations. This hierarchical structure aimed at quick access to query results and easy navigation of detailed information. Figure 4.A bottom-up searching approaching indicating the hierarchical relationship amongst the tasks. 85 3.1.2 Algorithm for detection of protocol violation At the first stage of violation detection, DVHs were useful in summarizing dose distribution data in a linear graph model to allow rapid screening of treatment plans. Each ROI was uniquely defined by ROISequence in RT Structure Set with a ROI number as shown in Table 1. In this example, the ROI number for the right lens was 35. By cross- referencing this number with DVHReferenceROISequence_Item1 in RT Dose object, the corresponding item number for the right lens was found to be 26. Based on this item number, DVH of the right lens was reconstructed by extracting data from RT DVH module in RT Dose object. Table 1.Illustrating how to find the relevant item number for each region of interest (ROI). To generate the DVH for a structure, the defined volume of ROI was partitioned into voxels. Dose for each voxel was then calculated and accumulated in the appropriate dose bin of the histogram. The ordinate for each point on the cumulative DVH curve represented the total volume of ROI that receives at least the given dose indicated on the abscissa. Assuming maximum lens dose was constrained at 6 Gy, figure 5 demonstrated how to directly read off the corresponding value represented by DVH. Figure 5. Cumulative DVH curves for the right lens of two plans. The solid line corresponds to a qualified plan while dashed line corresponds to an unacceptable plan. The plan represented by the solid line satisfied the constraint with maximum dose just below 6 Gy. Conversely, another plan represented by the dashed line resulted in unacceptable dose distribution. The maximum dose was 10 Gy, violating the planning goal. If any of the constraints were not met, detailed slice-based evaluation of isodose coverage was required. The CT slice revealed that a sizable fraction of the right lens received dose exceeding the specified limit, a situation that warranted a modification of treatment plan due to unnecessary sacrifice of vision (Figure 6). 86 Figure 6. CT scan images showing the right lens contour and 6-Gy isodose line. As well as OAR sparing, PTV coverage was also used as a criterion to evaluate. The ideal cumulative DVH for a target volume should appear as a horizontal line at 100% volume on ordinate with a vertical drop at the prescribed dose on the abscissa. In clinical reality, PTV volume coverage of at least 95% was generally required. The adequacy of target coverage could be evaluated by the shape of DVH. As illustrated in figure 7, plan represented by the solid line achieved acceptable target coverage with 95% volume of the PTV70 receiving at least 70 Gy. On the contrary, another plan represented by dashed line failed to meet the minimum requirement. Only 92% volume of the PTV70 was adequately covered as prescribed. To have a clear understanding of spatial locations of the undesirable hot and cold spots in PTV70, it was still necessary to review the isodose distribution. Figure 7. Cumulative DVH curves for the PTV70 of two plans. The solid line corresponds to a qualified plan with acceptable target coverage while dashed line corresponds to an unacceptable plan. 87 3.1.3 Overdose and underdose regions extraction Once the 3D dose distribution of an IMRT plan was calculated and ready for evaluation, the corresponding RT Structure Set, RT Dose objects together with a series of planning CT images were exported from the TPS and loaded into the computer-aided evaluation system (Figure 8). With the aim of improving tumor control while decreasing normal tissue complications, either underdosing (cold spot) within tumor or overdosing (hot spot) was undesirable. The quality of each treatment plan was critically evaluated before being implemented. With respect to specific dose volume criteria, the DVH statistics for each ROI should be evaluated separately. In order to examine the anatomic location and extent of hot and cold spots, the CT slices containing violations were searched by the programme and displayed. Dose Images Structures: OARs/PTV Treatment Planning System DVH Data Violation? ENDNo Yes Region detection Eye ball Tumor Image display Figure 8. Region extraction model was designed around the concepts of DICOM and DICOM RT objects, including planning CT images, RT structure set and RT dose. Extraction of both overdose and underdose regions was based on the edge-based approach. First of all, the boundary of the specified isodose line and ROI contour were plotted respectively. To reconstruct the outline of a structure, the evaluation system made use of the contour data stored in the RT Structure Set object. With the same frame of reference, each ROI was associated with reference to CT images. Proper ROI contour coordinate transformation including scaling and translation was necessary. Since dose values were described as pixel data elements, grid doses in specified dose units were constructed by multiplying each pixel value stored in the Image pixel module with the Dose Grid Scaling attribute (3004,000E) in the RT Dose module of the RT Dose IOD. The voxel coordinates of RT Dose matrix with reference to CT images were found in the patient coordinate system as defined in CT scans. The goal of IMRT was to deliver a dose distribution as homogeneous as possible within the PTV while sparing nearby OARs. Either overdose or underdose within targets should be penalized, whereas OARs only carried overdose penalties. 88Concerning cold spots inside targets, the non-overlapping boundaries between the target contour and the prescribed isodose line were detected. On the contrary, the overdose regions were found by searching the overlapping boundaries between the defined structure and specified isodose line. The areas of both hot and cold spots on each CT slice were computed by counting the total number of pixel inside these regions respectively. 3.2 Design of GUI and system testing Upon completion of establishment of the computer-aided software, user-centered GUI panels were designed based on the workflow of treatment planning in a radiation oncology department. MATLAB with a powerful GUI Development tool called GUIDE was adopted for quick and easy development of the user interface windows. System development was an iterative process involving task analysis, design and testing. For testing of the system, a total of 30 IMRT plans were collected and anonymized. Using DICOM export in the Varian Eclipse treatment planning system (TPS) (Varian Medical System, Palo Alto, CA), the DICOM-based plans were then imported to the system using the GUIs. Both structural (clear box) testing and functional (black box) testing were performed to assess the system performance. Structural testing required detailed information about the structure of the system and subjected the individual elements of the system to independent examination. On the contrary, functional testing was concerned only with the inputs and outputs of the system, focusing on functionality against specification. 4. RESULTS The DICOM-based computer-aided decision-support system for automatic evaluation of IMRT plans was successfully developed. To illustrate the functionality of the computer-aided evaluation system, a sample IMRT plan for head-and-neck case was reviewed. An IMRT plan was evaluated based on its ability to meet the user-defined dose volume criteria. Considering a wide variety of treatment protocols available for adoption, a GUI panel allowing the creation of individual template was designed with flexibility in mind. Figure 9 is a screen capture showing how to set the plan acceptance criteria. To kick off the plan evaluation process, the user selected an anonymized patient folder. A series of planning CT images together with the corresponding DICOM-RT objects, namely the RT Plan, RT Structure Set and RT Dose objects were automatically loaded. The evaluation system provided two approaches to specify the dose volume criteria, allowing users to select an existing template or define a new set of parameters. If desired, all input fields can be saved for future use. 89Figure 9.Screenshot of input data panel setting up all acceptance criteria for targets and OARs. The panel contains five buttons which initiate separate functions of the programme. Clicking on the first button will start loading of a particular IMRT plan into the system. The second button on the panel will open the existing template of dose volume criteria while the third panel button will save the inputs as template. The plan evaluation process will be proceeded by clicking on the fourth button. The rightmost panel button with cross sign will trigger a request to close the frame. Through comparison with the user-defined constraints on a point- by-point basis, ROIs which failed to meet the acceptance criteria were listed. By selecting a specific ROI, the related DVH curve along with other useful indicators such as maximum, mean, minimum doses and standard deviation were calculated and displayed (Figure 9). The drop-down menu allowed the user to view a specific CT slice with overdose or underdose regions highlighted. The direct relationships between the DVH curve to the diagnostic CT images and the corresponding dose and structure contours were visualized. Figure 10.Screenshot of treatment plan evaluation page. By choosing a particular z position from a drop-down menu, the user can quickly assess for the hot and cold spots. As an example, the DVH curve for brainstem and one DICOM isodose line and brainstem contour overlaid are displayed. Only the image slices with brainstem receiving dose greater than 54 Gy are extracted and listed for review. Both structural testing and functional testing were implemented to assess the system performance. The computer- aided evaluation system allowed better appreciation of resultant plans. With prompt problem detection and correction features, the direct relationship between the DVH data to the corresponding CT images and RT dose data could be displayed simultaneously. Designated dose levels along with relevant contours and CT images were shown in a precise and efficient manner. Automation of plan evaluation process could maximize productivity and perfect the plan quality, further accelerating the adoption of IMRT in routine clinical practice. The system performance was satisfactory in terms of robustness, precision and reproducibility. 90 5. CONCLUSION With such promising evaluation results, this DICOM-based decision-support system is a major breakthrough in the routine IMRT planning workflow by eliminating all tedious manual evaluation steps. The system could be applied to treatment of different regions of the body and the concept could also be adopted in the evaluation of plans other than IMRT. REFERENCES [1] Tham, I. W. K., Lin, S., Pan, J., Han, L., Lu, J. J. and Wee, J., Intensity -modulated radiation therapy without concurrent chemotherapy for stage IIb nasopharyngeal cancer, Am J ClinOncol 33(3), 294 -299 (2010). [2] Wong, F. C. S., Ng, A. W. Y., Lee, V. H. F., Lui, C. M. M., Yuen, K. K., Sze, W. K., Leung, T. W. and Tung, S. Y. Whole -field simultaneous integrated-boost intensity-modulated radiotherapy for patients with nasopharyngeal J RadiatOncolBiolPhys 76(1), 138 -145 (2010). [3] Tsuji, S. Y., Hwang, A., Weinberg, V., Yom, S. S., Quivey, J. M and Xia, P. Dosimetric evaluation of automatic segmentation for adaptive IMRT for head-and- neck cancer Int J RadiatOncolBiolPhys 77(3), 707 -714 (2010). [4] Stapleford, L. J., Lawson, J. D., Perkins, C., Edelman, S., Davis , L., McDonald, M. W., Waller, A., Schreibmann, E. and Fox, T. Evaluation of automatic atlas -based lymph node segmentation for head-and-neck cancer Int J RadiatOncolBiolPhys 77(3), 959 -966 (2010). [5] Chau, R. M. C., Leung, S. F., Kam, M. K. M., Cheung, K. Y., Kwan, W. H., Yu, K. H., Chiu, K. W., Cheung, M L M and Chan , A. T. C. A broadly adaptive array of dose -constraint templates for planning of intensity-modulated radiation therapy for advanced T-stage nasopharyngea l carcinoma Int J RadiatOncolBiolPhys 74(1), 21 -28 (2009). 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 SELECTED PEER REVIEWED REPRINTS 112Int J CARS DOI 10.1007/s11548-010-0522-8 ORIGINAL ARTICLE Grid-based implementation of XDS-I as part of image-enabled EHR for regional healthcare in Shanghai Jianguo Zhang \u00b7Kai Zhang \u00b7Yuanyuan Yang \u00b7 Jianyong Sun \u00b7Tonghui Ling \u00b7Guangrong Wang \u00b7 Yun Ling \u00b7Derong Peng Received: 8 January 2010 / Accepted: 14 July 2010 \u00a9 CARS 2010 Abstract Purpose Due to the rapid growth of Shanghai city to 20 million residents, the balance between healthcare sup-ply and demand has become an important issue. The localgovernment hopes to ameliorate this problem by develop- ing an image-enabled electronic healthcare record (EHR) sharing mechanism between certain hospitals. This systemis designed to enable healthcare collaboration and reducehealthcare costs by allowing review of prior examination data obtained at other hospitals. Here, we present a design method and implementation solution of image-enabled EHRs(i-EHRs) and describe the implementation of i-EHRs in four hospitals and one regional healthcare information center, as well as their preliminary operating results.Methods We designed the i-EHRs with service-oriented architecture (SOA) and combined the grid-based image man-agement and distribution capability, which are compliantwith IHE XDS-I integration prole. There are seven majorcomponents and common services included in the i-EHRs. In order to achieve quick response for image retrieving in low- bandwidth network environments, we use a JPEG2000 inter-active protocol and progressive display technique to transmit images from a Grid Agent as Imaging Source Actor to the PACS workstation as Imaging Consumer Actor.Results The rst phase of pilot testing of our image-enabled EHR was implemented in the Zhabei district of Shanghai forimaging document sharing and collaborative diagnostic pur-poses. The pilot testing began in October 2009; there have J. Zhang (B)\u00b7K. Zhang \u00b7Y. Ya n g \u00b7J. Sun \u00b7T. Ling Laboratory for Medical Imaging Informatics, Shanghai Institute of Technical Physics, Shanghai, Chinae-mail: jgzhang62@yahoo.com G. Wang \u00b7Y. L i n g \u00b7D. Peng Healthcare Information Center of Zabei District, Shanghai, Chinabeen more than 50 examinations daily transferred between the City North Hospital and the three community hospitals for collaborative diagnosis. The feedback from users at all hospitals is very positive, with respondents stating the sys-tem to be easy to use and reporting no interference with their normal radiology diagnostic operation. Conclusions The i-EHR system can provide event-driven automatic image delivery for collaborative imaging diagnosisacross multiple hospitals based on work flow requirements. This project demonstrated that the grid-based implemen- tation of IHE XDS-I for image-enabled EHR could scaleeffectively to serve a regional healthcare solution with collaborative imaging services. The feedback from users of community hospitals and large hospital is very positive. Keywords IHE XDS-I prole \u00b7Image-enabled electronic healthcare record \u00b7Grid-based image management \u00b7 Picture archiving and communication system Abbreviations ASP Application service provider CDA R2 Clinical document architecture, release 2 caBIG Cancer Biomedical Informatics GridDICOM Digital imaging communication in medicine ebXML eXtensible markup language used for electronic business EHR Electronic Healthcare recordEHRs Electronic Healthcare record solutionEMR Electronic medical record GID Global identier Grid_FTP File Transfer protocol used in grid computing GUI Graphical user interface GW Gateway HL7 Health Level Seven 123 113Int J CARS ICD Intelligent content delivery i-EHRs Image-enabled EHRs IHE The Integrating Healthcare Enterprise ITI Information technology infrastructureJPIP JPEG 2000 interactive protocol KOS Key Object Selection MSG MessageNCI Network communication interfaces NPfIT National Program for IT OID Object identierPHI Protected Health InformationPIX Patient Identier Cross-Referencing PACS Picture Archiving and Communication System RIS Radiological information systemSAAS Software as a service SAN Storage Area Network SOA Service-oriented architectureUID Unique identier VPN Virtual to DICOM objectWS WorkstationXACML Cross-Enterprise Document SharingXDS-I Cross-Enterprise Document Sharing for Imaging Introduction A fundamental requirement for achieving continuity of care is the seamless sharing of clinical information from mul-tiple locations. The electronic healthcare record (EHR) is urgently required in order to provide an information exchange platform for regionally coordinated healthcareservices. One key integration problem in the implementa- tion of EHRs for continuity of patient care is identica- tion of a proper method for sharing and exchange of patientrecords among various hospitals and healthcare providers. To solve this integration problem, several different technologi- cal approaches have been developed to enable the sharing ofhealth records. Images, diagnostic reports, and evidence documents derived from the processing of images represent importantcomponents of a patient's medical record. However, they aremanaged and archived on a variety of imaging information systems, such as RIS and PACS, depending upon the institu- tion. Many healthcare delivery professionals (e.g., referringphysicians, radiologists, surgeons, and oncologists) would benet from a coordinated method for locating and accessing relevant imaging information. The creation and subsequentusage of these documents might span several care deliveryorganizations and may be performed separately over differ-ent time periods. The EHR is a secure, real-time, point-of-care, patient- centric information resource for healthcare providers. Manycountries and regional districts have set long-term goals tobuild EHRs, and most EHRs are built based on the integrationof different information systems with different information models and platforms. To solve the problem of integration across different platforms, the Integrating Healthcare Enter-prise (IHE) [1] has dened an integration prole termed IHE Cross-Enterprise Document Sharing (XDS) [2] to regu- late medical records publication, query, and retrieval amongdocument sources and consumers. The XDS for Imaging (XDS-I) Prole extends and supportimaging \"documents\", specifically including sets of DICOM instances (including images, evidence documents, and pre- sentation states) and diagnostic imaging reports provided ina ready-for-display format. Some programs have been devel- oped to enable image document sharing among regional hos- pitals, for example the National Program for IT (NPfIT) inUnited Kingdom [4] and the Health Infoway project in Can- ada [ 5]. Additionally, a number of hospitals in Shanghai are piloting the development of an EHR solution with a service-oriented architecture (SOA). The rst phase of theproject targets the diagnostic imaging domain and allows seamless sharing of images and reports across multiple hos- pitals. In this paper, we present a design method and imple- mentation solution for image-enabled EHRs XDS-I integration prole com-bined with a grid concept [ 6], which integrates a network of geographically distributed systems or resources togetherto tackle a single, compute-intensive task\u2014in essence a\"virtual supercomputer\". There are many implementationinstances of grid concept in computer science such as Globus [ 7], GLite [8], and UNICORE [9]. Actually, the grid is middleware concept in distributed computing, and there are many advantages of using grid concept to develop dis- tributed system, some vendors related to medical imaging management business use grid concept to develop enter-prise-wide distributed image management products [ 10]. Also, some medical imaging researches use computing gridtool kits as foundation to develop their application sys-tems such as NCI (National Cancer Institute) caBIG (Can-cer Biomedical Informatics Grid) project using Globus as its biomedical imaging and informatics sharing infra- structure [ 11]. We use grid concept to develop image- enabled EHRs and make it as middleware between the local PACS/RIS and remote PACS/RIS systems and enable it to provide a single point of image/report communication ser-vices to local user systems when it communicates with other 123 114Int J CARS remote distributed imaging management systems such as PACS/RIS. In the following sections, we rst briefly introduce the services models of healthcare systems in Shanghai and basicrequirements for the building of EHRs. Secondly, we presentthe design architecture of the image-enabled EHRs and itsmajor components. Third, we report on the implementation of i-EHRs in four hospitals and one regional healthcare infor- mation center, as well as their preliminary operating results.Finally, we discuss the technical approach of our solution with those of other countries in implementing the regional healthcare sharing systems. Current situation of healthcare infrastructure in Shanghai Shanghai is a large city of approximately 20 million residents. There are about 500 hospitals and clinics dis- tributed in 19 districts, providing healthcare services. All hospitals in China are ranked into three grade levels accord-ing to bed count, healthcare resource, and service quality:level 3, more than 800 beds (7%); level 2, 200-800 beds (13.3%); and level 1, less than 200 beds (79%). Usually, the service quality and medical expert resources of largehospitals are better than that of smaller hospitals. With the rapid growth of Shanghai, balancing healthcare supply and demand has become a serious issue, since more and moreresidents live in outskirts of downtown area while most large hospitals are located in city center areas. Addition- ally, most patients still prefer to attend large hospitals tosee doctors when they are sick, despite the higher cost. Thisresults in overloading of large hospitals and a relative insuf- cient number of patients for smaller hospitals, whose ser- vice quality is not recognized even though they are equippedwith high-quality imaging modalities. The local government wants to solve the problems by encouraging patients to attend small hospitals for initial evaluation and receipt of a pre-liminary diagnosis, such as having imaging examination; subsequently, senior radiologists working in large hospitals would make the nal imaging diagnosis through a regionalhealthcare information exchange platform. Patients can thenbe transferred to large institutions if needed. The govern- ment also wants to develop an image-enabled EHR sharing mechanism between some of the hospitals to reduce med-ical costs by re-use of previous patient examination data obtained in other hospitals. The central and local city gov- ernments have funded some projects to solve key technicalproblems and test the work and data flow. In the following sections, we report some of our preliminary results of an image-enabled EHR project for collaborative healthcare inShanghai.Architecture design and major componentsof image-enabled EHRs To develop i-EHRs for regional coordinated healthcare, some factors should be considered in designing the architecture.First, the design should adopt the IHE XDS-I integrationprole [3] as a technical guide in building image and report sharing mechanism between hospital PACS and RIS. Sec- ondly, it can not only integrate with hospitals that have PACSand RIS, but could also include those that use different dig- ital imaging modalities and RIS. Thirdly, in order to over- come limited bandwidth problem and achieve quick responseon image retrieval and display, the JPEG 2000-based stream data transferring and progressive display technologies are used in i-EHRs. Fourthly, the security issue should considerincluding access controlling, medical data authenticity, andintegrity as well as auditing [12]. The SOA-based design method, which loosely couples the distributed components of the enterprise systems via Web Services, will be adopted tomake it more scalable to cross-enterprise application. Mean- while, the grid concept should be introduced into the i-EHRs and enable pre-fetch and peer-to-peer collaboration amongdifferent hospitals to provide collaborative imaging diagno- sis efciently and make the whole integrated system a vir- tual single super enterprise PACS and RIS to the end users,resulting in system administration that is user friendly [ 13]. Figure 1diagrams the architecture of i-EHRs. In Fig. 1, we see the designed solution is the SOA with grid-based image management. It is compliant with the IHEXDS-I integration prole. There are eight major components and common services: (1) XDS Registry, which functions as document Registry Actor dened in IHE XDS/XDS-I integration prolesand uses ebXML (eXtensible markup language used for electronic business) registry model to store andmanage metadata of submitted image/report docu- ments. (2) Grid Manager, which functions to manage the data flow of images between the Grid Agent nodes such as pre-fetching, data backup from hospitals PACSs to regional data center, and tracking the image/message data flows. (3) Security Module, which provide the image/report doc- ument access control, medical data authenticity and integrity, and auditing. (4) XDS Repository, functioning as the document Reposi- tory actor dened in IHE XDS/XDS-I proles, storesand manages submitted image/report documents for retrieving. (5) PIX (Patient Identier Cross-Referencing) Manager, which is dened as the PIX Manager actor in the IHEXDS/XDS-I proles, stores the cross-enterprise patientreference information. 123 115Int J CARS Fig. 1 Architecture of image-enabled electronic healthcare record solution (i-EHRs) (6) Grid Agent is used to convert the reports to CDA (R2)- based documents and create image manifest or DICOM KOS (Key Object Selection) object to submit to XDSRepository and register in Registry, and to integrate the multiple hospital PACS and RIS servers into the i-EHRs as a virtual single PACS/RIS; Grid Agent also workswith Repository as a middleware between the Regis- try and end-points such as XDS-I Imaging Document Sources and Consumers actors [3]. In Grid Agent,there are two sub-modules: XDS-I Imaging DocumentSource and XDS-I Imaging Document Con- sumer Gateway. The XDS-I Imaging Document Source Agent provides interfaces, SCP and DICOM C-Move/C-Store SCP, to other XDS-I Imaging Document Consumer clients to access the image data. The XDS-I Imaging DocumentConsumer Gateway provides the DICOM/HL7 inter- faces for PACS/EMR WS to query and retrieve docu- ment and image data from other XDS-I Source actors. (7) PACS/RIS servers, which are located in hospitals and functioned as the image/report source actor dened in IHE XDS/XDS-I proles. (8) PACS/EMR workstations are used by end users to access the image/report documents from i-EHRs; theyfunction as the consumer actor dened in IHE XDS/ XDS-I proles. Major services in i-EHR system Figure 2shows four key use case services to be implemented: (1) XDS-I.b (version b) Submitting and Registering of imag- ing documents from PACS/RIS servers; (2) XDS-I.b Queryand Retrieval; (3) DICOM Submitting, Query, and Retrieval from PACS WS; (4) Grid services for auto-routing of collab- orative imaging diagnosis among hospitals. Most serviceswere implemented in Grid Agent. Figure 2shows the majorservices running in Grid Agent and their relation to local PACS/RIS, remote imaging document sources, and remote Grid Agent nodes, as well as to XDS Registry, Repositoryand Grid Manager. Usually, the Grid Agent connects to a hospital PACS server and workstations through DICOM Storage, Query/Retrievalor WADO Services, and to RIS through HL7 or some Web services dened for XDS-I submitting, query/retrieval, and collaborative imaging diagnosis. The Grid Agent works asImaging Document Source Actor on behalf of PACS/RISservers to submit the manifests of image, evidence documents from PACS, or diagnostic reports from RIS. The Agents also work as the Imaging Document Consumer Actor on behalfof PACS workstations to query the XDS Registry, retrieve the reports or manifests from XDS Repository, and then retrieve images from other hospital PACS through the remoteGrid Agent node. As the HL7 inbound service and DICOM services of C-Store, C-Find, and C-Move are well known [14,15], we only briefly describe some key functions of Web services dened for PACS communicating with Grid Agentto perform XDS-I submitting and query/retrieval as well as collaborative imaging diagnosis implemented in Grid Agent here. Image study/reports registering services This service group enables a PACS/ RIS workstation to obtain DICOM series or reports (CDA R2/Plain text) from the PACS/ RIS server as indicated by the symbol in Fig. 2a. It extracts specic metadata information (UIDs of patient/study/series/images) from these series/reports, cre-ates manifest dened in the way of DICOM KOS [3], sends manifest to Grid Agent through a Web service, indi-cated by in Fig. 2a, which retrieves GID from PIX Man- ager and creates the Submission Set containing the manifest,DocEntry Metadata, and Submission set Metadata denedby Repository as indicated by , 123 116Int J CARS Fig. 2 Services implemented in Grid Agent and their relation to local PACS/RIS, remote imaging document sources, and remote Grid Agents, as well as to XDS Registry, Repository and Grid Manager. aData flows of the XDS-I Submitting and Registering services are indicated by thesymbols -----.bData flows of the XDS Query and Retrieval are indicated by the symbols /prime-/prime--/prime-/prime-/prime-/prime-/prime-/prime.cData flowsof the DICOM/HL7 MSG (Reports) Submitting are indicated by thesymbols /prime/prime-/prime/prime--/prime/prime-; data flows of DICOM Query and Retrieval are indicated by the symbols /prime/prime--/prime/prime-/prime/prime--/prime/prime-/prime/prime.dData flows of the Grid Services for Auto-Routing with HL7 MSG (ADT) are indicatedby the symbols /prime/prime-/prime/prime--/prime/prime-/prime/prime-/prime/prime-/prime/prime , and D in Fig. 2a. The XDS Repository stores the DICOM manifest & DocEntry Metadata to the database, creates the Object UID (OID) for each document in the Submission Set, and forwards the DocEntry Metadata, OIDs, and URL of theRepository to XDS Registry as indicated by in Fig. 2a. XDS-based image study query/retrieval services This service group enables a PACS WS to query PIX Man- ager by using a Web service of query and HL7 Query Engine to get patient GID based on the local ID and ID Issuer rst, as indicated by /prime-/prime-in Fig. 2b. Also, it uses GID (or GIDs) XDS Query (XDS Stored_Query, ITI-18) transactionto Registry as indicated by /prime. Meanwhile, the XDS Registry searches the Registry Database and returns alist of OIDs (Object UIDs created in Repository when thedocument is stored in Repository). The PACS WS parses the queried results to allow the user to make a selection and to initiate retrieval procedure to XDS Repository to retrievethe image manifest (DICOM KOS) or reports with CDA R2 format as indicated by /prime, parses the manifests to get UIDs of the study/series, and initiates a DICOM C-Move requests to Grid Agent by sending UIDs to it. The Grid AgentC-Move SCP service receives the C-Move request, convertsthe request to Grid_Retrieval MSG, and sends the MSG, going through Grid Manager, to the remote Agent with UIDs of the study/series, respectively. The remote Grid Agentnodes receive the Grid_MSG, parse MSG, get UIDs of theseries, and initiate DICOM C-Move requests to the attached PACS server to retrieve the image series. After receiving the DICOM series sent from the remote PACS server, theremote Grid Agent node caches the images in local storage devices, and then sends these series to the requesting node through Grid_FTP le transfer protocol; it then routes theimage series to the PACS WS through DICOM C-Store ser- vice. The whole data flow of image data retrieval is indicated by /prime-/prime-/prime-/prime-/primein Fig. 2b. For obtaining images using DICOM C-Find and C-Move services, data flow is shown inFig.2c. auto-routing service The Grid-based XDS-I solution provides an event-driven mechanism to deliver image data sets to specic destina- tions (PACS servers, workstation, or hospital facilities) tomeet specied work flow requirements. The image delivery 123 117Int J CARS Fig. 3 Data flow of JPEG 2000 progressive display implemented in a PACS WS (Client) for image retrieval from a remote Grid Agent (Server) rules of auto-routing are built based on healthcare event types, work flow arrangements, and user preferences among differ-ent enterprises. For example, HL7 MSG (ADT) can be used to trigger the data flow of pre-fetching the previous related studies done by other hospitals to the current site if the patientis admitted to the hospital and an examination is ordered. This procedure data flow is indicated by /prime/prime-/prime/prime--/prime/prime-/prime/prime-/prime/prime-/prime/prime in Fig. 2d. JPEG 2000 interactive protocol (JPIP) service In order to achieve quick responding effects in image retriev- ing in a low-bandwidth network environment, we use theJPEG 2000 interactive protocol (JPIP) to access images man- aged by Grid Agent nodes and use a progressive display technique to transmit images from Grid Agent, as ImagingDocument Source Actor, to the PACS WS, as Imaging Doc- ument Consumer Actor. Figure 3shows the JPEG 2000 pro- gressive display data flow implemented in our PACS WS for image retrieval from a remote Grid Agent [ 16]. Security solution and central management In order to secure the communication and image/report shar- ing between the hospitals, we developed an integrated secu- rity solution for i-EHR system. The security services and function of the security solution include the following [17]: (1) Access Control; (2) Single Sign-On; (3) PHI (Protected Health Information) Data Protection;(4) Auditing Trial. We also developed an administration graphic user interface tool to centrally manage, monitor, and control all componentsof XDS Registry, Repository, PIX Manager, and Grid Agentnodes. This administration tool can provide graphic informa-tion about imaging document submitting, registering, retriev-ing, operating, and physical status of all key components of the i-EHR system and can perform system administration and conguration remotely. Implementation and preliminary results Healthcare regulation concerning radiologic imaging diag- nostic service in China requires two steps to complete imag-ing diagnosis: preliminary diagnosis and nal diagnosis. Junior radiologists can perform the preliminary diagnosis, but the nal diagnosis must be approved by a senior radiol-ogist. Usually, there are a few senior radiologists working in level 1 hospitals, such as community hospitals. In this sit- uation, nal reports usually required more than one day tobe available for the physician or patients, as the report must wait for a senior radiologist to physically come to the level 1 hospital and nalize the report. The major goal of our pro-ject is to develop an image exchange and sharing platform toefciently enable collaborative imaging diagnosis between hospitals of different levels and to provide sharing mecha- nism between hospitals in order to reduce costs by re-usingprior examination data obtained in other hospitals. Pilot testing of the image-enabled EHR The rst phase of pilot testing of our image-enabled EHR was performed in the Zhabei district of Shanghai for imag- ing document sharing and collaborative diagnostic purposes. Figure 4shows the Shanghai map and the location of Zhabei district. We built a pilot testing environment in the Zhabei district including four hospitals through a virtual private net- work (VPN) with bandwidth of approximately 2 Mbits/s to10 Mbits/s. The i-EHR server consisted of servers of XDS Registry, XDS-I Repository, PIX Manager, and Grid Man- ager and an image backup storage system; these were locatedat the Healthcare Information Center of Zhabei district.The Grid Agent, functioning as XDS-I Imaging Document Source and Consumer Actors, was located in each of four hospitals and integrated with PACS and RIS. The four hos-pitals participating in the pilot testing were City North Hospital with 500 beds (level 2) and Wan Long, Ling Feng, and Peng Pu community hospitals (all level 1).The PACS/RIS systems installed in these four hospitals came from two vendors, Siemed Healthcare Information Incorp. (Shanghai) and New Health Network Incorp.(Beijing). 123 118Int J CARS Fig. 4 Map of Shanghai showing locations of hospitals participating in the pilot testing in Zhabei District Hardware conguration and network connection The i-EHR system consists of one controlling center of the i-EHR system and multiple Grid Agent nodes functioning asimaging document source and consumer actors. The hard- ware congurations of the i-EHR system were as follows: (1) The server of XDS Registry: HP ProLiant DL585 server with dual CPU, 16 GB RAM, and dual network com- munication interfaces (NCI); (2) The server of XDS Repository: HP ProLiant DL585 Server with dual CPU, 16 GB RAM, and dual NCI; (3) PIX Manager: HP ProLiant DL585 Server with dual CPU, 16 GB RAM, and dual NCI; (4) Image backup Server: HP Itanium/Integrity RX266 server with dual CPU, 12 GB RAM, dual NCI, and20 TB SAN (Storage Area Network) Storage (EMCCX4/CX); (5) Grid Agent nodes: Dell PowerEdge Server 2850 with dual CPU, 2 GB RAM, and dual NCI, or Dell Power-Edge SC430 with single CPU, 2 GB RAM, and dual NCI. Figure 5shows the major components of i-EHR servers and agent nodes integrating the four hospitals' PACS/RIS in Zhabei district of Shanghai city for pilot testing. Most com-ponents in Fig. 5are described in Sect. 3; the Image Backup server is rst introduced here. The Image Backup server isused to backup image studies from lower-level hospitals thatdo not have PACS but require image sharing service with higher-level hospitals via i-EHRs. The Image Backup server is one Grid Agent node attached with 5 TB SAN storage, andthe stored image data in the backup server was transferredfrom other remote Grid Agent nodes through the Grid-FTP service. Implementation of work flows of imaging document sharing and collaborative diagnosis Figure 6shows the work and data flows of the pilot test- ing for sharing and collaborative diagnosis. The work flow of shared imaging documents such as DICOM images andreports to XDS Repository and Registry or i-EHR Server is straightforward, as described in Sect. 4.1: (1) The images can be sent from PACS servers or work- stations through DICOM C-Store, and the manifests of DICOM image instances, Document Entry Metadata,and Submission Metadata are created by Grid Agent. They are then submitted to XDS Repository through XDS-I.b Provide & Register Document Set-b [IHERAD-68] protocol [3] as indicated by symbol and in Fig. 6. The submission procedure for reports has the same steps, but the manifests are replaced by CDA(Release 2)-based reports. (2) For the Query step, the PACS WS rst queries the XDS Registry through Grid Agent via XDS.b Stored Query[IHE ITI-18] protocol [3]i nF i g .6 and retrieves the reports or manifests from the XDS Repository as indi- cated by symbols /primeand/prime. (3) If a Grid Agent receives a manifest from Repository, it decodes the manifest and uses the UIDs of seriesfrom manifest to retrieve images from a remote Grid Agent through WADO or http-based JPEG2000 inter-active protocol (JPIP) as indicated by the symbol /prime. 123 119Int J CARS Fig. 5 Diagram of major components of i-EHR servers and Grid Agent nodes integrating four hospitals' PACS/RISs in the Zhabei district of Shanghai city for pilot testing. There is one level 2 hospital and threelevel 1 hospitals participating in the pilot testing. Solid lines indicate the communications with image data and XDS-I/Grid MSGs, and dash lineindicates the communication only with XDS-I/Grid MSGs We also integrated XACML (eXtensible Access Control Markup Language) into imaging document submitting, reg-istering, querying, and retrieval to enable the access control for a specic user accessing the specic documents. The work flow of collaborative diagnoses is implemented as following: (1) A junior radiologist in a community hospital (level 1) rst reads the images on PACS WS, creates the pre- liminary report, and stores it into the local RIS.Meanwhile, he completes an electronic Request Form integrated with RIS reporting GUI (graphical user inter- face) with patient ID, UIDs of the report and stud-ies, and ID and name of a senior radiologist working in a remote level 2 or level 3 hospital as indicated in Fig.7a. (2) The CDA-based Request Form was created and submit- ted to the XDS Repository through Grid Agent; at the same time, the related DICOM images and preliminary report are sent to the local Grid Agent and then to theremote Grid Agent. The data flow of this requesting procedure is indicated by the symbols ,, and in Fig.6. The notication of requesting nal reporting to the senior radiologist is transmitted through the Gridinstant messaging channel. (3) The senior radiologist receives the message and checks the Inbox of his account in the i-EHR system. From theInbox work list, he nds the Request Form, selects the preliminary report and study from the queried list ofXDS Registry and Repository, and retrieves the study using either http-based JPEG 2000 progressive dis- play features or the DICOM C-Move/C-Store servicesthrough the attached Grid Agent, which moves the image data from remote sites. Data flows of this pro- cedure are as indicated by the symbols /prime,/prime, and /prime in Fig. 6. (4) After reading the study and preliminary report, he/she signs the nal report and sends it to the Grid Agent,which converts it to a CDA-based report and sends itback to the original requesting site, indicated by the symbol /prime. (5) The junior radiologist receives a notication message concerning the available nal report and downloads itto the local RIS to read and print. Figure 7a is the GUI of a junior radiologist in a community hospital used to select a senior radiologist for nal reporting from a level 2 or level 3 hospital. Figure 7b is the GUI of the Inbox study list for nal reporting by a senior radiologistPACS workstation. There are different colors in the Inboxstudy list indicating the image transferring status: blue and green indicate the studies are ready to be retrieved, yellow means the studies are transferring, and red indicates that thetransferred studies failed. 123 120Int J CARS Fig. 6 Diagram of the work flow and data flow of the image-enabled EHR system for imaging document sharing and collaborative diagnosis among small hospitals (level 1) and large hospitals (level 2 or 3). Solid lines show data flow, and dash lines show work flow Fig. 7 a The GUI of a junior radiologist at a community hospital showing a Requesting Form with selected level 2 hospital and a senior radiologist for nal reporting. bThe GUI of worklist in the Inbox of a senior radiologist showing the available requested jobs for nal reporting The piloting testing began October 2009, and senior radi- ologists at higher-level hospital received approximately 50 transferred messages and examinations daily from three com-munity hospitals for collaborative diagnosis. The feedback from both users of community hospitals and North City hos- pital was very positive, reporting that it was easy to use anddid not interfere with their normal daily operations.Performance evaluation of the image transmission for sharing and collaborative diagnosis In order to provide faster image responding for image retrieval, we developed a JPIP-based progressive display technique combined with http protocol and used this tech-nique in PACS WS to retrieve images. Table 1gives the 123 121Int J CARS Table 1 Testing results of JPIP-based progressive transmission and display on different kinds of images in i-EHR system from a remote Grid Agent to a PACS WS Modality typesOriginal size/lossless KB of imagesBand width of network ( KB/seconds)Time of rst frame arriving display (Seconds)Time of full size image arriving (Seconds)Time of complete image (or data set) arriving (Seconds) CT (16) I71 KB (1) 2297 KB \u00d7l 250 <12 9 testing results of progressive transmission and display for dif- ferent image types in a low-bandwidth network environment (250 KB/sec). We selected two series from each type of modality study to evaluate their image transferring perfor-mance from a remote Grid Agent to PACS WS. First, we measured the time of rst low-resolution frame arriving to the display WS after a user initiates a retrieval request to aremote Grid Agent for a JPEG2000 image compressed with multiple resolution frames, as indicated by the right third column in Table 1; this provides the feature of time respond- ing of image retrieval in i-EHR. Second, we measured thetime of full viewing size image arriving to the display WS after a user initiates the retrieval request to a remote Grid Agent, as indicated by the right second column in Table 1; this would report the length of time before a user could start to view an image. Third, we measured the total time required to download a whole series of images to PACS WS after auser initiating the retrieval request to a remote Grid Agent, as indicated by right rst column in Table 1. From Table 1, we see that the performance of image transmission and display is quite good with the JPIP tech- nique integrated in the i-EHR system, since the time of rst frame (the lowest frame of multiple resolution frames in one JPEG2000 compressed image) and full size of image trans-mitted from a remote Grid Agent to a PACS WS are very short, about 1-2 s in the low-bandwidth network environ- ment (250 KB/s). The time required to download a wholeseries of JPEG 2000 lossless compressed images to PACS WS was 3-10 s but would be 3-5 times longer if they were not compressed, as the sizes of original images were 3 timeslarger. Discussion There are many countries and regional districts with long- term goals to build EHRs, and there are different ways tobuild EHRs based on different healthcare service modelsand technical approaches. One of key challenges in build- ing EHRs is identifying a cost-effective way to securely share and exchange patient records among different hospitalsand healthcare providers to meet various healthcare require- ments. In this section, we discuss and compare some tech- nical approaches for the implementation of image-enabledEHRs. The NHS National Programme for IT (NPfIT) is an ini- tiative by the Department of Health in England to move theNational Health Service (NHS) in England towards a single,centrally mandated electronic care record for patients and to connect 30,000 general practitioners to 300 hospitals. This system aims at providing secure and audited access to theserecords by authorized health professionals [ 18]. The NPfIT consists of 5 geographic clusters: North East, North West,Eastern, London, and Southern, built by ve capital care alli-ances [4]. It seems that the image sharing between PACSs in most of these clusters are transmitted through central archiv- ing systems and use the application service provider (ASP)model [19 ] to implement the sharing mechanism. The PACSs installed in England's NHS are largely successful in individ- ual hospitals; however, communication between systems in different hospitals is poor, according to a new position paperfrom the Royal College of Radiologists [20 ]. Another seri- ous problem in NPfIT, according to the RCR's paper [20],is its \"failure to realise the importance of document sharingthat integrates radiology reports and images and the lack of a clear, long term strategy for integrating radiology reports and images into the electronic patient record\". One drawback of this kind of central approach is that the costs of image sharing and exchanging between hospitals in a large city such as Shanghai with 20 million residents and 500 hospitals would be much higher compared to the distributedarchitecture such as XDS-I described in the paper. This is because the former (1) needs an extra large central archiving system to exchange the image data between hospital PACSs, 123 122Int J CARS (2) requires higher-network bandwidth in central archiving system to receive image data from multiple hospital PACSsand to transfer data from the central system to the desti- nation PACSs, if the desired communication performance is required, (3) usually lacks capability of image work flow anddata flow control and report sharing, and (4) faces difculty toimplement higher efcient collaborative diagnosis between hospitals. This paper outlines a set of guidelines complied to international standards to overcome the problem of auto-mated image and report sharing. These guidelines include the adoption of the IHE XDS and XDS-I proles for sharing images and other clinical information [20]. Canada Health Infoway (Infoway) aimed at building Diag- nostic Imaging Repository (DI-r) in the majority of Canada'sprovinces in order to allow hospitals in one regional healthauthority to share a digital Picture Archiving and Communi-cation System (PACS), which enables patients to have radio- logical imaging scan performed at one hospital with the results accessible to physicians at other hospitals and online[21]. Up to now, the DI-r projects in most provinces are very successful, and there are many benets being achieved fromthese projects [22 ]. Infoway also adopted IHE XDS-I prole as a pan-Canadian standard to guide the development of DI-r or to provide federation among the DI-rs in large cities or provinces [ 21]. However, there are still some uncertainties in implementing pan-Canadian standard in some DI-r projects,such as how to use existing Radiology Technical Framework Proles (e.g. IHE Schedule Work Flow and IHE XDS-I) in regional Diagnostic Imaging Repository (DI-r) to allow com-munication with local PACS and how such a system should actually support them [ 23]. In this paper, we described one approach to implementing the IHE XDS-I prole for a regional image sharing and col-laborative imaging diagnosis. We developed i-EHR with Grid Agent nodes to implement the most services of IHE XDS-IImaging Document Source and Consumer Actors and usedthe grid concept to federate the Grid Agents. The Grid Agent nodes and server components of i-EHR function as middle- ware between the local PACS/RIS and remote PACS/RISsystems, and they provide a single point of image/report communication services to local user systems. Additionally, there are some specic designed services, such as event-driv-ing auto-routing in i-EHRs, to enable collaborative imaging diagnostic service between higher-level hospitals and lower- level hospitals. Compared to the image sharing architecturesimplemented in NPfIT and Infoway DI-r projects, our solu-tion has some advantages: (1) We do not use central archiving or Repository to achieve the image data communication between hospi- tal PACSs, because central approach requires two times the bandwidth usage to upload and download images incentral archiving server and requires extra large storage(central Repository) to exchange image data betweenhospitals. (2) The Grid Agent node has most DICOM communica- tion services and XDS-I Imaging Document Source/Consumer Actors transaction services and can directlyinterface with imaging modalities. Thus, i-EHRs canprovide software as a service (SAAS) to some small hospitals or clinics, which have imaging modalities but do not have PACS, and enable them to share andexchange image data with other hospital PACSs to pro- vide qualied imaging diagnostic service to patients. This feature of i-EHRs can save costs of image man-agement in some smaller hospitals. It also provides data and work flow control and management to exchange and share images and reports together between hospitals forcollaborative imaging diagnosis and makes the collab-oration more efcient and cost-effective. (3) The approach presented in this paper uses a peer-to-peer mode to share and exchange image data between thehospital PACSs and uses SOA architecture and grid con- cept (providing single point of services to local systems so it is easy to integrate with different vendor's PACSand easily deployed to different hospitals) to implement the i-EHR. The designed i-EHRs can scale efciently and effectively to serve a regional implementation. Our i-EHR project in Shanghai is still ongoing, and we are working to deploy the system to include all hospitals in Zhabei district. We are also planning to establish an imagingdocument sharing mechanism between different healthcare organizations and hospital groups or called cross-community access (XCA); the proposed IHE XCA-I integration prole[24] is considered a technical guidance. The challenge is tomake sharing systems in every related community or domain that are XDS-I compliant [24]. Conclusions In this paper, we presented a design method and imple- mentation solution of image-enabled EHRs (i-EHRs) fully aligned with the IHE XDS-I integration prole and com-bined with the grid concept. The rst phase of our projectwas to build the major components of an i-EHR system and to test functionality of these components and work flows of image sharing and collaborative diagnosis in four hospitals.We built a pilot testing environment in the Zhabei district of Shanghai city across multiple hospitals through VPN con- nection with bandwidth around 2 Mbits/s. We installed theServer of i-EHR in Healthcare Information Center of Zhabei district and deployed the Grid Agent in four hospitals. With the i-EHR system, the seamless sharing of images and reportsacross multiple hospitals was achieved, and the i-EHR system 123 123Int J CARS can provide automatic image delivery for collaborative imag- ing diagnosis across multiple hospitals based on work flowrequirements. Feedback from users at both the community hospitals and large hospital is very positive. The JPEG2000-basedstream data transferring and progressive display technolo-gies overcome limited bandwidth problem and achieve quick response on image retrieval and display. From this project we learned that the IHE XDS-I integration prole provides goodarchitecture for regional imaging document sharing across multiple healthcare providers, but there are challenges to its implementation. We developed a Grid Agent componentto solve interfacing problems between local PACS/RIS and regional image sharing system and developed some specic services to provide collaborative imaging diagnostic servicesbetween lower- and higher-level hospitals. This project dem-onstrates that our image-enabled EHR solution based on SOA with a grid concept can scale effectively for regional imple- mentation. Acknowledgments This research was supported in part by the National Nature Science Foundation of China (Grant No. 30570512), Department of Science and Technology of China (No. 2007BAH06B01/03), Department of Science and Technology of Shanghai (GrantNo. 05DZ19510, 064119658, 06SN07111), and the Major StateBasic Research Development Program of China (973 Program) (No.2010CB834302). We acknowledge the major criticisms from thereviewers. Their careful thoughts and suggestions result in our refor-mulation of the contents and the presentation of this paper. References 1. Siegel E, Channin D (2001) Integrating the healthcare enterprise: a primer part 1. Introduction. RadioGraphics 21:1339-1441 IHE-RAD_ TF_Suppl_XDS-I-b_TI_2009-06-21.http://www.ihe.net/Technical_Framework/ 4. programme for information tech- nology\u2014an overview. J Vis Commun Med 30(2):72-77 5. Catz & clouds. http://www.itu.int/dms_pub/itu-t/oth/23/ 01/T23010000090001PDFE.pdf 7. Middleware for Grid Computing, http://glite.web. cern.ch/glite/ 9. Uniform Interface to Computing Resources, http://www.unicore. eu/index.php 10. Daher N Middleware moves in on PACS. Imaging Technology News. http://www.itnonline.net/node/28246 11. The cancer Biomedical Informatics Grid, https://cabig.nci.nih.gov/ overview/ 12. Audit Trail and ol1_FT_ 2009, pp 54-66. http://www.ihe.net/ Technical_Framework/ 13. Yang Y, Jin J, Sun J, Zhang J (2008) Design and implementation of grid-based PACS in a hospital with multiple imaging departments.SPIE 6919:69190L1-9 14. DICOM (Digital Imaging and Communications in Medicine) ISO TC215:Health Informatics: ISO/DICOM:12052:2006. http:// ISO/HL7 21731:2006. http://www.iso.org/iso/ 16. Tian Y, Cai W, Sun J, Zhang J (2008) A novel strategy to access high resolution DICOM medical images based on JPEG2000 inter-active protocol. SPIE 6919:691912.1-691912.12 17. Yao Y, Zhang C, Sun J, Zhang J (2007) Integrated security solu- tion for electronic healthcare record sharing. SPIE 6516:65160P.1-69160P.11 18. NHS National Programme for IT, http://en.wikipedia.org/wiki/ NHS_National_Programme_for_IT 19. Liu B, Huang HK, Cao F, Documet L, Muldoon J (2002) Clinical experiences with an ASP model backup archive for PACS images(abstr). Radiology 225(P):313 20. The Information Technology Sub-Committee of the Royal Col- lege of Radiologists IT guidance: national strategy for radiologyimage and report sharing. http://www.rcr.ac.uk/docs/radiology/ pdf/BFCR(09)6_imaging_strategy.pdf 21. Lgras E Achieving diagnostic imaging data sharing. http://www. ihe.net/Participation/upload/3d_ihe_wkshp07_chinfoway_igras.pdf 22. Videre Team Analysis: Canada Health Infoway Diagnostic Imag- ing Benets Evaluation Final Report, December 15, 2008. http:// www2.infoway-inforoute.ca/Documents/ 23. Heaney D Add image repository to SWF/XDS-I\u2014detailed pro- posal. http://wiki.ihe.net/index.php?title=Add_Image_Repository _to_SWF/XDS-I_-_Detailed_Proposal 24. Cross Community Access for Imaging (XCA-I)\u2014Detailed Proposal. http://wiki.ihe.net/index.php?title=Cross_Community_ Access_for_Imaging_(XCA-I)_-_Detailed_Proposal 123 124Int J CARS DOI 10.1007/s11548-010-0524-6 ORIGINAL ARTICLE MIDG-Emerging grid technologies for multi-site preclinical molecular imaging research communities Jasper Lee \u00b7Jorge Documet \u00b7Brent Liu \u00b7 Ryan Park \u00b7Archana Tank \u00b7H. K. Huang Received: 6 February 2010 / Accepted: 14 July 2010 \u00a9 CARS 2010 Abstract Purpose Molecular imaging is the visualization and iden- tication of specic molecules in anatomy for insight intometabolic pathways, tissue consistency, and tracing of sol-ute transport mechanisms. This paper presents the Molec- ular Imaging Data Grid (MIDG) which utilizes emerging grid technologies in preclinical molecular imaging to facil-itate data sharing and discovery between preclinical molec-ular imaging facilities and their collaborating investigator institutions to expedite translational sciences research. Grid- enabled archiving, management, and distribution of ani-mal-model imaging datasets help preclinical investigators to monitor, access and share their imaging data remotely, and promote preclinical imaging facilities to share publishedimaging datasets as resources for new investigators. Methods The system architecture of the Molecular Imaging Data Grid is described in a four layer diagram. A data model for preclinical molecular imaging datasets is also presentedbased on imaging modalities currently used in a molecu- lar imaging center. The MIDG system components and con- nectivity are presented. And nally, the workflow steps forgrid-based archiving, management, and retrieval of preclin- cial molecular imaging data are described. Results Initial performance tests of the Molecular Imaging Data Grid system have been conducted at the USC IPILab J. Lee (B)\u00b7J. Documet \u00b7B. Liu \u00b7H. K. Huang IPILab, Department of Biomedical Engineering, University of Southern California, 734 West Adams Blvd.,Los Angeles, CA 90089, USAe-mail: jasperle@usc.eduURL: http://www.ipilab.org R. Park \u00b7A. Tank Molecular Imaging Center, Department of Radiology, Keck School of Medicine, University of Southern California,2250 Alcazar Street, CSC 103, Los Angeles, CA 90033, USAusing dedicated VMware servers. System connectivity, eval- uated datasets, and preliminary results are presented. The results show the system's feasibility, limitations, direction of future research.Conclusions Translational and interdisciplinary research in medicine is increasingly interested in cellular and molecularbiology activity at the preclinical levels, utilizing molecularimaging methods on animal models. The task of integratedarchiving, management, and distribution of these preclinical molecular imaging datasets at preclinical molecular imaging facilities is challenging due to disparate imaging systems andmultiple off-site investigators. A Molecular Imaging Data Grid design, implementation, and initial evaluation is pre- sented to demonstrate the secure and novel data grid solu-tion for sharing preclinical molecular imaging data across the wide-area-network (WAN). Keywords Molecular imaging \u00b7Animal model \u00b7Imaging informatics \u00b7Data Grid Abbreviations API Application Programming Interface A VI Audio Video InterleaveBIRN Biomedical Informatics Research NetworkDICOM Digital Imaging and Communications in Medicine FTP File Transfer ProtocolGAP Grid-Access-Point GridFTP Grid File Transfer Protocol (Globus Toolkit) HTTP Hypertext Transfer ProtocolIHE Integrating the Healthcare Enterprise IPILab Image Processing and Informatics Laboratory, University of Southern California JPEG Joint Photographic Experts Group LAN Local-Area-Network 123 125Int Grid MIMI Multi-modality Multi-resource Information Integration PACS Picture Archiving and Communication System PDF Portable Document FormatPET-CT Co-registered PET and CT PNG Portable Network Graphics RLS Replica Location Service (Globus Toolkit)SSL Secure Sockets Layer TIFF Tagged Image File Format UCLA University of California-Los AngelesUS Ultrasound USC University of Southern California WAN Wide-Area-Network Introduction Molecular imaging studies using animal-model subjects are necessary steps in biological medical research and new ther- apy discoveries that are focused on cellular and molecu-lar pathways. Researchers from multi-disciplinary labs and institutions utilize imaging modalities and software resources provided by preclinical molecular imaging facilities to plan,acquire, post-process, visualize, and analyze their experi-mental animal-model studies [1]. However, the data from these preclinical imaging studies are currently isolated to investigator folders on primitive storage solutions, lack-ing distributive data infrastructure with institu- tional access [2]. The research in this paper addresses theapplication, design, and an implementation of emerging grid technologies to tackle these informatics challenges. The objectives are to enable preclinical molecular imaging facil-ities to share their imaging datasets as resources for newinvestigations and to equip preclinical investigators with infrastructure to remotely monitor, share, and access animal- model imaging data. Molecular imaging Molecular imaging is the visualization, localization, and characterization of biological processes at the cellular and molecular levels within intact living organisms. The multi- ple image-capture techniques in molecular imaging reflectpharmacokinetic pathways and in vivo mechanisms of dis- ease within of physiologically authentic environ- ments [3]. Investigators of inter-disciplinary sciences, suchas pharmaceuticals, cancer research, proteomic studies, andimage engineering, are increasingly dependant on molec-ular imaging to test their hypothesis before moving on intheir translational research. With promising clinical benets in personalized medicine, molecular imaging techniques are increasingly being utilized in animal-model trials and medi-cal research experimentation [ 4]. The imaging modalities in preclinical molecular imaging are similar in design to clinical radiology modalities, but havesmaller gantries and higher spatial resolution for small animalimaging. Figure 1shows photographs of six common small animal imaging modalities available in preclinical molecu-lar imaging today. Figure 2shows a sample dataset from a co-registered PET/CT imaging study of a nude mouse with a prostate cancer tumor, courtesy of the USC Molecular Imag- ing Center [5]. Preclinical molecular imaging informatics Preclinical molecular imaging provides valuable insight into, otherwise unseen, molecular pathways and disease progres- sion in animal-model anatomy through in image acqui- sition, visualization, quantication, and analysis [ 1,3]. Due to high capital and operational costs, these preclinical imag-ing modalities, computing resources, and trained imaging staff are typically convened into dedicated preclinical imag- ing facilities. As of 2008, there were an estimated 150 pre-clinical molecular imaging facilities in the United States, of which a majority are located in medical schools to serve both on-campus and local investigators [6]. The investigative imaging workflow at these facilities, overviewed in Fig. 3, go from study planning and scheduling, to preparing animals for scans, to post-processing acquisitiondata, to visualization and analysis on dedicated workstations,and, if no further scans are required, to archive and distribute the resulting datasets. Investigators travel to preclinical imag- ing facilities, even after image acquisitions are completed, tomassage, analyze, and collect their data. Because molecu- lar imaging systems and data formats are still changing, the data archives for preclinical molecular imaging facilities areprimitively tied to the imaging modalities, staff, and com- putational software [7]. The current challenges in molecular imaging informatics are to organize and distribute these dataarchives to multiple investigator sites in a secured data infra-structure so that investigators can to readily access and con- tribute new data from their own labs [8]. This paper presents an informatics data grid method to meet these challenges. The informatics systems of preclinical molecular imaging can be categorized into two fronts-image post-processingand data management. Although efforts have been devotedto the automation of computational workflows, data archiv- ing, and data dissemination in preclinical imaging facilities have been comparatively primitive due to informatics chal- lenges caused by non-standardized data formats, complex 123 CARS Fig. 1 a MicroPET, bMicroCT, cMicroMRI, dMicroUS, eOptical Imaging, fAutoradiography. Courtesy Center, USC for Fig. 1a, b, d-f, and Molecular Imaging Program at Stanford, Stanford University for Fig. 1c Fig. 2 Sagittal CT, PET, and PET/CT Fusion Image of a Mouse [left toright ]. Courtesy of Molecular Imaging Center,USC Fig. 3 Traditional Molecular Imaging and InformaticsWorkflow ( Green Arrow digital data write and Blue Arrow digital data read)1. Plan Imaging Studies2. Schedule Imaging3. Prepare Animals4. Perform Scan5. Performs Post-processing (if required) 7. Data Archiving9. Data Distribution6. Analysis & Reporting10. Investigator Views Images and Results 8. Local Network Storage Device 123 127Int J CARS experimental metadata, and antiquated storage infrastructure [9-11 ]. A Molecular Imaging Data Grid (MIDG) A Molecular Imaging Data Grid (MIDG) has been devel- oped in the IPILab and is being deployed at the USC Molec- ular Imaging Center, which needs a better way to document, search, and distribute its experimental image data for itsgrowing number of investigators. Previous methods of docu-menting studies and imaging parameters were on log-books written by technicians. Previous methods of saving image data were on stacks of DVD's and external hard-drives. And,previous methods of data distribution were using DVD's and portable flash drives, or sent via email. As the quantity and complexity of experimental datasets increase, the USCMolecular Imaging Center was lacking an integrated infor- matics infrastructure to expedite their multimodality imaging dataflow. The objective of the MIDG is to provide a study-centric archive infrastructure for preclinical molecular imaging com- munities with a web-based user interface for uploading, mon- itoring, searching, and downloading preclinical molecularimaging datasets. The novelty of using data grid technol- ogy is in its ability to deliver large imaging datasets securely and efciently across the wide-area-network (WAN) [ 12]. Designing a metadata database and user interface for pre- clinical molecular imaging workflows, and integrating them with a data grid infrastructure creates a unique data sharingplatform for preclinical molecular imaging research com-munities. Figure 4demonstrates how the Molecular ImagingData Grid improves image data sharing among interdisciplin-ary preclinical molecular imaging research communities. Methodology Building on the existing models of preclinical molecular imaging facilities and the experience of the IPILab in data grid systems for enterprise Radiology, a Molecular Imag-ing Data Grid for preclinical molecular imaging datasetswas designed for preclinical molecular imaging communi- ties. This system is undergoing preliminary evaluation at the USC campus involving the USC Molecular Imaging Centerand the IPILab. The primary steps in design were to dene a preclinical molecular imaging data model with a study- centric database and build components of the data grid archi-tecture around that data model. Preclinical molecular imaging data model A data model for preclinical molecular imaging identies data formats and relational structure of the data. The preclin- ical molecular imaging data model presented here is arranged in a study, session, group, scan, and le hierarchy. The leformats in preclinical molecular imaging vary by individ- ual facility's modalities, software, and storage policy, but all les fall within the acquisition, post-processing, and distrib-uted les categories. Figure 5shows this data model with sample les based on modalities, software, and workflow atthe USC Molecular Imaging Center. This preclinical imag-ing data model is reflected in the metadata database for theMolecular Imaging Data Grid. MicroPETPost- ProcessingGAP MicroCTGrid-Access-Point (GAP) Server GAPShared Grid Resources: Database Server Grid-based Messaging & File DeliveryUSC Molecular Imaging Center - multimodality imaging facility -Collaborating Investigator Sites Informatics Research LabLog into Data Grid Web GUI Monitor Imaging Study Status Retrieve Final Images & Reports Share Completed Studies Extensible Storage Archive Grid Management Grid Monitoring Image Processing Tools Redundant Disk StorageDownload Upload GridFTPSystem Overview: Molecular Imaging Data Grid Wide-Area-Network (WAN) Study-Centric Metadata Database Reliable File Transfer File Format Standardization Redundant Data Archiving Web-based User and Management Interface Fig. 4 Implementation scenario of the multi-institution Molecular Imaging Data Grid 123 128Int J CARS FILESYSTEM ex. D:\\studies\\ STUDY ex. 04637 Tables (LivingImage) Autoradiography tiff, FILES - Optical - tiff (LivingImage)SESSION ex. 0014 Fig. 5 Molecular Imaging Data Model for Storing Files in the Data Grid Archive In its current design, the Molecular Imaging Data Grid is customized to support le types provided by the USC Molec- ular Imaging Center. It converts all 2-dimensional viewableimage formats (JPEG, TIFF, PNG, PDF) to the DICOM format so that nal distributed les are standardized and prepared for interaction with external DICOM-compliantsystems. File formats that can not be converted to DICOM, such as raw acquisition les and proprietary les, are also registered into the Molecular Imaging Data Grid, but are notphysically copied into the remote storage archives of the grid.Non-DICOM les are kept at the originating facility's stor- age where they are most frequently accessed and are sourced directly to remote sites when queried upon. Molecular Imaging Data Grid software architecture The system architecture for a Molecular Imaging Data Grid is organized into 4 layers-application, user-level middle- ware, core middleware, and fabric. Certain components ofthis architecture are adaptations to previous Medical Imag- ing Data Grid work done at the USC IPILab [ 13,14]. It too utilizes the secure grid infrastructure provided by the Globus Toolkit 4.0, an open source software pack- age with le management services and secure le deliv- ery protocols [15 ]. Figure 6a below shows the architec- ture of the Molecular Imaging Data Grid and is con-trasted with Fig. 6b to demonstrate design similarities and differences of this new data grid for archival anddistribution of preclinical molecular imaging images. InFig. 6a, the blocks in orange identify the new software components of the Molecular Imaging Data Grid, and theGrid-Access-Point (GAP) services at the user-level middle-ware are highlighted in green. The core middleware layer of the Molecular Imaging Data Grid also utilize the Globus Toolkit packages, but a Resourcesand Events Monitoring service has been implemented tomonitor and audit data exchange among preclinical inves- tigators and imaging facility staff. The picture archiving and communication system (PACS) simulator in Fig. 6b has been removed because preclinical imaging workflows do not uti- lize PACS at this time. The new components of the Molecular Imaging Data Grid architecture shown in Fig. 6a are now presented in more detail in the following sections. Application layer With non-standardized data formats and communications protocols in preclinical molecular imaging informatics, the application layer was implemented with web-based user interfaces for archiving, monitoring, retrieving, and man-aging experimental imaging datasets within the Molecular 123 129Int J CARS Fig. 6 a Molecular Imaging Data Grid system architecture, built with services from the Globus Toolkit package, tailoredfor and resource)corresponds to the coremiddleware layer shown inFig.6aA B Imaging Data Grid. Unlike the DICOM-compliant data grid for radiology where external DICOM-compliant systems store, query, and retrieve imaging studies with limited user accountability, the web-based user-level interfaces enableuser-level control such that study registration, data upload, study sharing, and dataset retrieval are restricted to autho- rized users only over the secure HTTP protocols betweenuser workstations and local GAP servers. Only authorizedgrid managers also have an interface to monitor user activity and congure the local GAP services (Fig. 7). The primary features of the application interfaces are uploading of preclinical molecular imaging data les, review-ing and sharing of uploaded studies, searching for publicly shared studies based on ltered experimental parameters, 123 130Int J CARS Fig. 7 Screenshots of the Upload (left) and Download (right ) pages from the Molecular Imaging Data Grid's web-based user interface and retrieval of imaging datasets from the data grid's storage archives. The workflow of uploading and download-ing studies from the Molecular Imaging Data Grid is shown in Fig. 8. User-level middleware layer There are two major components in this layer: the Grid- Access-Point server (GAP) and the Data Persistence Man- ager. GAP. Grid-Access-Point servers (GAP, see Fig. 6ai n green) are placed behind network rewalls at each partici- pating grid site so only grid messaging and grid le trans- fer ports are allowed to pass into the Internet. When GAP servers receive new molecular imaging study data and lesfrom the web-based user interfaces, metadata attached with incoming les are updated to the metadata database by the Metadata Catalog Service, and then physically distributed toone or more of the external grid storage archives over the WAN using core middleware services. To retrieve imaging les from the grid, the Data Retrieve Service processes userselected requests from the web-based interfaces and initi-ates a secure GridFTP transfer to pull data les stored in the grid archives back into its local cache so users can down- load them locally from the Grid-Access-Point server. Bothof these GAP services are written in Java. Collision Management . To handle user trafc at the GAP services, there is a queuing mechanism at each Grid-Access-Point for uploading and downloading requests from users so that only one request is handled at a time. Further- more, data les are not made available for download untilupload has been completed and conrmed. If users from twoinstitutions are requesting to download the same image le,there is not a conflict because each Grid-Access-Point serverhandles its own user requests. However, if one user is attempt- ing to download a le while an administrative user at another institution is trying to delete that le, the delete request willnot be queued because verication is done to make sure that le is not already listed on the download queue. Data Persistence Manager. Data les are archived redun- dantly in a Molecular Imaging Grid at multi-site storagedevice destinations based on congurations in each Metadata Catalog Service, to allow reliable access to shared data. Thisdata redundancy is maintained by Data Persistence Manag-ers installed at each storage archive, initiating transmission of local data les to remote storage archives as a third-party manager using GridFTP. The Data Persistence Manager mon-itors the availability of a remote storage archive during off- peak hours and tries to re-populate missing data les. Upon successful transmission, databases are updated to reflect theadded le copy. This method creates an automated disaster recovery mechanism for all data les archived in the Molec- ular Imaging Data Grid. Core middleware layer The core middleware layer provides critical communications and data management services for the user-level middleware layer, and relies heavily on the Globus Toolkit API packages, particularly the components shown in gray in Fig. 6a. The Globus Toolkit provides secure le management and deliv- ery across the multi-site infrastructure via its Replica Loca- tion Service (RLS), certificate authentication protocols, andGridFTP le delivery services [17]. These software services 123 131Int J CARS Fig. 8 Application Layer Workflows for Archiving and Query/Retrieving in the Molecular Imaging Data Grid'sWeb-based User Interface1) Facility Administrators Register a new Study into the User Interface. 2) Temporary Study Folder is Created in the Shared Upload Directory on the GAP Server. 3) At the End of each Imaging Session, New Imaging Files are Manually Copied from Modality Workstations to the Created Study Directory on the GAP server. 4) Preclinical Imaging Staff log into the Web-based User Interface, Fill Out Relevant Study Metadata, and Select Imaging Files. Clicking \"Submit\"will Add the Upload Request to the Upload Queue. 5) Metadata Catalog Service on the local GAP server will process Upload Requests on a First-In Basis.1) An Investigator Logs Into Their local GAP'sUser Interface, and Queries the Archive by Study Metadata.(e.g. disease type) 2) Investigator selects on a Study to Download, adding the Download Request to the Download Queue. 3) Data Retrieval Service will Process Download Requests on a First-In Basis. Retrieved Study Files are Zipped and made Available as an FTP Link on the Web-based User Interface Page. 4) Investigator Clicks on Download Link to Download the Study Zip File to Personal Computer.Archive Query/Retrieve can be implemented redundantly at multiple remote servers to provide continuously available operations and resources. The resources and events monitoring software in the Molecular Imaging Data Grid is used to monitor grid hard-ware resources and auditing of data handling events are essential. This is necessary to maintain the integrity ofexperimental research data, services, and investigators in the Molecular Imaging Data Grid. A dedicated monitoring and auditing server maintains its own database to audit the statusof all hardware resources, and major events from the usersand middleware services. Fabric layer The components making up the fabric layer in the grid archi- tecture are the storage devices, databases, and network re-walls. In setting up a storage device for the molecular imag-ing grid, the amount of storage space allocated by a site is determined by all participating sites archiving data in the same Molecular Imaging Data Grid, thereby requiring dis-cussion and planning between parties. There are three main databases in the imaging grid-the molecular imaging meta- data database, the RLS databases, and the grid monitoringand auditing database. Based on experiences from previous data grid implemen- tations, the metadata database and monitoring and auditingdatabase are kept separate from the core middleware ser-vices due to performance degradation issues [ 18]. Nonethe- less, all three databases are critical resources to the grid'soperations and are implemented on dedicated database serv-ers with redundancy methods and secure socket layer (SSL) communications support. Molecular Imaging Data Grid connectivity and workflow The network connectivity of the Molecular Imaging Data Grid is shown in Fig. 9from the perspective of a molecular imaging site. The aquamarine area encapsulates the molec- ular imaging site's devices and the gray cloud area encap- sulates the components of the Molecular Imaging Data Gridthat are located outside in the wide-area-network (WAN). A network rewall, shown in amber, is required at each molec- ular imaging site to protect the local-area-network (LAN)devices. The workflow for data archiving, management, and distri- bution of preclinical molecular imaging, presented earlier inFig.1, changes with a grid-enabled Molecular Imaging Data Grid infrastructure. This new workflow is shown in Fig. 10. The colored arrows depict these three specic dataflows, andthe gray regions mark the Molecular Imaging Data Grid com-ponents that have been integrated into the original preclinical molecular imaging workflow. In step 7 of Fig. 10, molecular imaging les and study metadata are uploaded into local Grid-Access-Point servers 123 132Int J CARS Fig. 9 Components and Connectivity of the Molecular Imaging Grid Architecture, from a Molecular Imaging Site'sPerspective. Metadata CatalogService: dataredundancy; System Monitoringand databases,storage GAP (MIDG) Wide-Area-NetworkUser Interface Web-Server HTTPS Metadata Catalog Service & Data Retrieval Service Redundant Master Metadata Database ServerCertificate Authorization ServerStorage Archive RAID 5Storage Archive RAID 5Local Metadata Database (optional) RLS Server w/ Redundant DBReplica Location Service GridFTP ProtocolLocal RLS Database (optional) Network Firewall Molecular Imaging Site Local-Area-Network Molecular Imaging User Interface Data Persistence ServerData Persistence ServerSystem Monitoring & Events Auditing Server Fig. 10 Overall workflow of the USC Molecular Imaging Center with the Molecular Imaging Data Grid showing the novel archiving, datamanagement, and data retrievaldataflow methods 8. Local Network Storage DeviceWeb-based User Interfaces Gateway Services Molecular Imaging Middleware & Grid Resources Replica Location DatabasesMIC Archive Rules-based Data Persistence ManagerIPILab Studies2. Schedule Imaging3. Prepare Animals4. Perform Scan5. Performs Post-processing (if required ) 7. Data Archiving9. Data Distribution6. Analysis & Reporting10. Investigator Views Images and Results 123 133Int J CARS and transmitted securely into remote grid storage archiving sites. Within the grid, data les are monitored and maintainedby the Data Persistence Manager in order to maintain con- tinuous data availability through replication and long-term storage. In step 9, investigators can query for animal-modelimaging data from multiple collaborative sites and downloaddatasets into their workstations through a single web-based user interface of the Molecular Imaging Data Grid. Results Experimental set-up Initial evaluation of the Molecular Imaging Data Grid has been completed at the USC's Molecular Imaging Center and IPILab using VMware [ 19] environments. A Grid-Access- Point server has been installed on a Dell Precision PC located on the Molecular Imaging Center's local-area-net- work (LAN). The remaining hardware components of theMolecular Imaging Data Grid are being run at the IPILab on a dedicated Dell PowerEdge server with VMware Server 2.0. Network connectivity speeds between the Molecular Imag-ing Center and IPILab is 100 mbps data upload speed. Theobjectives of the evaluation were to measure the robustness in multiple le format support and to obtain quantitative esti- mates of the duration each process takes. Preclinical molecular imaging datasets for evaluation of the MIDG Sample preclinical molecular imaging datasets were collected at the USC Molecular Imaging Center from six preclinical imaging modalities-microCT, microPET, PET- CT, optical imaging, ultrasound, and autoradiography has a unique combination of post-processed, and nal viewable les and formats.These datasets listed in Table 1, identied by the USC Molecular Imaging Center as necessary les for long-term archiving and/or distribution to their investigators, were selected for evaluation of the MIDG. In this evaluation, onlynative DICOM (DCM) images and formats able to be con-verted to DICOM were used (see red font in Table 1). Preliminary results Initial tests of the MIDG have been done by measuring the time it takes to upload and download collected sample data-sets in the Molecular Imaging Data Grid. The measured time for uploading a study dataset starts when users click on the \"Submit\" button in the web-based user interface, and endswhen all selected study les have been received and marked as completed by the Metadata Catalog Service. This com- pletion signies that the uploaded study has been success-fully processed and moved to its storage destination in theMIDG and is available for download. The amount of time it takes to copy imaging datasets from modality workstation to the shared study folder on the GAP server was not mea-sured because it does not differ from the existing archiving methods. The measured time for downloading a study dataset starts when users click on the \"Download\" button in the web-baseduser interface, and ends when an FTP link to the zipped study le appears on the web-based user interface. Initial test resultsfor 1 study from each of the ve modality types are shownin Table 2. From these initial performance tests, qualitative results and quantitative performance times can be seen for all sixpreclinical modality types. The qualitative results are based on success of transmission of the sample datasets both to and from the MIDG. Testing scenarios include simultaneousuploading and downloading events to test for potential colli-sion handling. Upon renement of the MIDG system, all sam- ple datasets used in the evaluation were able to be archived and retrieved without failure or colliding trafc. The aver-age length of time for retrieval was half the time it took for archiving the same dataset. The modality types with few DICOM les had a performance time under half a minute,whereas larger scan datasets such as the 461 DICOM les in a microCAT scan took upwards of 5 min to archive and 2 min to retrieve for download. Table 1 Preclinical molecular imaging le formats collected for evaluation from USC Molecular Imaging Center MicroCAT MicroPET Pet-CT Optical imaging US Autoradiography Acquisition CAT TIFF - TIFF HDR TXT TIFF PDF XLS A VI PDF PDF 123 134Int J CARS Table 2 Performance tests measuring the time it takes to archive and retrieve a study dataset from 6 different preclinical molecular imaging modality types over a 100 mbps network MicroCAT MicroPET PET-CT Optical imaging US Autoradiography # of Files in animal scan 461 63 3 4 3 2 Total size 130 MB 2 MB 206 KB 105 KB 578 KB 8.9 MB Failures None None None None None None Collisions None None None None None Current status and future work The current Molecular Imaging Data Grid system supports all DICOM le formats; its performance is as shown in Table 2. We are in the process of converting non-DICOM le formats, such as proprietary raw acquisition les from the microCAT modality, and A VI videos from the ultrasound modality. Although DICOM compliance in the MolecularImaging Data Grid creates a standardized image output thatmakes preclinical molecular imaging data more accessible to external user software, the challenge to standardize all data formats in preclinical molecular imaging is inevitably insur-mountable. Thus, further work is being done to utilize inte- gration proles from the Integrated Healthcare Enterprise (IHE) in clinical radiology informatics to support sharingof imaging-related non-DICOM les across the The user-level and core-level middleware of the Molecular Imag- ing Data Grid architecture needs to be modied to incorporatethese large and diverse les. Discussion Comparing existing data grids in healthcare informatics Over the past decade in healthcare, there have been a handful of national and international efforts to realize grid-based sys- tems in biomedical research involving imaging data, such asEurope's ActionGrid and United States' Biomedical Infor- matics Research Network (BIRN) [20, 21]. The difference between the MIDG and these existing methods is in its appli- cation and project scope. The Molecular Imaging Data Gridapplies data grid technology to preclinical molecular imag- ing facilities, a specic biomedical imaging research com- munity that has not been addressed before. Furthermore, thescope of MIDG is focused on small communities of pre- clinical molecular imaging researchers, centered around a few, if not one, preclinical molecular imaging facility and itsafliated investigator institutions. The scope of the MIDG is purposely kept small to enable comprehensive customiza- tion for study metadata and supported le formats, and toempower preclinical molecular imaging facilities to becomeimaging cores with accessible historical datasets. Nonethe-less, a common theme in these grid-based projects is the needfor data standardization, user interfaces, metadata databases, grid-based data delivery, and extendable infrastructure for multiple sites [ 22]. The Molecular Imaging Data Grid takes these challenges into consideration and creates a unique pre- clinical molecular imaging informatics infrastructure with a workflow, data model, and user interfaces that can readily beintegrated into larger scoped initiatives such as BIRN in thefuture. Comparing current solutions in preclinical molecular imaging informatics Previous work at other preclinical molecular imaging facil- ities has been done to facilitate preclinical molecular imag- ing workflow by developing web-based data managementinterfaces for staff and investigative users within their respec- tive institutions. At UCLA's Crump Institute for Molecular Imaging, a web-based interface is implemented on campusfor investigators to schedule scan sessions in advance andrequest their own datasets to be made available on univer- sity-wide leservers [9]. The physical data archive consists of network le servers that organize datasets under individualinvestigator folders. At Case Western Reserve University, a web-based Multi-modality Multi-resource Information Inte- gration (MIMI) system has been developed to integrate staff,investigator, and data workflows. Its functionality ranges from scheduling, to data cataloging, to billing. The MIMI system also has a database for documenting user, equipment,project, and billing information. However, they too tacklearchiving and retrieval using share leservers and investiga- tive folders [6]. Retrieval of data les from these previous informatics solutions remains institutionalized and inves-tigator-centric. Thus off-campus access, contribution and discovery of new or historic preclinical molecular imag- ing datasets are very discouraged with current storage infra-structure [8]. As the value of inter-institutional collaboration and the volume of molecular imaging data generated in pre- clinical trials increases, the need for multi-institutional datasharing infrastructure and study-centric data management is 123 135Int J CARS becoming more relevant. The MIDG stands up for these chal- lenges. Conclusion Data grid technology is an integrative informatics platform has been used in many research arenas for organizing and sharing large datasets among collaborating institutions. Pre-clinical molecular imaging facilities can become imaging cores within a multi-disciplinary research community, such that medical investigators, basic sciences researcher, andmedical imaging engineers can discovery, contribute, and manage preclinical molecular imaging data remotely. In this paper, we presented the Molecular Imaging Data Grid todemonstrate a novel method for archiving and disseminat-ing preclinical molecular imaging data. A multi-modality data model was dened, and the system architecture of the Molecular Imaging Data Grid was presented. We are inthe process of deploying a three-site research test-bed within the University of Southern California to evaluate the Molec- ular Imaging Data Grid system based on data provided bythe USC Molecular Imaging Center. Initial evaluation has been performed in VMware environment to measure quanti- tative performance times for archiving and retrieving imag-ing study datasets from the Molecular Imaging Data Grid.By building upon features and services of grid technology, and DICOM imaging standards and IHE workflow proles, the accessibility of disparate animal-model molecular imag-ing datasets by users outside a molecular imaging facility's LAN can be improved. Productivity of research for transla- tional sciences investigators are thereby improved throughstreamlining experimental dataflow. Acknolwedgments The contributions to this work by the rst author was made possible by funding from the NIH National Institute of Bio- medical Imaging and Bioengineering T32 Training Grant #EB004308.The contents of this publication are those of the authors and do notnecessarily represent the ofcial views of the NIH. We would also liketo acknowledge Mr. Bihui Liu for his help in performing preliminarysystems evaluation at the IPILab. References 1. de Kemp RA, Epstein FH, Catana C et al (2010) Small animal molecular imaging methods. J Nucl Med 51(Suppl 1):S18-S32.doi:10.2967/jnumed.109.068148 2. Jakobovits R, Soderland S, Taira R et al (2000) Requirements of a web-based experiment management system. AMIA Annu SympProc, pp 374-378 3. Molecular imaging in living sub- jects: seeing fundamental biological processes in a new light. Genes Dev 17(5):545-580. doi: 10.1101/gad.10474034. Yang J, Yang M, Arabnia H, (2008) Genomics, molec- ular imaging, bioinformatics, and bio-nano-info integration Imaging Center, Department of Radiology, Keck School of Medicine, University of Southern California, Los Angeles, CA,http://mic.usc.edu . Accessed 20 June 2010 6. Szymanski J (2008) An integrated informatics infrastructure for pre-clinical research-IT support, unpublished thesis (PhD), CaseWestern Reserve University 7. Peng H (2008) Bioimage Informatics: a new area of engineer- ing biology. Bioinformatics doi: 10.1093/ bioinformatics/btn346 8. Anderson N, Lee E, Brockenbrough J et al (2007) Issues in bio- medical research data management and analysis: needs and bar-riers. J Am Med al (2005) Small ani- mal imaging center design: the facility at the UCLA crump institutefor molecular imaging. Mol Imaging Biol 7(6):393-402. doi: 10. 1007/s11307-005-0015-2 10. Yang Y, Tai YC, Siegel S (2004) Optimization and performance evaluation of the microPET II scanner for in vivo Trends Cell Biol 19(11):656-660. doi: 10.1016/ j.tcb.2009.08.007 12. Foster I, Kesselman C (1999) The grid: blueprint for a new comput- ing infrastructure. Morgan Kaufmann, Massachusetts, pp 259-278 13. Huang HK (2008) Utilization of medical imaging informatics and biometrics technologies in healthcare delivery. Int J CARS 3:27-39. doi: 10.1007/s11548-008-0199-4 14. Huang HK, Zhang A, Liu BJ et al (2005) Data grid for large-scale medical image archive and analysis. Proceedings of the 13th ACMinternational conference on multimedia. pp 1005-1013. doi:10.1145/1101149.1101357 15. Foster I, Kesselman C, Nick J, Tuecke S (2002) The physiology of the grid: an open grid services architecture for distributed systemsintegration. Globus. http://www.globus.org/alliance/publications/ papers/ogsa.pdf . Accessed 17 July 2009 16. DICOM Standard. http://medical.nema.org/ .A c c e s s e d1 4A p r i l 2010 17. Globus Toolkit (2006) Data Management: Key Concepts. Glo- bus. http://www-unix.globus.org/toolkit/docs/4.0/data/key/index. html. Accessed 18 September 2009 18. Estrella F, Hauer T, McClatchey R et al (2007) Experiences of Engineering Grid-based Medical Software. Int J Med Inform Vmware, M (2007) Biomedical informatics and health- European IEEE Eng Med Biomedical Informatics Research Network (2009) About: view. http://www.birncommunity.org. Accessed 20 October 2009 22. Flanders AE (2009) Medical image and data sharing: yet?. RadioGraphics 29(5):247-1251. doi: 10.1148/rg.295095151 (ePR) system for Image- Assisted Minimally Invasive Spinal Surgery Jorge Documet1, Anh Le1, Brent Liu1, John Chiu2, and HK Huang1 1 IPILab, Department of Radiology, Keck School of Medicine, University of Southern California, 1450 San Pablo Street, Suite DEI 2100, Los Angeles, CA 90033, US, Tel: 323-442-7057, Fax: 323-442-7021 2 California Spine Institute Medical Center Inc, 1001 Newbury Road, Thousand Oaks, CA 91320, US Abstract Purpose\u2014This paper presents the concept of bridging the gap between diagnostic images and image-assisted surgical treatment through the development of a one-stop multimedia electronic patient record (ePR) system that manages and distributes the real-time multimodality imaging and informatics data that assists the surgeon during all clinical phases of the operation from planning Intra-Op to post-care follow-up. We present the concept of this multimedia ePR for surgery by first focusing on Image-Assisted Minimally Invasive Spinal Surgery as a clinical application. Methods\u2014Three clinical Phases of Minimally Invasive Spinal Surgery workflow in Pre-Op, Intra- Op, and Post Op are discussed. The ePR architecture was developed based on the three-phased workflow, which includes the Pre-Op, Intra-Op, and Post-Op modules and four components comprising of the input integration unit, fault-tolerant gateway server, fault-tolerant ePR server, and the visualization and display. A prototype was built and deployed to a Minimally Invasive Spinal Surgery clinical site with user training and support for daily use. Summary\u2014 A step-by step approach was introduced to develop a multi-media ePR system for Imaging-Assisted Minimally Invasive Spinal Surgery that includes images, clinical forms, waveforms, and textual data for planning the surgery, two real-time imaging techniques (digital fluoroscopic, DF) and endoscope video images (Endo), and more than half a dozen live vital signs of the patient during surgery. Clinical implementation experiences and challenges were also discussed. Keywords ePR; System Integration; Pre-; Intra-; and Post-Op Surgical Workflow; Minimally Invasive Spine Surgery 1. Introduction 1.1 Bridging the Gap between Diagnostic Images and Surgical Treatment This paper presents the concept of bridging the gap between diagnostic images and image- assisted surgical treatment through the development of a one-stop multimedia electronic patient record (ePR) system that manages and distributes the real-time multimodality imaging and informatics data that assists the surgeon during all clinical phases of the operation from planning Intra-Op to post-care follow-up. We present the concept of this multimedia ePR for surgery by first focusing on Image-Assisted Minimally Invasive Spinal Surgery as a clinical application. For this particular surgical procedure, in addition to images, clinical forms, waveforms, and textual data for planning the surgery, two real-time imaging techniques (digital NIH Public Access Author Manuscript Int J Comput Assist Radiol Surg . Author manuscript; available in PMC 2010 May 1. Published in final edited form as: Int J Comput Assist 137fluoroscopic, DF) and endoscope video images (Endo), and more than half a dozen live vital signs of the patient during surgery are needed to assist and monitor the surgery. All these data have to be acquired, displayed and archived in real-time as well. 1.2 Minimally Invasive Spinal Surgery Back and neck pain is the price human beings pay for poor posture, prolonged sitting, lifting, repeated bending, obesity, and injury from accidents. This ailment gives the United States with a massive economic headache. Approximately 85% of inhabitants of the Western world are afflicted with some degree of back or neck pain at some point in their lives [ 1]. About 25% of our population has been incapacitated for two weeks or more due to back pain and an estimated 8 to 10 million people have a permanent disability from it [2,3,4,5]. The economic impact is obvious. In most cases, simple treatments such as bed rest, exercise, physiotherapy, and pain medication bring relief. Many sufferers are not so fortunate. If one or more of their vertebral discs ruptures and presses on nerve roots, the pain radiating from the back or neck and down the limbs can be incapacitating and severe. Until recently, the only treatment was surgical removal of part of the ruptured disc, a major operation that required general anesthesia, the dissection of muscle, removal of bone, manipulation of nerve roots, and, at times, bone fusion. In an effort to overcome the disadvantages of traditional surgical techniques, the scientific medical community began exploring the use of endoscopy (arthroscopy) for Minimally Invasive Spinal Surgery surgical operation [6,7]. An endoscope provides clear visualization and magnification of deep structures in real-time. With the advancement of scientific technology and miniaturization, including fiber optics, video imaging technology, laser treatment and experience gained through minimally invasive spinal surgery, there is a less traumatic discectomy procedure for some patients with disc problems. In the recent years, development of image-assisted surgery has improved the precision and reduced surgical tissue trauma. Figure 1 depicts the cervical, thoracic and lumbar spines on MRI before (Pre-Op) and after (Post-Op) the endoscopic-guide spinal discectomy. The lesion(s) at each spinal region is clearly cured after the surgery. 1.3 Rationale for a multimedia ePR System for Image-Assisted Minimally Invasive Spinal Surgery Minimally Invasive Spinal Surgery will be the method of choice for future spinal surgery to treat cases of herniated lumbar discs, post fusion junctional disc herniation, neural compression, stenosis, vertebral compression fractures, spinal tumor, synovial cysts and other types of spinal traumas. Despite the overall advantageous and benefits of Minimally Invasive Spinal Surgery compared to conventional open spinal surgery, there are challenges remained in Minimally Invasive Spinal Surgery including 1) Integration of Pre-, Intra-, and Post-Op surgical data from scattered data acquisition systems; 2) Overcoming the difficulty of real-time data collection during the surgery; and 3) Improving the efficiency of surgical workflow. An integrated real-time multi-media ePR system is an ideal solution to overcome these challenges. If successful, it will take Minimally Invasive Spinal Surgery to a higher level of excellence by combining surgical expertise in minimally invasive spinal surgery with the frontier advancements in imaging informatics. 1.4 The Goals of the ePR The two goals of this research development are: 1.To develop a totally integrated multi-media ePR system for image-assisted minimally invasive spinal surgery. All data collected for the patient from Pre-Op, Intra-Op and Post-Op will be acquired, displayed, and archived during each clinical phase of theDocumet et al. Page 2 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 138surgical workflow. Any data record of the patient in the ePR can be retrieved instantaneously anytime and anywhere. 2.To deploy the ePR at a clinical site for daily clinical use. Figure 2 depicts the ePR prototype system running at the Minimally Invasive Spinal Surgery Operating Room (OR) of a clinical site, with two large LCDs (liquid crystal display), one for the Pre- Op consultation integrated display, and the second for the Live Intra-Op integrated display. 2. Materials and Methods 2.1 General Minimally Invasive Spinal Surgery Workflow The Minimally Invasive Spinal Surgery current high-level operation workflow includes pre- surgical consultation, pre-operation preparation, intra-operation image and vital signs acquisition and display, post-surgery documentation to patient recovery monitoring. The workflow can be broken down into three phases [8,9]: 1) Before surgery; 2) During surgery (including the preparation) 3) Post surgery. Each of the three clinical phases will be discussed below. 1.Before surgery (Pre-Op): This phase is the workflow involved prior to the actual surgical procedure. In the Pre-Op workflow, usually the patient presents with a problem and is evaluated by the physician to determine whether Minimally Invasive Spinal Surgery is needed and whether it would be helpful to the patient. If this case is true, then a procedure is scheduled. At this stage the surgeon or surgeons in combination with the physician assistant plan the surgical procedure using digital diagnostic images such as CR, CT and MRI. In addition to the information obtained from the medical studies, the patients also fill out a set of surveys that determine the level of pain that they feel. 2.During surgery (Intra-Op): During the surgical procedure, the surgeon(s) operate on the different disc(s) that need to be corrected. While operating, there is a significant amount of data being acquired that help monitor the body response of the patient to the procedure. This includes video and image data acquired with the endoscope. A single vertebrae procedure usually lasts 30 minutes on average. 3.After surgery (Post-Op): During this Phase the patient recovers from surgery. The patient is continuously monitored in the recovery area to assure all vitals signs are stable. In addition, a set of tests are also performed to assess the outcome of the surgical procedure which includes an additional set of forms that the patient fills out. The recovery period after surgery lasts from 45 minutes to one hour. The patient is then discharged. Therapy can begin the next day and the patient can go back to work within 2 to 3 days. 2.2 Data Model of ePR System The data model of the ePR for Minimally Invasive Spinal Surgery has been designed to extend the DICOM data model due to the similarities that exists for medical imaging data at CSI utilizing DICOM. From the DICOM data model the ePR for Minimally Invasive Spinal Surgery follows the relationship between the patient, the medical studies, series and images. The modified data model utilized for the current ePR contains additional entities that describe the data required for Minimally Invasive Spinal Surgery. These new elements that are added to the data model include the surgical procedure type, waveforms, the key image, survey forms for pain, and user information for access to the system. The data model is shown in Figure 3.Documet et al. Page 3 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 1392.3 The ePR Dataflow The initial Data flow utilized by the ePR system was based on the concept of the workflow presented in the General Minimally Invasive Spinal Surgery workflow and is shown in Figure 4 where each numeral represents a dataflow event. There are three time phases, from the top down: the Pre-Op Image/Data module, the Intra-Op module, and the Post-Op module. Each of these modules contains four components: input module, input gateway, ePR server, and the visualization and display module. 2.3.1 Pre-Op Workflow\u2014 Following Figure 4, 1.Historical medical imaging studies in DICOM format are acquired from the PACS (Picture Archiving and Communications System). 2.The Gateway, which is a component of the ePR system, receives the DICOM images and processes them accordingly. The original image is kept in the ePR and a JPEG version is utilized for display purposes via the web interface of the ePR. All DICOM header information and metadata are extracted and recorded in the database. 3.Pre-Op authoring is performed by the surgeon(s) and the physician assistants. The surgical procedure information is entered into the ePR. At this Phase the patient's survey pain forms are also entered into the system. The surgeon selects some key images and authors annotations overlaid on the key images that will ultimately be utilized during surgery. The authorized images/data are displayed in the OR utilizing a 52-inch LCD display (see Figure 1). 4.Authorized images/data are the , 6 and 7The Integration Unit (IU) is connected to all clinical devices in the OR and continuously gathers live data signals from them during the entire surgical procedure, and display them in real-time on the second large 52-inch digital display (see Figure 1). 6The Gateway Server receives the data from the IU and stores the data values and images in real-time at the database within the ePR system. 2.3.3 Post-Op Workflow 8While the patient is in the recovery area, the system continues gathering some vital signs that are transferred to the Gateway Server. 9The Gateway Server receives the data and stores the data into the database of the ePR system. 10The surgeon uses the Post-Op authoring module to create a final report out of the data gathered during the pre-, intra-, and Post-Op Phases. 11The final report will be kept in digital format at the ePR Server as the patients' permanent surgical record. 2.4 Minimally Invasive Spinal Surgery ePR System Architecture Recalling Figure 4 which depicts the workflow and data flow model of the Minimally Invasive Spinal Surgery ePR system represented by a 3 \u00d7 4 dimension matrix model. The three rows are Pre-Op, Intra-Op, and Post-Op workflow process Phases; and the four columns are the input data integration unit (IU), input gateway, ePR server, and Image/Data display. From theDocumet et al. Page 4 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 140system architecture point of view, the ePR system should be designed for efficiency, effectiveness, and reliability of system operations. The fault-tolerant requirement of each component in the system is designed to support other existing components of the system for easy system back-up and cost containment. The ePR System architecture is shown in Figure 5 below and will be discussed in detail in the following paragraphs. 2.5 Four Major Components in the Minimally Invasive Spinal Surgery ePR System The four major components in the Minimally Invasive Spinal SurgeryePR System are: 1) Integration Unit (IU); 2) Fault-tolerant Gateway server; 3) Fault-tolerant ePR Server, and 4) Visualization and Display. Both the Input Gateway and the ePR Server include data storage and archive, system database, system security, system fault-tolerance, continuous availability and failover. The GUI and display module resides within the ePR Server. All data input systems like medical imaging, surgical video, vital signs waveform recorders, and textual data recorder generate Pre-Op, Intra-Op, and Post-Op data, and they are all categorized as input data. The imaging and data systems that generate information are existing peripheral surgical supported equipment already within the OR but they do not belong to the Minimally Invasive Spinal Surgery ePR system. However, the ePR system must integrate these devices in order to receive the input data that is acquired before, during, and after surgery that support the surgical procedure. 2.5.1 Integration Unit (IU)\u2014 This component is responsible for acquiring all data from different peripheral devices that are presented in the OR during surgery (Intra-Op) that continuously measure all live vital signs, waveform signals, and surgical related images of the patient undergoing a procedure. The data acquired by the IU from all input devices are synchronized through a master clock and displayed live onto a customized interface using a 52 LCD (Liquid Crystal Display) screen (called Intra-Op Live Display) in the OR. The data gathered during surgery include the following: - Digital C-ARM fluorographic images - Digital EMG (Electromyography), BIS (Bispectral Index), and Vitals (Blood Pressure, Heart Rate, Respiratory Rate, PulseOX, Body Temperature and Partial Pressure of Carbon Dioxide). The images, videos and data points mentioned above are transferred automatically and continuously from the various input sources of the different data devices in the OR during operation that are attached to the data input IU. The data is immediately saved into IU memory. The IU software displays the waveforms, images, and streamed videos properly every second (which is a default value) on the large Intra-Op LCD, and also makes a copy from the memory to the IU local hard drive with 1.5 TB (Terabytes) of storage space every five seconds (which is also a default value). These two default values can be adjusted interactively depending on clinical demands. Normal procedures for a single vertebra surgery take about 30 minutes on average. This Intra- Op data is sent continuously to the Gateway where the images are processed if needed and then placed in a data folder shared with the ePR server where they will be permanently archived. The data values are also extracted and saved to the ePR system database. In addition to the one second input display refresh-rate described in the last section, the IU features a rule-based alert- mechanism that checks each input waveform for data that is out of the normal range. The IU has a set of rules based on clinical accepted medical practice that determines when a given signal is considered within the normal range for a patient. If at any given time during the surgical procedure, a signal falls outside the safe range, the IU will trigger an alert message on the Intra-Documet et al. Page 5 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 141Op Live display. This assists the surgeon and key personnel in the OR to take necessary actions during the surgical procedure. It is noted that the default values might not be considered normal for all patients; thus, during the Pre-Op patient consultation time, these default values can be revised and properly adjusted as necessary. 2.5.2 The Fault-tolerant Gateway server\u2014The functions of the Input gateway are receiving, staging, managing, and transferring input data during the three clinical workflow phases of the surgery: Pre-Op, Intra-Op, and Post-Op. Pre-Op Phase: The gateway receives DICOM images and diagnostic reports from PACS. Once images are received by the gateway, a Pre-Op script is automatically launched by the gateway to properly extract all the information from the headers of the DICOM files. This data is then saved into the database. This whole process is automated at the gateway and does not require any user intervention. Intra-Op Phase: During Intra-Op, the gateway receives live data from the IU using an API (Application Program Interface). The transfer protocol used is the HTTPS (HyperText Transfer Protocol Secure) Standard. Before any data is sent to the Gateway, the IU needs to properly authenticate itself in order to avoid conflict with other possible input devices. Once the data is received by the Gatewayserver, the API will place the data in a specific location in the ePR where a script will be executed to process the data accordingly. Post-Op Phase: During Post-Op, the patient is under observation in the recovery area by a nurse and the surgeon. The vital signs and other monitoring equipment are used to evaluate the patient PostOp condition. During the 45 minutes to one hour observation, live data of the patient is continuously received and displayed at the bedside monitor by the Post-Op module. 2.5.3 The Fault-Tolerant ePR Server\u2014The ePR Server is the heart of the Minimally Invasive Spinal Surgery ePR System and is the front-end of the system where the users will login to perform all the necessary tasks during the surgical workflow. The ePR Server allows access to the Pre-Op authoring module, the Pre-Op display in the OR and the Post-Op authoring module (see Figure 5). Administrative tasks such as giving the users access to the system, registration of patient information, scheduling, among others are also included. The ePR by definition allows the participants to obtain any necessary information about the patient from a single interface, i.e., the information follows the patient. The ePR not only shows information about the medical examinations for the patients, but also any other related data such as clinical history and pain surveys acquired during the surgical procedure. The ePR is developed utilizing PHP (PHP: Hypertext Preprocessor) as the backend programming language. The data values are stored using a MySQL database [10]. The web pages are structured with HTML (Hyper Text Markup Language), and they are styled using CSS (cascading style sheet). The interfaces are dynamically updated using JavaScript. The web server utilized is Apache 2.2 [ 11]. Data Storage and Archive and System Database: Managing the data acquired by the ePR system is a critical task. Therefore, a dual-system back-up mechanism is implemented as follows. First, the ePR server has the server hardware, and the Gateway has the Gateway hardware. Two identical server software packages are implemented, one in the ePR server hardware as the primary and the other in the Gateway hardware as the back-up. By the same token, two Gateway software packages are implemented, the primary package is in the Gateway hardware, and the secondary package is in the ePR Server hardware as the back-up. Refer to the middle row of Figure 5, the Gateway and the ePR server each has its own hardware, whereDocumet et al. Page 6 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 142each hardware piece is housing both the ePR server software and the Gateway software; one is the back-up of the other. Figure 6 shows the dual-system backup mechanism. The input data first comes to the Gateway hardware, where the Gateway software categorizes them by images, live waveform information, and textual information. Images include DICOM images in their original DICOM format as well as in JPEG format for web display; as well as endoscopic videos, endoscopic single frame images, and digital C-arm fluoroscopic images. The metadata in the DICOM images and other data are stored in the database disks. All acquired data and metadata are immediately backed up by the ePR Server hardware. System Security: The system security has been considered carefully during the design in order to comply with the HIPAA (Health Insurance Portability and Accountability Act) requirement. Only the users who have been granted permission are allowed access to the system. At the same time the privacy of the communications are kept to avoid any non-authorized receiver to obtain a given patient's private information. To guarantee the security of the data, web access to the ePR is established with HTTPS that encrypts all communication between the server and the clients (web browsers). In addition, the ePR system handles permissions that will allow users to perform different tasks on the system. Different user groups in the system have a different set of enabled permissions, however, permissions can be overwritten for individual users by the system manager if necessary providing a greater level of flexibility. System Fault-Tolerance and Continuous Availability and Failover: The information that is kept in the ePR is unique and cannot be obtained from any other sources if lost. To overcome any possible loss of data, a fault-tolerant solution that replicates the data of the ePR to more than one place has been implemented. The primary Gateway serves as the backup for the primary ePR server, and vice versa. In addition to having the data being stored with more than one copy, system redundancy with automatic failover mechanism has been designed to access the data in case of the failure of any component in the system to guarantee system continuous availability. 2.5.4 Visualization and Display\u2014 The last of the four components in the ePR System is the Graphic User Interface (GUI) and Display. In order to have the ePR system to be utilized as an effective tool that can improve the workflow of the Surgery Department, it is important to have a user-friendly GUI that presents all necessary contents for the surgery in an easy to use manner. For this reason, the ePR system is designed with this concept to achieve this goal. Because the entire ePR system operates in three interrelated Phases during a surgical procedure, from planning (Pre-Op), to surgery (Intra-Op), to patient recovery (Post-Op); the interface design between these three Phases are critical. The Display interface design (see Figure 5) includes the main page, the Pre-Op display at the patient consultation room, the Pre-Op display at the OR, the Intra-Op display at the OR, the Post-Op at the patient recovery area, the Post- Op at the OR for surgical documentation, and the administrative pages. 2.5.4.1 Pre-Op Authoring Module: The Pre-Op Phase of a Minimally Invasive Spinal Surgeryprocedure is where all necessary information prior to the surgery procedure is collected and organized in a patient e-folder. The Pre-Op happens days prior to the surgery and involves querying, interviewing, collecting, and storing of pre-surgical medical images, patient demographic information as well as other pertinent data value that would assist the surgery during the procedure. Traditionally, surgeons have been relying on their memory for localization of where the procedure should be performed. They review the MRI and X-Ray images the day before surgeryDocumet et al. Page 7 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 143and studied the approach to be taken during the procedure. These images are also brought to the OR for reference. But they are displayed in hard copy in an unorganized fashion scattered throughout the OR. The next few paragraphs focus on the organization of the Pre-Op patient information which requires a preparation process. This process should not be done during the time of surgery and the information should be saved in advance with the display streamlined and organized for efficiency purposes. Creating a Surgical Procedure in the Pre-Op Authoring Toolkit: The interface allows the users to create the surgical procedures by first selecting the key images as well as adding annotations to those key images as shown in Figure 7. On this screen the PACS image and surgical procedures had been combined into one display in the Pre-Op module. Image studies related to the surgical procedure are shown on the left hand side based on the surgical data model (see Figure 7). To view an image in a study, the users can either drag the study shown on the list from the left to the viewing pane on the right hand side or by double clicking the study from the list on the left. Figure 7 displays a sagittal MRI image with patient's ID above the image. The toolbar with icons at the top of the viewing pane allows the users to perform certain tasks accordingly to the current status of the editing module. 1.To view images in a study: The two icons on both the right and the left sides allow the user to preview images in the study series. 2.To perform image manipulation: The toolbar for the Pre-Op include some basic image manipulation tools such as window/level, pan, and zoom. With this functionality, the images can be displayed optimally at the exact location of the lesion. During a Minimally Invasive Spinal Surgeryoperation, it is important to correlate the axial view with the corresponding sagittal view of an MRI study. The neuro-navigator tool in the Pre-Op module allows such correlation through the display as show in Figure 7. In addition to the input data described earlier, one type of Pre-Op data which is critical during surgery is the hand written whiteboard information located at the entrance of the OR which contains a very short summary of the patient such as name, gender, age, weight, height, any allergies, comorbidity and pain. Normally, the white board should contain all patients' information to be operated during the day. The Pre-Op authoring module described has been designed to integrate the whiteboard information onto the same Pre-Op screen for display in the OR during the surgery. The following survey measures are also included: 1.Visual Analog Scale (VAS): Is a psychometric response scale to describe the amount of pain a patient is feeling from a specific part of her/his body. 2.Oswestry Disability Index: A survey to identify how the pain in the back or legs is affecting the patient in his/her daily activities. The design concept of the ePR system is user-friendly but effective at the same time. For these reasons, the criterion of the user interface is to minimize the number of mouse clicks needed to perform a certain task and to aggregate information adequately into a single interface whenever possible. The current Pre-Op authoring module is a self-contained interface where the users can download, edit, add, and delete the contents as needed. The Pre-Op has two major interfaces, one for editing and one for display in the OR. Pre-Op Display: A Minimally Invasive Spinal Surgeryprocedure requires multimedia data during the Pre-Op Phase including patient history, images, and consultation results. These data should be organized and displayed in the Pre-Op display during surgery. An example is shown in Figure 8 which depicts the general patient information (first top row), whiteboard information outside of the OR (second top row), as well as the key images selected from the MRI study with their annotations during consultation (center). The term that is used for thisDocumet et al. Page 8 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 144display is the Pre-Op Display since the Pre-Op authored data is actually displayed during the Intra-Op workflow Phase. 2.5.4.2 Intra-Op Live Display: Figure 9 shows a mock up example of the Intra-Op Live Display with waveforms and images. The horizontal axis is time. The stream from the vital signs device is displayed at the top row (left) and to the right there are five groups of waveform: three vital signs with blood pressure, pulse oxygen concentration and pCO2, as well as BIS, IVF (Intravenous Fluid). Every dot in the waveform represents a data point over a one second interval. In the middle row, there are two images, the C-Arm fluoroscopic (right) and the endoscopic video images (middle), and one EMG waveform in the left. In the lower row, there is laser energy in joules. The video is updated on the Intra-Op Live Display with a frame rate of 30 per second (a default value). Rule-Based Alert Mechanism: If a signal falls outside ipts safe range a three stage mechanism will alert personnel in the OR about that situation. 1.Warning mode: If the numeral falls outside the safe range it will change its color to red (as seen with the PulseOX and Blood Pressure in the figure) 2.Emergency mode: If the condition falls to a value greater or lower in 25% of the safe range then the Intra-Op Live Display will place an alert message on top of the screen. 3.Critical mode: If the data signal value is either greater or lower in 50% to the values in the safe range then the alert message will cover the whole screen. 2.5.4.3 Post-Op Module: The Post-Op Phase takes place after the completion of the surgical procedure, normally, the next several days after the surgery. There are three time substages: 1) Patient in the recovery area and then discharged, 2) the Surgeon documents the surgical results, and 3) follow up pain surveys after Post-Op for several months. Post-Op Authoring Toolkit: When the surgeon performs Post-Op documentation, he/she can retrieve information from the Post-Op module pertinent to the surgery using the GUI. This process involves four major steps: 1.Finding the Patient from the ePR System. The correct patient can be located from the ePR via the worklist. 2.Selecting images. From this GUI, the surgeon can select endoscopic images that will be included in the final report by clicking the star at the top left corner of the viewing pane. As shown in Figure 10, that image has been selected for the final report. 3.Selecting Waveforms. The waveforms are displayed at the bottom of the GUI (Figure 10). They can be dynamically selected by clicking their corresponding boxes on the upper right side of the interface. 4.Data Synchronization. A slider at the bottom of the graph (green pointer in Figure 10) would allow for synchronized viewing of all the image and waveform data being displayed. The data that was displayed and selected for documentation in Figure 10 includes a C-Arm fluoroscopic X-Ray image, heart rate, diastole and systole blood pressures, respiratory rate, BIS score value, oxygen pressure and partial pressure of carbon dioxide. The curve shown at the bottom of Figure 10 (Heart Rate) is a waveform obtained from another Intra-Op device. Figure 10 shown contains real-patient data with anonymized acquisition date and time and patient demographics.Documet et al. Page 9 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 145Nurses and Front-desk personnel perform surveys several times after the surgery and enter the pain surveys data into the Post-Op module of the ePR system as a follow-up of the progress of the patient. The collective information can be used for future patient outcome analysis. 3. Results 3.1 Clinical Site for Developing and Implementing the Minimally Invasive Spinal Surgery ePR System The design and implementation has been in collaboration with the California Spinal Institute (CSI), Thousand Oaks, CA. CSI is a full self-sufficient independent spinal surgery institute and performs between 5 - 10 minimally invasive spinal surgeries per week. It has its own diagnostic imaging facility including conventional X-rays, CT and MRI services and a commercial PACS. CSI also provides patients with the full in-house services for spinal surgery from Pre-Op consultation to Post-OP evaluation, check-up and therapy. The concept of developing the multi-media ePR system for image-assisted Minimally Invasive Spinal Surgery was conceived five years ago but technologies were not available until recently [9]. The go head development decision was made in early 2007. Many parameters used in the design were based on daily clinical experiences at CSI during the past five years. The ePR system can be modified for Minimally Invasive Spinal Surgery operation at other similar healthcare facilities, and image-guided surgery OR's (Operation Room). 3.1.1 System Deployment\u2014The prototype system was deployed in August, 2008 to the California Spine Institute (CSI) located in Thousand Oaks, California, which is the only clinical site in Southern California that performs Minimally Invasive Spinal Surgery. This site served as an initial approach to understand the general workflow of the surgical procedure. Because the goal of the system is to be able of being installed in other locations, the workflow and implementation was kept in its more general instance, avoiding any specific-related design for CSI. In the case that a particular part of the implementation was tailored for this site, the options were configured to be flexible. The customization of the modules used in the ePR will allow having the system implemented in different locations where other vendors are used. This section summarizes the highlights. Planning and design phase: The ePR system for Minimally Invasive Spinal Surgerywas developed at the IPILab, USC. IPILab and CSI have had close collaboration for more than five years. There are three phases of the implementation. First, to test the functionality of the ePR system, a prototype for each of the ePR components was developed and integrated at the CSI research facility; in addition, mockup data was collected at CSI that included an Intra-Op signal simulator for the IU device. Second, once the system was tested fully in the laboratory environment, it was then deployed in the OR to obtain user feedback and clinical evaluation. The hardware and software components consist of the Gateway Server, the ePR server, and the IU. In addition, other software packages include the ePR web pages, the IU application, the database, and the web server. The final stage of the clinical implementation was to deploy the ePR system in the OR. This stage has been challenging, since the OR is continuous in use for Minimally Invasive Spinal Surgery, both the clinical team and the engineering team have to work together to circumvent the clinical schedule minimizing the risk of any possible disruption of the clinical service through coordinating of various tasks among the teams member; this is especially true in the final stage of implementation, when the ePR has actually been used taking care of some regular duties usually reserved by the traditional surgical method.Documet et al. Page 10 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 146Hardware installation: The ePR and Gateway servers were installed at CSI on a rack at their Server Room. Figure 11 shows the installation in progress and the final location of those servers. In addition to the two servers above, the IU was also installed in one of the ORs at CSI. The IU needs to be connected to all required peripheral devices that are presented in the OR for monitoring the real-time patients' response during the clinical procedure. The IU, located in the OR, and its connection to input devices are shown in Figure 12. Software installation: Once the servers were installed at the clinical facility, the next step was to configure all necessary software components of the ePR system. Those components include: 1. ePR server: The server requires the installation of the web server (Apache) and the database (MySQL). 2. Gateway server: Composed of a software DICOM listener that receives incoming DICOM studies sent from the PACS and a set of scripts to extract the metadata information and store it at the database. 3. Integration Unit: Software developed in C++ is utilized to make low level system calls to the different interfaces depending on performance requirements to display real-time data in the OR. Training and Support for Clinical Users: The following users were among those trained for the use of the ePR system: 1. Surgeons: They received training on the Pre- and Post-Op authoring modules. In addition, they were taught to properly interpret the two large Pre-OP and Intra-Op LCD displays. 2. Physician Assistants: They were involved in both group and individual training sessions for Pre-Op authoring module. 3. Nurses: They were trained to properly enter information related to the patient's whiteboard data and survey forms. 4.Front-desk assistants : They received training for scheduling of surgical procedures, input of pain surveys for Pre-Op and Post-Op Phases as well as patient registration. 5. Technicians: The training given to them was on how to correctly understand the data presented at the LCD monitor displays at the OR. 6.Administrative staff: They were given training on how to add or remove a user from the ePR system and to manage the permissions for the different user types or a specific user as well. The engineering team provided three months on-site baby-sitting of the ePR system as well as assisted the duty staff to prepare Pre-Op module. Figure 13 shows a typical training session. Clinical Implementation of the Post-Op module is currently ongoing. 3.1.2 Clinical Implementation Experiences 1.The implementation phases were planned based accordingly on the three workflow stages to provide a good understanding of the features included in the ePR System and at the same time to address any positive feedback from the users. Phase one implementation was included the Pre-Op authoring and display toolkit as well as general ePR features such as worklist navigation and DICOM Query/Retrieve. Phase two implementation included the Intra-Op display as well as the Pre-Op display onDocumet et al. Page 11 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 147large LCD monitors. Finally, phase three included the Post-Op authoring and display toolkit and is currently undergoing training sessions. Since the ePR System was installed in August 2008 at CSI, every surgical operation has utilized the Pre-Op Display module within the OR. This is a direct result of the clinical staff performing the Pre-Op authoring one day prior to surgery. In the same amount of time, the Intra- Op live display has been used to show a centralized view of all the data obtained from peripheral devices. Data captured from the IU module is currently stored in the ePR System automatically since May 2009. 2.Even though there was no formal evaluation from the users' training, all the people that were trained had been using the ePR with no major complaints. After a one year clinical operation with sufficient and meaningful data collected, a more formal user acceptance survey will be conducted targeted for a follow-up clinical experience paper. 3.The chief surgeon who is one of the architects of this system has monthly meeting with the ePR team to provide suggestions, input and user experience for system refinement and upgrades. He has been the champion of the project. 3.1.3 Next steps in Research and Development Prototype version 2 for Integration Unit: The Integration Unit (IU) is a very critical component in the ePR system, but at the same time is very complex and needs to be refined to satisfy the ePR System requirements. The prototype version 2 of the IU has been designed to provide continuous availability, improve the performance for data collection, visualization and storage with expanded flexibility in order to support a larger set of devices and configurations. Difference between current version and the version 2 of the Integration Unit: The main difference between the two versions of the Integration Unit is the capability of handling fault tolerance and continuous availability: the first prototype of the IU did not provide any fault tolerance. The second prototype provides fault tolerance by adding a second set of key pieces from the IU. This is similar to what have been done to the PACS [ 12]. Among the pieces added are: more robust UPS (Uninterruptible Power Supply); NAS (Network Attached Storage) for storage; the main processing unit is provided by means of two identical clustered blade servers. In case of any failover the recovery is done automatically. In addition, the second prototype is assembled in a self-contained mobile cart that enhances the flexibility for implementation in different environments. At the same time the second prototype has increased the number of ports to include more peripheral devices present in the Operating Room. The software that acquires, displays, and stores the data also requires an update to handle the new infrastructure for the second prototype. Upon completion of the second prototype, one copy will replace the existing first prototype within CSI and the second copy will be deployed at a second clinical site to be determined. 4. Discussion 4.1 Lessons Learned Much of the experience gained and many lessons learned in developing the multi-media ePR for Image-Assisted Minimally Invasive Spinal Surgery are similar to that of early times when PACS was developed and deployed in radiology departments, and later to hospitals. However, there are some differences due to the fact that ePR users are mostly local and not hospital-wide. Among these, are listed in the following as well as any comments on the differences and similarities between them whenever appropriate.Documet et al. Page 12 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 1481. Lack of standards from peripheral data and imaging devices used in the OR. This was the major obstacle during the implementation phase. There are many vendors who sell peripheral devices to ORs where no data format or communication standard compliance is required. Different vendors export their data in different ways, adding complexity to the mechanisms for data retrieval and limiting the interoperability to certain vendors and products. In imaging, most ORs still use Pre-Op hardcopy for reference during the surgery. For image-assisted surgery, the Intra-Op endoscopic and C-Arm radiographic images are for assisting the surgeon during the surgery, and there is no requirement for keeping hard or soft copies for surgical document. The multi- media ePR system for Minimally Invasive Spinal Surgery, on the other hand, keeps all live data during the surgery in the database, they will be selected by the surgeon to include in the patient report during Post-Op authoring. Therefore, it had been a major challenge for acquiring data from real-time peripheral devices as well as images from endoscope and C-Arm radiography in the OR during surgery. In PACS installation, similar problems were encountered in imaging modalities connectivity, but this issue was resolved by the mandated compliance to DICOM standard in almost all the purchases in imaging systems and PACS in the late 1990s. The development of the Integration Unit (IU) in the ePR system prototype is the first step allowing all devices to be integrated. We anticipate several years down the road, surgical OR may see the advantages of data integration in the ePR and enforce vendors to output data with certain standards. 2.The clinical environment was different from the laboratory environment. When the ePR prototype was moved from the laboratory environment to the clinical site, the engineering team encountered a culture shock. In the former, the laboratory environment was under control and debugging and modifications could be performed easily. Whereas in the latter, the reality of the real world sank in, and it was very difficult to make modifications for two reasons: 1) Once the ePR was installed, the clinical use of the system has always been with the highest priority, any modifications were secondary, 2) Users were reluctant to continuously adopting new changes. Unlike PACS installation which has long passed this R&D mode, nowadays a prototype system would be rarely installed in the clinical site without extensive test at the manufacturer site first. 3. The Clinical institution was not always in control of its computer and ICT (Information and Communication Technology) equipment . Installing new applications in clinical computers might sometimes require administrative privileges. In addition, configuring and adding new servers to CSI might need to be performed by a third party IT (Information Technology) team that could cause implementation issues. This issue would be encountered in many PACS installation as well. 4. User Acceptance. Whenever a new application in the ePR was implemented at CSI, users might be reluctant to fully embrace the new application. It is because it would temporarily disrupt their normal routine clinical workflow even if the system would ultimately improve their clinical workflow in the long run. The user acceptance is easier in PACS now since the healthcare community has gained more than 15 years of experience. 5.Graphical User interface challenging for new users : When a new application was developed, training becomes crucial since users were not familiar with the interface and functionality. This issue is 100% the same as PACS when the user is first time or switches to a new PACS, or a new GUI is installed.Documet et al. Page 13 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 1494.2 Design Principles and Reproducibility 1. The Design principle. The design principles of the ePR system are modularity and reproducibility. The system has three major components, Pre-Op, Intra-Op, and Post- Op, they are operated as a complete system. In order for the Post-Op to function properly, both Pre-Op and Intra-Op have to be operable. In the same token, in order for the Intra-Op to be functional, Pre-Op has to be operable. However, Pre-Op can be used without the Intra-Op and Post-Op in operation. In this case, no data from the Pre-Op would be input to the Intra-Op and Post-Op modules. 2. Reproducibility. The infrastructure of the ePR system is applicable to most image- assisted minimally invasive surgical operation rooms. However, certain customization may be required. For example, different surgical input including images, waveforms and textual data may need new designs for various input device interfaces. The Integration unit (IU) infrastructure has been tested to handle up to a combined total of 12 waveforms data points, imaging inputs and video streaming sources. In addition, the Display format and GUI need to be redesigned to suit various surgical requirements. 5. Conclusion A step-by step approach was introduced to develop a multi-media ePR system for Imaging- Assisted Minimally Invasive Spinal Surgery. First, the clinical need for the Minimally Invasive Spinal Surgery ePR was introduced. Then, the three clinical Phases of Minimally Invasive Spinal Surgery workflow in Pre-Op, Intra-Op, and Post-Op were discussed. The three-phased modules; and the four components: the input integration unit, fault-tolerant gateway server, fault-tolerant ePR server, and the visualization and display component. A prototype was built and deployed to a Minimally Invasive Spinal Surgery clinical site with user training and support for daily use. Finally, special experience gained and lessons learned from developing the system were discussed. This methodology can be extended to other image-assisted minimally invasive surgery. Abbreviations API Application Program Interface BIS Bispectral Index System CO2 Carbon dioxide CR Computed Radiography CSI California Spine Institute CSS Cascading Style Sheet CT Computed Tomography DICOM Digital Imaging and Communications in Medicine EMG Electromyography ePR Electronic Patient Record GIF Graphics Interchange Format GUI Graphical User Interface HIPAA Health Insurance Portability and Accountability Act HIS Hospital Information SystemDocumet et al. Page 14 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 150HTML Hyper Text Markup Language HTTP HyperText Transfer Protocol HTTPS HyperText Transfer Protocol Secured ICT Information and Communication Technology IA-MISS Image-Assisted Minimally Invasive Spinal Surgery IPILab Image Processing and Informatics Laboratory IRB Institutional Review Board IT Information Technology IU Integration Unit IVF Intravenous Fluid JPEG Joint Photographic Expert Group LCD Liquid Crystal Display MB Megabytes mmHg Millimeters of Mercury MRI Magnetic Resonance Imaging OR Operating Room PACS Picture Archiving and Communication System PHP PHP:Hypertext Preprocessor PNG Portable Network Graphics RAM Random Access Memory RIS Radiology Information System RS232 Recommended Standard 232 SC Secondary Capture SDK Software Development Kit TB Terabytes USC University of Southern California VAS Visual Analog Scale VGA Video Graphics Array References 1. Vallfors B. Acute, Subacute and Chronic Low Back Pain: Clinical Symptoms, Absenteeism and Working Environment. Scan J Rehab Med Suppl 1985;11:1-98. 2. Chiu, J.; Savitz, MH. Use of Laser in Minimally Invasive Spinal Surgery and Pain Management. In: Kambin, P., editor. Arthroscopic and Endoscopic Spinal Surgery - Text and Atlas. 2. Humana Press; New Jersey: 2005. p. 259-269. 3. Chiu, Cervical In: Kim, D.; Fessler, R.; Regan, Surgery and New York: Thieme Medical Publisher; 2004. p. 5p. 48-58.Documet et Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript Author Regan, J., editors. Endoscopic Spine Surgery and Instrumentation. Vol. Chapter 19. New York: Thieme Medical Publisher; 2004. p. 212-229. 5. Chiu J, Clifford T, Greenspan M. Percutaneous microdecompressive endoscopic cervical discectomy with laser thermodiskoplasty. JW, Ryken TC, Vanier MW. Image - Guided Surgery of the Spine. J Min Invasive Spinal Tech 2001;1(1):87-92. 7. Jaikumar S, Kim D, Kam A. History of Minimally Invasive Spine Surgery. Neurosurgery Supp 2002 2002;5l2:1-14. 8. Huang, HK. PACS and Imaging Informatics: Principles and Applications. John Wiley & Sons; Hoboken, New Jersey: Mar. 2004 p. 704 9. Huang HK. PACS, Informatics, and the Neurosurgery Command Module. J Mini Invasive Spinal Technique 2001;1:62-67. 10. MySQL AB, Sun Solaris Microsystems Inc. http://dev.mysql.org 11. Apache web server, Apache Software foundation . http://httpd.apache.org 12. Liu BJ, Huang HK, Cao F, Zhou MZ, Zhang J, Mogel G. A Complete Continuous-Availability (CA) PACS Archive Server Solution. Radiographics 2003;24(4):1203-1209. 2004. [PubMed: 15256640]Documet et al. Page Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 152Figure 1. Minimally invasive spinal surgery on cervical, thoracic, and lumbar spines. Upper row: Pre- operation arrows show the areas where the disc protrudes the spine. Lower row: Post endoscopic-assisted spinal surgery shows the lesions have been cured.Documet et al. Page 17 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 153Figure 2. Schematic of the dynamic multi-media ePR system for Image-Assisted Minimally Invasive Spinal Surgery. The ePR prototype system is running at the Minimally Invasive Spinal SurgeryOR of CSI, with two large LCDs (liquid crystal display), one for the Pre-Op consultation integrated display, and the second for the Live Intra-Op integrated display.Documet et al. Page 18 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 154Figure 3. The data model of the ePR system. It extends the schema of DICOM to accommodate surgical information including live waveform and several standard surgical forms. Additional entities have been augmented to the data model.Documet et al. Page 19 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 155Figure 4. Dataflow of the ePR system for Minimally Invasive Spinal Surgery. There are three time Phases (vertical): Pre-Op, Intra-Op and Post-Op; and four operational modules (horizontal): input units, gateway, ePR Server and database, and visualization and display, which forms a 3 \u00d7 4 matrix. Each numeral represents one event in the dataflow explained in the text.Documet et al. Page 20 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 156Figure 5. The ePR system architecture showing three operation phases (first column): Pre-Op, Intra-Op and Post-Op; as well as four operation modules (partitioned and scattered systematically). Some partitioned modules are bundled up together for ease of data transfer and fault-tolerant back-up. The arrows show the data flow during the three phases of operation. The outside light gray color side-way \"U\" band is the Display module backbone with five rectangular box subunits. Inside the opening of the \"U\" in dark gray are the Integration Unit, Fault-tolerant Gateway, and Fault-tolerant ePR Server. Within the Gateway and the ePR Server, the Database and Filesystem software are interrelated and shared by both components.Documet et al. Page 21 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 157Figure The Dual-system back-up Schema with two hardware pieces: ePR Server hardware and Gateway hardware. Each hardware piece has two components of software: ePR Server software, and Gateway software; and a tandem database with hard drive for data and metadata archive.Documet et al. Page 22 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 158Figure 7. (Left - Figure 7A) The Pre-Op authoring module page. The upper left hand text list depicts the surgical data model showing the studies and procedures. After the user clicks an item in the list, the proper image, in this case, a sagittal MRI is shown on the right. (Right - Figure 7B) The Neuro-navigator tool allows the correlation of the position of the lesion in the sagittal (left) and the axial view (right). The red lines are the two corresponding sagittal and axial sections.Documet et al. Page 23 Int J Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 159Figure 8. The Pre-Op display organized during patient consultation as seen on the Pre-OP display monitor in the OR during Intra-OP. Top Text Row: Patient General Information, Second Text Row: Whiteboard information, Bottom row: Images transverse MRI.Documet Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 160Figure 9. A mock-up example of the Intra-Op Live Display as seen on the Intra-Op large monitor in OR. Top row from left to right: Video stream of vital signs and six waveforms coming from three vital signs, BIS and IVF; the horizontal axis is time. Middle row from left to right: Waveform of EMG, endoscopic image and Fluoroscopic image. Bottom row: Laser output values.Documet et al. Page 25 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 161Figure 10. The Post-Op authoring module displaying a patient case showing data acquired during the surgery. The x-axis represent the time, while the y-axis represent the numerical value of the data points. The green mark represents the time frame when this page was captured. This module can be utilized by the surgeon to create an image and waveform Post-Op results document in pdf format. The graph showed at the bottom is the sequence of Respiratory Rate values over the whole procedure time.Documet et al. Page 26 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 162Figure 11. The ePR Server installation at the Server room of CSI. J. Document, was installing the servers.Documet et al. Page 27 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 163Figure 12. Integration Unit (IU, left inside the red ring) installed in the OR connected to different input sources. (Middle: Input units cables are connected to the back of the IU; Right: Vital Signs device is being connected.).Documet et al. Page 28 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 164Figure 13. Group training in Pre-Op authoring at the consultation roomDocumet et al. Page 29 Int J Comput Assist Radiol Surg . Author manuscript; available in PMC May 1. NIH-PA Author Manuscript NIH-PA Author Manuscript NIH-PA Author Manuscript 165 SELECTED BOOK EXCERPTS 190230 Computer-Aided Detection 2 and Diagnosis 3 H.K. (Bernie) Huang, Brent J. Liu, Anh HongTu Le, and Jorge Documet 4 Summary. The ultimate goal of Picture Archiving and Communication System 5 (PACS)-based Computer-Aided Detection and Diagnosis (CAD) is to integrate CAD 6 results into daily clinical practice so that it becomes a second reader to aid the 7 radiologist's diagnosis. Integration of CAD and Hospital Information System (HIS), 8 Radiology Information System (RIS) or PACS requires certain basic ingredients from 9 Health Level 7 (HL7) standard for textual data, Digital Imaging and Communica- 10 tions in Medicine (DICOM) standard for images, and Integrating the Healthcare 11 Enterprise (IHE) workflow proles in order to comply with the Health Insurance 12 Portability and Accountability Act (HIPAA) requirements to be a healthcare infor- 13 mation system. Among the DICOM standards and IHE workflow proles, DICOM 14 Structured Reporting (DICOM-SR); and IHE Key Image Note (KIN), Simple Image 15 and Numeric Report (SINR) and Post-processing Work Flow (PWF) are utilized in 16 CAD-HIS/RIS/PACS integration. These topics with examples are presented in this 17 chapter. 18 18.1 Introduction 19 Picture Archiving and Communication System (PACS) technology for health- 20 care enterprise delivery has become a part of the daily clinical imaging service 21 and data management operations for most health care institutions. Alongside 22 PACS, new technologies have emerged including Computer-Aided Diagnosis 23 (CAD), which utilizes computer methods to obtain quantitative measurements 24 from medical images and clinical information to assist clinicians to assess a 25 patient's clinical state more objectively. However, CAD needs image input and 26 related information from PACS to improve its accuracy; and PACS benets 27 from CAD results online and available at the PACS workstation as a second 28 reader to assist physicians in the decision making process. Currently, these 29 two technologies remain as two separate independent systems with only min- 30 imal system integration. This chapter addresses the challenges and solutions 31 encountered by both technologies. 32 T.M. Deserno (ed.), Biomedical Image Processing , Biological and Medical Physics, Biomedical Engineering, DOI: 10.1007/978-3-642-15816-2 18, c/circlecopyrtSpringer-Verlag Berlin Heidelberg 21a 1b 3 Fig. 18.1. PACS and CAD not integrated. The physician must manually transfer the image to the CAD workstation (1a), initiate the CAD processing, which is archived in the CAD system only (2), and transfer the results back to the PACS by meansof natural language writing the report (3) Figure 18.1 depicts the PACS environment (shaded boxes) and a CAD 33 workstation or server location that is outside the realm of PACS. These two 34 systems are usually disjoint. When an image is needed for CAD processing, 35 the workflow is as follows: 36 1a.A technologist or radiologist transmits the original images from the PACS 37 server or PACS workstation to CAD workstation for processing 38 1b.CAD processing of the exam is ordered through RIS, or directly from its 39 creating modality 40 2.The results are stored within the CAD domain, since the CAD workstation 41 or server is a closed system 42 3.A clinician needs to physically go to the CAD workstation to view results 43 and transfer into the clinical report with natural language worded by the 44 investigator writing the report 45 18.2 The Need for CAD-PACS Integration 46 In most CAD systems, the analyzed images need to reside on the local storage 47 of the workstation running the applications. In the current best practice clini- 48 cal workflow, medical images are stored in PACS. Therefore, the images must 49 be queried for and retrieved by the wor kstation for a CAD system to process. 50 The DICOM Query and Retrieve (Q/R ) begins by sending a DICOM query 51 command that contains query keys, su ch as patient name, medical record, 52 modality, etc. to PACS and then waits for a response. Once the worksta- 53 tion receives the response, which contai ns a patient name or a list of patients 54 satisfying the query keys, it then sends another DICOM command to PACS 55 to retrieve the images back to the workstation. If the CAD application is not 56 implemented with the Q/R functionality from PACS, one must manually load 57 the images to the workstation for CAD process or manually push the images 58 from PACS. After the images are loaded, the CAD performs two tasks: 59 Computer-Aided Detection and Diagnosis 457 Automatic segmentation to detect the location of possible abnormalities 60 in images 61 Quantication to classify th e detected regions or lesions 62 The main purpose for integrating CAD with PACS for clinical operations is 63 to utilize CAD as a second reader for diagnosis of medical images [1,2]. In order 64 to utilize CAD results more eciently for this purpose, the CAD should be 65 integrated within the daily clinical PACS environment. Currently, some PACS 66 and CAD vendors have had some success integrating several C AD applications 67 within a PACS environment, but the solution is either CAD-specic or in a 68 closed PACS environment with proprietary software. 69 18.2.1 Approaches of CAD-PACS Integration 70 Computer-aided detect ion (CADe) is based on images, which must be 71 received from the archive for analysis . This is usually done using a DICOM 72 Query/Retrieve (Q/R) command. Conceptually, integration of CAD with 73 DICOM PACS can have four approaches, which dier in the systems per- 74 forming the query and retrieve commands. In the rst three, the CAD is 75 connected directly to the PACS, while the fourth approach is to use a CAD 76 server to connect with the PACS: 77 PACS Workstation Retrieves and CAD Workstation Performs Detection :78 In this approach, the PACS workstation queries and retrieves images from 79 the PACS database while the CAD workstation performs the detection. 80 Figure 18.2a illustrates the steps of the integration. This method involves 81 the PACS server, the PACS workstation, and the CAD workstation. A 82 DICOM C-store function must be installed in the CAD workstation. 83 The major disadvantage to this approach is that the particular studies 84 must be queried for by the PACS workstation and manually pushed to the 85 CAD workstation for processing, which is a complex workflow. In addition, 86 once the results are generated, they r eside only on the CAD workstation. 87 CAD Workstation Retrieves and Performs Detection : In this approach, 88 the CAD workstation performs both, querying and retrieving of the image 89 data from the archive, and thereafter the detection within the image data. 90 This method only involves the PACS server and the CAD workstation. 91 The function of the PACS server is almost identical to that of the last 92 method. The only dierence is that the last method uses the PACS work- 93 station for querying and retrievin g images, whereas in this method the 94 CAD workstation performs this step. For this reason DICOM Q/R must 95 be installed in the CAD workstation (Fig.18.2b). 96 Although for this approach, the CAD workstation can directly query 97 and retrieve from the PACS to obtain the particular image study for pro- 98 cessing, the workflow is still manual and a disadvantage. In addition, once 99 the results are generated, they res ide only on the CAD workstation. 100 169BookID DICOM Workstation methods of integrating CAD with PACS. (a)P A C S workstation queries/retrieves and the CAD workstation performs the detection (C-GET is a DICOM service); and per- detection; ( c) the PACS workstation has the CAD software integrated; and (d)aC A Ds e r v e ri si n t e g r a t e dw i t ht h eP A C S PACS Workstation with Integrated CAD Software : A more advanced 101 approach is to install the CAD software within the PACS workstation. This 102 method eliminates all components in the CAD system and its connection 103 to the PACS (Fig.18.2c). 104 Most of the CAD components can be eliminated which is an advantage. 105 However, the major disadvantage is that because the CAD must be inte- 106 grated directly with PACS, the CAD manufacturer must work very closely 107 with the PACS manufacturer, or vice versa, to open up the software which 108 rarely happens due to the competitive market. 109 Integration of CAD Server with PACS : In this method, the CAD server is 110 connected to the PACS server. The CAD server is used to perform CAD 111 for PACS workstations (Fig.18.2d). 112 This is the most ideal and practical approach to a CAD-PACS integra- 113 tion. The CAD server can automatically manage the clinical workflow 114 of image studies to be processed and can archive CAD results back 115 to PACS for the clinicians to review directly on PACS workstations. 116 This also eliminates the need for b oth the PACS manufacturer and the 117 CAD manufacturer to open up their respective software platforms for 118 integration. 119 170BookID 190230 Software 120 CAD software [1] can be a stand-alone CAD worksta- 121 tion, a CAD server, or integrated in PACS as PACS-based CAD. Currently 122 several PACS and CAD companies have successfully integrated their CAD 123 applications within the PACS operation, but these applications are either 124 in a CAD-specic workstation or in a closed PACS operation environment 125 using proprietary software. For example in mammography, cf. Chapter 13, 126 page 329, CAD has become an integral part of a routine clinical assessment 127 of breast cancer in many ho spitals and clinics across the United States and 128 abroad. However, the value and eectiv eness of CAD usefulness are compro- 129 mised by the inconvenience of the stand-alone CAD workstation or server, 130 certain DICOM standards and IHE workflow proles are needed, which will 131 be described in the next section. 132 18.3 DICOM Standard and IHE Workflow Proles 133 In order to integrate CAD and HIS/RIS/PACS eciently, certain basic ingre- 134 dients are needed from Health Level Seven (HL7) standard1for textual 135 data, DICOM standard for image communication [3], and Integrating the 136 Healthcare Enterprises (IHE) proles2in order to comply with the Health 137 Insurance Portability and Accountability Act (HIPAA) requirements. These 138 requirements include: 139 Health Care Access 140 Portability 141 Renewability 142 Preventing Health Care Fraud and Abuse 143 Administrative Simplication 144 Medical Liability Reform, containing ve rules: 145 -The Privacy Rule 146 -The Transactions and Code Sets Rule 147 -The Security Rule 148 -The Unique Identiers Rule 149 -The Enforcement Rule 150 The HITECH Act addressing privacy a nd security concerns associated 151 with the electronic transmission of health information 152 Among the DICOM standard and IHE workflow proles, DICOM Struc- 153 tured Reporting (DICOM-SR), and IHE Key Image Notes (KINs), IHE Simple 154 Image and Numeric Reports (SINRs), and IHE Post-processing Work Flows 155 (PWFs) are important components in Huang et al. 18.3.1 DICOM Structured Reporting 157 The scope of DICOM Structured Reporting (DICOM-SR) is the standardiza- 158 tion of structured clinical reports in the imaging environment [6]. DICOM-SR 159 documents record observations made for an imaging-based diagnostic or inter- 160 ventional procedure, particularly info rmation that describes or references 161 images, waveforms, or a specic Regions of Interest (ROI). DICOM-SR was 162 introduced in 1994 and achieved major recognition when Supplement 23 was 163 adopted into the DICOM standard in 1999 as the rst DICOM-SR for clinical 164 reports. The DICOM Committee has initiated more than 12 supplements to 165 dene specic DICOM-SR document templates, cf. Sect. 17.2.2, page 442. 166 Among these supplements, two that relate to capturing CAD results have 167 been ratied: 168 The Mammography CAD SR (Supplement 50, 2000) 169 The Chest CT CAD S R (Supplement 65, 2001) 170 In practice, the use of structured forms for reporting is known to be benecial 171 in reducing the ambiguity of natural language format reporting by enhancing 172 the precision, clarity, and value of the clinical document. 173 DICOM-SR is generalized by using DICOM Information Object Deni- 174 tions (IODs) and services for the storage and transmission of structured 175 reports. Figure 18.3 provides a simplied version of the DICOM model of 176 the real world showing where DICOM- SR objects reside. The most impor- 177 tant part of an DICOM-SR object is the report document content, which is 178 a DICOM-SR template that consists of dierent design patterns for various 179 applications. Once the CAD results with images, graphs, overlays, annota- 180 tions, and text have been translated into a DICOM-SR template designed for 181 this application, the data in the specic template can be treated as a DICOM 182 object stored in the worklist of the data model (Fig.18.3, shaded boxes), and it 183 can be displayed for review by a PACS workstation with the DICOM-SR dis- 184 play function. The viewing requires the original images from which the CAD 185 results were generated so that the results can be overlaid onto the images. 186 Fig. 18.3. Real world model of DICOM. The DICOM-SR document is located in the DICOM data module (shadedbox), which is at the same level as the DICOM image RegistrationRadiotherapy and Diagnosis 461 The DICOM-SR display function can link and download these images from 187 the PACS archive and display them as well on the workstation. 188 18.3.2 IHE Proles 189 IHE proles provide a common language to discuss the integration needs of 190 healthcare sites and integration capabilities of healthcare IT products. They 191 organize and oer clear implementation paths for communication standards, 192 such as DICOM, HL7, and World Wide Web Consortium (W3C), and security 193 standards to meet specic clinical needs. The rst large-scale demonstration 194 (IHE connectathon) was held at the Radiological Society of North Amer- 195 ica (RSNA) annual meeting in 1999, and in subsequent meetings thereafter. 196 In these demonstrations, manufact urers came together to show how their 197 products could be integrated toge ther according to IHE protocols. 198 There are three IHE proles useful for CAD-PACS integration: 199 1.KINallows users to flag images as signican t (e.g., as reference, for surgery) 200 and to add a note explaining the content 201 2.SINR species how diagnostic radiology reports (including images and 202 numeric data) are created, exchanged, and used 203 3.PWF provides a worklist, its status and result tracking for post-acquisition 204 tasks, such as CADe, Computer-Aided Diagnostics (CADx), or other image 205 processing tasks 206 18.4 The CAD-PACSTMToolkit 207 In the beginning of this chapter, we have discussed the current workflow 208 of CAD in clinical use. To overcome the several bottlenecks, a CAD-PACS 209 toolkit (Fig. 18.4, elliptic box), which can integrate with the PACS server 210 and/or workstation with the CAD server and/or workstation via the DICOM 211 standard and IHE proles, passes the CAD results to the PACS server for 212 archiving and the PACS workstation for viewing; and query/retrieves original 213 images from PACS server to PACS workstation to be overlaid with the CAD 214 results. In addition, it can automatically pass images directly from the PACS 215 server or PACS workstation to the CAD workstation for processing. 216 ModalityPACS Environment The CAD workflow ( dotted lines )i s integrated in the PACS environment (shaded box )u s i n gt h e Huang et al. 18.4.1 Concept 217 The CAD-PACSTMToolkit is a software toolkit using the HL7 standard 218 for textual information; the DICOM standard for various types of data for- 219 mats, including images, waveforms, graphics, overlays, and annotations; and 220 IHE workflow proles described in the a forementioned section for the inte- 221 gration of CAD results within the PACS workflow [5]. This software 222 toolkit is modularized and its compon ents can be ve 223 congurations: 224 1.A stand-alone CAD workstation 225 2.AC A Ds e r v e r 226 3.A PACS workstation 227 4.AP A C Ss e r v e ro r 228 5.A mix of the previous four congurations 229 In general, a CAD manufacturer would be more comfortable with the rst 230 two approaches because there is very little collaboration needed for the PACS 231 software, which is too complex for most CAD manufacturers. On the other 232 hand, a PACS manufacturer would prefer to use an in-house CAD or acquire 233 the CAD from a third party and integrate it with its own PACS using the 234 latter three approaches. 235 18.4.2 Structure, Components, and Editions 236 The CAD-PACSTMToolkit has ve software modules: 237 1.i-CAD-SCTMcreates the screen shot for any CAD application, converts it 238 to a DICOM object and sends it to PACS for storage 239 2.i-CADTMresides in the CAD workstation and provides key functions for 240 CAD-PACS integration, including DICOM-SR object creation and archival, 241 query and retrieval of images for CAD processing, and communication with 242 the i-PPMTMmodule 243 3.i-PPMTMresiding in the PACS server provides functions to schedule and 244 track status of CAD-PACS workflow. This module is also used as a supple- 245 ment for those PACS manufacturers which do not support post-processing 246 management in order to be DICOM and IHE-compliant for CAD-PACS 247 integration 248 4.Receive-SRTMresides in the PACS server and performs the functions of 249 archiving, query and retrieving DICOM-SR objects from the PACS server 250 5.Display-SRTMresides in the PACS workstation. This module is used when 251 PACS does not support DICOM-SR C-Store Service Class User (SCU) and 252 C-Find. It is built as a display Web server with DICOM-SR C-Store and 253 C-Find features 463 Fig. 18.5. Architecture of the CAD-PACSTMToolkit [5]. T h e v em o d u l e sa r ec o m - bined to three dierent editions ( left). The concept of four levels of integration with the CAD-PACSTMToolkit is shown on the right Furthermore, the CAD-PACSTMToolkit has three editions for the dierent 255 levels of PACS integration requirements. Each edition contains some or all of 256 the software modules (Fig.18.5) [5]: 257 DICOM-SCTM: The rst edition converts a simple screen capture output, 258 and the CAD data are not stored for future use. 259 DICOM-PACS-IHETM: The second edition is for full CAD-PACS integra- 260 tion requiring elaborate collaboration between the CAD developer and the 261 PACS manufacturer. 262 DICOM-CAD-IHETM: The third edition does not require the elaborate 263 integration eorts of the two parties, and proper use of the CAD-PACS 264 toolkit is sucient, which favors the independent CAD developer. 265 18.5 Example of CAD-PACS Integration 266 In this section, we provide a step-by- step procedure to integrate a CAD with 267 PACS using the Bone Age Assessment (BAA) of children on a hand and wrist 268 radiograph as an example. 269 The classical method of BAA is a clinical procedure in pediatric radiol- 270 ogy to evaluate the stage of skeletal maturity based on a left hand and wrist 271 radiograph through bone growth observations. The determination of skeletal 272 maturity (\"bone age\") plays an important role in diagnostic and therapeutic 273 investigations of endocrinological abnormality and growth disorders of chil- 274 dren. In clinical practice, the most commonly used BAA method is atlas 275 matching by a left hand and wrist radiograph against the Greulich and Pyle 276 atlas, which contains a reference set of normal standard hand images collected 277 in 1950s with subjects exclusively from middle and upper class Caucasian pop- 278 ulations. The atlas has been used for BAA around the world for more than 279 50years [7]. 280 18.5.1 The Digital Hand Atlas 281 Over the past 30years, many studies ha ve raised questions regarding the 282 appropriateness of using the Greulich and Pyle atlas for BAA of contemporary 283 Proof# 1 - (Bernie) Huang et al. children [8]. However, these studies did not provide a large-scale and system- 284 atic method for validation. A digital hand atlas with normal children collected 285 in the United States along with a CAD-BAA method has been developed dur- 286 ing the past 10years in our laboratory as a means to verify the accuracy of 287 using the Greulich and Pyle atlas to assess today's children bone age [9]. 288 The digital hand atlas consists of eight categories, where each category 289 contains 19 age groups, one group for subjects younger than 1 year, and 18 290 groups at 1-year intervals for subjects aged 1-18years. The case distribution 291 within each of these 18 groups is as even as possible during the case collection 292 of gender and ethnicities (Table 18.1). 293 The total is 1,390 cases. For each case, at least two pediatric radiologists 294 had veried the normality and chronological age, and assessed the bone age 295 of the child based on the Greulich and Pyle atlas matching method [10]. 296 18.5.2 CAD Evaluation in a Laboratory Setting 297 After the CAD was completed, the system needed to be integrated with the 298 PACS. The integration is then evaluated rst in a laboratory setting, followed 299 by the clinical environment. After image acquisition using Computed Radiog- 300 raphy (CR), Digital Radiography (DR), or lm scanner, the image is archived 301 in the PACS server. The laboratory set up then mimics the clinical workflow 302 as shown with four steps (Fig.18.6): 303 0.The PACS workstation query/retrieves the hand image from the PACS 304 archive and displays it on the monitor 305 1b.The modality/PACS server also sends a second copy of the hand image 306 to the CAD server which generates CAD results 307 Table 18.1. The digital hand atlas. A breakdown of cases according to gender and ethnicsEthnics/Gender Female Male Total Asian 167 167 334 African-American 174 184 358 Caucasian 166 167 333 Hispanic 183 182 365 Sum 690 700 1,390 Fig. 18.6. Laboratory setting for BAA evaluation [11]. The BAA-CAD system in thelaboratory environmentusing a PACS simulator is composed of four 465 2.The CAD server sends CAD results to the PACS workstation. The radi- 308 ologist reviews both the image and CAD result on the PACS workstation 309 3.The diagnosis from the radiologist assisted by CAD results is sent back 310 to the CAD server for storage 311 18.5.3 CAD Evaluation in a Clinical Environment 312 After laboratory validation, the BAA-CAD system and the PACS worksta- 313 tion were installed in a clinical environment for further evaluation. In this 314 example, the clinical environment is located at the Radiology Department of 315 Los Angeles County Hospital (LAC) and University of Southern California 316 (USC), where the CAD workstation can access the PACS and CR images. 317 The clinical workflow is similar to the laboratory workflow (Fig. 18.7): 318 1.The CR modality sends a copy of the hand image to the Web-based CAD 319 server located in the radiology reading room. The PACS workstation also 320 receives a copy of the image from the PACS server 321 2.The CAD program at the CAD server receives the image, performs BAA 322 and records the results in the CAD server database 323 3.The CAD server searches the PACS workstation to locate the original 324 image and links up with the CAD result, as well as the best-matched 325 image from the digital hand atlas in the CAD database 326 4.The Graphical User Interface (GUI) in the PACS workstation displays the 327 original image and the best-matched image (Fig.18.6, the right most image 328 set on the duel monitors), and assists the radiologist to take advantage of 329 the CAD results to make the nal diagnosis 330 CR Modality GatewayPACS ServerPACS WSLos Angeles County General Hospital ReceiverBAA CADWeb server Radiologist decisions CAD report on webCAD Server at Radiology Dept Reading Room LAC image CAD Report Web-based GUI Fig. 18.7. Clinical BAA evaluation setup. The diagram depicts the BAA-CAD system in clinical environment and the according workflow implemented in the LAC Hospital with the clinical PACS and the CAD server 177BookID 18.5.4 CAD-PACS Integration Using DICOM-SR 331 In Sect.18.3.1, we presented the concept of DICOM-SR and the need for con- 332 verting a text le CAD report to DICOM-SR format in order to overlay the 333 contents within the DICOM-SR onto the original image and to display it on 334 the PACS workstation. Referencing to two ratied CAD DICOM-SR tem- 335 plates for mammography and chest CT in the DICOM standard Supplement 336 50 and 65, a DICOM-SR object for the BAA-CAD based on a tree structure 337 was designed and implemented. 338 Figure 18.8 illustrates the DICOM- SR template for the BAA-CAD. This 339 design, which utilizes the DICOM standard Supplement 23, has a Document 340 Root BAA-CAD which branches into four parent nodes: Detection Performed 341 (DP), Analysis Performed (AP), Findings summary and Image library. Each 342 DP and AP parent nodes can have one or more children nodes. In this case, DP 343 describes one imaging processing algorithm, which is the BAA algorithm. The 344 AP parent node has two children nodes; each describes methods of quantita- 345 tive analysis that were performed on the hand image. Each analysis performed 346 can be further branched out to one or multiple grandchild nodes called Single 347 Image Findings (SIF). As shown in Fig.18.8, each AP children node only has 348 one SIF. The ndings summary parent node is the most important part of 349 an SR which includes the BAA-CAD results. The Image Library parent node 350 is optional; however, in the BAA-CAD SR, it is used to reference the images 351 from the digital hand atlas. The data structure format for each child can be 352 obtained directly from the DICOM standard, Supplement 23. 353 Figure 18.9 depicts the rst page of the BAA-CAD report in DICOM-SR 354 format of Patient 1. To the right is the plot of the bone age (vertical axis) 355 against the chronological age (horizontal axis) of Patient 1 (red dot) within 356 the\u00b1two standard deviations of the normal cases in the digital hand atlas. 357 Figure 18.10 shows an image page of the DICOM-SR report of Patient 358 2 including the original image (left) from which the BAA-CAD result was 359 obtained, the Greulich and Pyle atlas best-matched image (middle), and the 360 digital hand atlas best-matched image (right). The chronological age and the 361 CAD-assessed age of Patient 2, and the chronological age of the best-matched 362 Fig. 18.8. Nested DICOM-SR templates for BAA-CAD. The template is designed based on the types of output radiologists are required toreviewBAA-CAD Document RootDetection performed (DP)DP: BAA algorithm Analysis performed (AP)AP: match (CMI)Single image finding (SIF): Ref. CMI AP: Development curve(DC)SIF: Ref. object in normal DC Finding summary: BAA-CAD age Image library: Digital hand and 467 Fig. 18.9. Integrating BAA-CAD with DICOM-SR. Left :T h eC A Dr e p o r ti n DICOM-SR format is based on the design of the DICOM-SR template as shown in Fig. 18.8; Right: The plot of the CAD-BAA results of a patient ( red dot )c o m - pared with the normals and \u00b1two standard deviations in the digital hand atlas is a component in the DICOM-SR template image in the digital hand atlas are enclosed inside the green ellipse in the upper 363 right corner. The plot of the CAD-assessed bone age of the patient within the 364 \u00b1two standard deviations of the normal cases in the digital hand atlas is 365 shown in the upper right corner. The best-matched digital hand atlas image 366 is obtained by using the CAD age of Patient 2 to search the digital hand atlas 367 in the order of race, sex and age. The image with the closest chronological age 368 (the best matched age) is the matched image in the digital hand atlas. The 369 chronological age, BAA bone age, and the matched digital hand atlas age are 370 shown at the upper right of the screen within the green ellipse. 371 18.6 Conclusion 372 In order for CAD to be useful to aid diagnosis and/or detection, it has to 373 be integrated into the existing clinical workflow. In the case of image-based 374 CAD, the integration is with the PACS daily workflow. We have presented 375 the rationale and methods of CAD-PACS integration with emphasis in PACS 376 workflow proles using the DICOM standard and IHE workflow proles. 377 In the PACS-based workflow approach, the CAD results do not reside in 378 the PACS server and storage; instead they are in the CAD server. PACS 379 images used by the CAD are linked with the CAD results so that both images 380 179BookID Proof# 1 - Huang et al. Fig. 18.10. BAA-CAD GUI on the PACS workstation. Left : Original image; Center : Best matched Greulich and Pyle atlas image; Right: Best matched digital hand atlas image. The CAD-assessed bone age of the patient compared to the children in the normal range in the DHA is shown in the plot a n dC A Dr e s u l t si nD I C O Mf o r m a tc a nb ed i s p l a y e do nt h eP A C Sw o r k s t a - 381 tion. We use an example in BAA on hand and wrist joint radiographs as an 382 introduction to the advantage of CAD and PACS integration for daily clinical 383 practice. In general, physicians can assess the bone age of a child using the 384 Greulich and Pyle method, but the question is whether the classic method is 385 still valid for assessing the bone age of children of today. With the integra- 386 tion of BAA-CAD directly into the PACS workflow, the radiologist has the 387 CAD results as the second opinion to assist his/her BAA and to conrm the 388 diagnosis. 389 In conclusion, the integration of CAD to PACS clinical workflow has many 390 distinct advantages: 391 PACS technology is mature. Integrating CAD with the PACS can take 392 advantage of the powerful computers and high-speed networks utilized in 393 PACS to enhance the computational and communication power of the 394 CAD 395 The DICOM-SR and IHE workflow proles can be readily applied to 396 facilitate the integration of CAD results to PACS workstations 397 PACS-based query/retrieve tools can facilitate the CAD user to obtain 398 images and related patient data more directly from PACS for CAD 399 algorithm enhancement and execution 400 Detection and Diagnosis 469 CAD-PACS integration results can b e directly viewed and utilized at the 401 PACS workstation together with relevant PACS data 402 The very large, dynamic, and up-to-date PACS databases can be utilized 403 by CAD to improve its diagnostic accuracy 404 To utilize the DICOM-SR content more eciently, the current trends 405 for CAD and PACS integration is to promote the development of DICOM- 406 compliant databases and services which combine CAD ndings and DICOM 407 key image references [5]. This incorporation allows content-based query/ 408 retrieval of DICOM imaging studies based on DICOM-SR with its quan- 409 titative ndings rather than header information of DICOM objects and/or 410 disease category. The benets of querying/retrieving content-based imaging 411 data could have a large impact on medical imaging research and clinical prac- 412 tice. However, there are many challeng es in the development of data mining 413 methodology for CAD including the following: 414 Collaboration with PACS vendors at multiple medical centers to open 415 access to both PACS and CAD data 416 Acknowledgment of Institutional Review Board (IRB) and personal health 417 information requirements for using human subjects for research with 418 information within the PACS 419 Adoption and utilization of DICOM-SR templates in all PACS vendors 420 References 421 1.Doi K. Computer-aided diagnosis in medical imaging: historical review, current 422 status and future potential. Comput Med Imag Graph. 2007;31(4-5):198-211. 423 2.Huang HK, Doi 425 Standard. 23: Report ing Object. 1999;(2):1-47. 426 4.Zhou Z, Liu BJ, Le A. CAD-PACS integration tool kit-based on DICOM 427 screen capture (SC) and structured reporting (SR) and IHE workflow proles. 428 J Comput Med Imag Graph. 2007;31(4):346-52. 429 AHT, Huang HK, Liu B. Integration of computer-aided diagnosis/detection 430 (CAD) results in a PACS environment using CAD-PACS toolkit and DICOM 431 SR. Int 7.Greulich WW, Pyle SI. Radiographic atlas of skeletal development of hand 434 wrist. 2nd ed. Stanford, CA: Stanford University Press; 1959. 435 8.Huang HK. PACS and imaging informatics: basic principles and applications. 436 2nd ed. Hoboken, NJ: Wiley and Blackwell. 2010. 437 9.Gertych A, Zhang A, Sayre J, et al. Bone age assessment of children using a 438 digital hand atlas. Comput Med Imag Graph. 2007;31(4):322-31. 439 10.Zhang A, Sayre JW, Vachon L, et al. Cross-racial dierences in growth patterns 440 of children based on bone age assessment. J Radiology. 2009;250(1):228-35. 441 11.Zhou Z, Law M, Huang HK, et al. An educational RIS/PACS simulator. 442 InfoRAD exhibit. provide author/instit ute name for the reference \"[3]\". AQ2. Please provide author/instit ute name for the reference \"[6]\". 182 "}